{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Machine Learning Foundation\n",
    "\n",
    "## Course 5, Part d: Keras Intro LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Keras to Build and Train Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use a neural network to predict diabetes using the Pima Diabetes Dataset.  We will start by training a Random Forest to get a performance baseline.  Then we will use the Keras package to quickly build and train a neural network and compare the performance.  We will see how different network structures affect the performance, training time, and level of overfitting (or underfitting).\n",
    "\n",
    "## UCI Pima Diabetes Dataset\n",
    "\n",
    "* UCI ML Repositiory (http://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes)\n",
    "\n",
    "\n",
    "### Attributes: (all numeric-valued)\n",
    "   1. Number of times pregnant\n",
    "   2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "   3. Diastolic blood pressure (mm Hg)\n",
    "   4. Triceps skin fold thickness (mm)\n",
    "   5. 2-Hour serum insulin (mu U/ml)\n",
    "   6. Body mass index (weight in kg/(height in m)^2)\n",
    "   7. Diabetes pedigree function\n",
    "   8. Age (years)\n",
    "   9. Class variable (0 or 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The UCI Pima Diabetes Dataset which has 8 numerical predictors and a binary outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_curve, roc_auc_score, roc_curve, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Keras objects for Deep Learning\n",
    "from keras.models  import Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load in the data set \n",
    "names = [\"times_pregnant\", \"glucose_tolerance_test\", \"blood_pressure\", \"skin_thickness\", \"insulin\", \n",
    "         \"bmi\", \"pedigree_function\", \"age\", \"has_diabetes\"]\n",
    "diabetes_df = pd.read_csv('data/diabetes.csv', names=names, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>times_pregnant</th>\n",
       "      <th>glucose_tolerance_test</th>\n",
       "      <th>blood_pressure</th>\n",
       "      <th>skin_thickness</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree_function</th>\n",
       "      <th>age</th>\n",
       "      <th>has_diabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>6</td>\n",
       "      <td>151</td>\n",
       "      <td>62</td>\n",
       "      <td>31</td>\n",
       "      <td>120</td>\n",
       "      <td>35.5</td>\n",
       "      <td>0.692</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42.2</td>\n",
       "      <td>0.237</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>5</td>\n",
       "      <td>85</td>\n",
       "      <td>74</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.224</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>86</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.143</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>48</td>\n",
       "      <td>18</td>\n",
       "      <td>76</td>\n",
       "      <td>20.4</td>\n",
       "      <td>0.323</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     times_pregnant  glucose_tolerance_test  blood_pressure  skin_thickness  \\\n",
       "295               6                     151              62              31   \n",
       "350               4                      92              80               0   \n",
       "218               5                      85              74              22   \n",
       "249               1                     111              86              19   \n",
       "97                1                      71              48              18   \n",
       "\n",
       "     insulin   bmi  pedigree_function  age  has_diabetes  \n",
       "295      120  35.5              0.692   28             0  \n",
       "350        0  42.2              0.237   29             0  \n",
       "218        0  29.0              1.224   32             1  \n",
       "249        0  30.1              0.143   23             0  \n",
       "97        76  20.4              0.323   22             0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a peek at the data -- if there are lots of \"NaN\" you may have internet connectivity issues\n",
    "print(diabetes_df.shape)\n",
    "diabetes_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = diabetes_df.iloc[:, :-1].values\n",
    "y = diabetes_df[\"has_diabetes\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to Train, and Test (75%, 25%)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=11111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3489583333333333, 0.6510416666666666)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y), np.mean(1-y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we see that about 35% of the patients in this dataset have diabetes, while 65% do not.  This means we can get an accuracy of 65% without any model - just declare that no one has diabetes. We will calculate the ROC-AUC score to evaluate performance of our model, and also look at the accuracy as well to see if we improved upon the 65% accuracy.\n",
    "## Exercise 1: Get a baseline performance using Random Forest\n",
    "To begin, and get a baseline for classifier performance:\n",
    "1. Train a Random Forest model with 200 trees on the training data.\n",
    "2. Calculate the accuracy and roc_auc_score of the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=200)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "## Train the RF Model\n",
    "rf_model = RandomForestClassifier(n_estimators=200)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.766\n",
      "roc-auc is 0.830\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set - both \"hard\" predictions, and the scores (percent of trees voting yes)\n",
    "y_pred_class_rf = rf_model.predict(X_test)\n",
    "y_pred_prob_rf = rf_model.predict_proba(X_test)\n",
    "\n",
    "\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_rf)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_rf[:,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAHiCAYAAADSwATnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABFnElEQVR4nO3dd3hUZf7+8fcTqiBkpUtHgQVEXRREXVaiogiorPUnimBbUZevSC+CgCBVRVjLiiiIilhQRAULaARRuvQmAQxFkBIgQHqe3x8zsCEmZCAz80y5X9eVizlzTs7c82SYz3zOOXOOsdYiIiIioSPGdQARERE5lYqziIhIiFFxFhERCTEqziIiIiFGxVlERCTEqDiLiIiEGBVniUrGmHOMMZ8bYw4bYz5ynSeaGGMeMMb8mGP6qDHmAh9+r7YxxhpjigY2oTsFPUdjzBBjzLvBziXBp+IcBYwx240xKd43wT3GmCnGmHNzLXO1MeY7Y0yyt2B9boxplGuZssaYl4wxid51JXinK+TzuMYY86QxZq0x5pgxZqcx5iNjzMWBfL4+uhOoDJS31t5V2JUZY+KMMdnecUk2xmwyxjyYaxnrHYej3p9DhX1cH3JNMcakex/voDHmW2NMA++8U97ovfn+yFkYjDHFvPf96YQI3nVnGmPOL0xGa+251tqthVlHQaKhsEtkUXGOHrdYa88F/gY0AfqfmGGMuQr4BvgMqArUAVYBC090NMaY4sA84CLgJqAscBVwALgin8ccD3QDngTKAfWBmUC7Mw0fgDfVWsBma22mH7Ps9o5xWaA78IYx5q+5lrnUW4zOtdb+5Uwf+yyN8eaqDvwBTDnNsklAmxzTbbz3ncIYUxq4AzgMdPRb0ginDwfiKxXnKGOt3QN8jadInzAGmGqtHW+tTbbWHrTWDgQWAUO8y3QCagK3WWvXW2uzrbV/WGuHWWtn534cY0w94N9AB2vtd9baNGvtcWvte9baUd5l4o0xj+T4ndybO60x5t/GmF+BX40xrxljns/1OJ8ZY3p4b1c1xswwxuwzxmwzxjyZ1xgYY4YCzwD/z9tRPmyMiTHGDDTG/ObtFKcaY2K9y5/ouh42xiQC3xUwxtY7JgeBS063bD75fMnS2bsFY78x5mlf1mutPQ5MAxqfZrF38PytT+gETM1juTuAQ8CzQOcCnk95Y8wsY8wRY8wS4MJc860xpq73djtjzC/eZXcYY4bkscqHjDG7jTG/G2N65VhPjDGmn3eLzgFjzIfGmHLe2fO9/x7y/s2v8v7OQ8aYDcaYJGPM18aYWt77jTFmnHf8jxhj1hhj8hw37+t4pDFmiXfZz048bl6vndP9fQt6jnk89pXGmJ+MMYeMMauMMXG5cg33zj9qPFvDyhtj3vPmXGqMqZ3fusUxa61+IvwH2A608t6uDqwBxnunSwFZwLV5/N6DwO/e29OBt8/gMR8DfitgmXjgkRzTDwA/5pi2wLd4uu5zgGuAHYDxzj8PSMHT7ccAy/EU3eLABcBWoHU+jz0EeDfH9EPAFu/vnQt8ArzjnVfbm2UqUBo4J4/1xQE7vbdjgFuBbKBJrudT14ex8yXLG94xuRRIAxrms64pwHDv7XPxFOcF+YyBxVO49wJ/8Y7vXu99Ntd65+H5UFcZyAQuP83zmQ586B27xsCuPP7OdXOM48XeMbzE+/j/zPXc3/eu62JgH/97bXfD84GyOlACeB14P9fvFs3xuO2949wQKAoMBH7yzmvtfT39BTDeZc4/zet4l/e5lQZmnBjXvF47Pv5983uOQ3KsuxqeLVdtveN1g3e6Yo5cW/B8GIoF1gObgVbe5zsVmOz6/Uk/+fy/cR1AP0H4I3uK81Eg2fsffx7wF++86t77GuTxezcBGd7b3wKjzuAxnwYWFbBMPAUX5+tyTBsgEbjGO/0v4Dvv7eZAYq7198/vzYc/F6Z5wBM5pv8KZHjfxE68YV5wmucSh6cYH8JTLLOAp3ItY4Ej3mUOARPyWZcvWarnmL8EuCefdU0BUr2PtweYBVyYzxhYoC4wCeiC5wPWG977bI7lanqf69+801/j/bCXx+MX8WZvkOO+EXn8nfP80AK8BIzz3j7x3HOuawzwpvf2BuD6HPPOz2PcchbnOcDDOaZjgON4dnlch6eQXQnE+PA6HpVjuhGQ7n3uf3rt+Pj3ze85nvybAX3xFvUcy34NdM6R6+kc814A5uSYvgVY6ev/af0E90ebtaPHP621ZfAUkQbAiYO4kvC80eZ1UM/5wH7v7QP5LJOfM10+PztO3LCed5TpQAfvXfcC73lv1wKqejfvHTKeg60G4OnsfFEV+C3H9G943ixz/v4OTm+39exHLgtMwPMGn9tl1tq/eH/y3OzuY5Y9OW4fx9OB5ed57+NVsdbeaq1NKOB5TMWzOTu/Tdr3AxustSu90+8B9xpjiuWxbEVv9pxj91seywFgjGlujPneu2viMJ4PCLkPOMy9rqre27WAT3P8/Tfg+ZCU32ugFjA+x/IH8XwArGat/Q54GXgF+MMYM9EYUza/3HlkKpYrd875Z/pay/kcc+e/K9drvgWn/r/bm+N2Sh7Tp3vdiEMqzlHGWvsDnm7qee/0MeBnIK8jlu/G8ykfYC7Q2ngOBPLFPKC6MabpaZY5hmez+glV8oqca/p94E7vvsHmeDYhgufNbFuOwvcXa20Za21bH/PuxvNmd0JNPJtrc76Z5c6SJ2ttGp6u5mJjzD99fPwzzRJIC/C8wVcGfsxjfifgAuM58n8P8CKeQpTXWO/Dk71Gjvtqnuaxp+Hp7mtYa2OB/+IpmDnlXtdu7+0dQJtcr4GS1tpd5P232wF0ybX8OdbanwCstROstZfj6YTrA71Pkzt3pgz+98GWXI/vy983v+eYO/87ufKXtt5jOiS8qThHp5eAG4wxl3qn+wGdjedrT2WMMecZY4bjORp7qHeZd/C8GcwwxjTwHtRS3hgzwBjzpzdla+2vwKvA+8bzNaPixpiSxph7jDH9vIutBG43xpTyHhD0cEHBrbW/4HnTmwR8ba095J21BEg2xvQ1nu8wFzHGNDbGNPNxTN4Huhtj6hjP18xGAB/Yszia25szHc9mxGfO4tf9muVMebdQ3ALc6r19kvdAqgvxHKH/N+9PYzxFtRO5WGuz8OxTHeL9Ozfi9AeQlQEOWmtTjTFX4Nk6ktsg77ouwnNcxAfe+/8LPJfjoK6Kxpj23nn78Gwhyvl96v8C/b3rwRgTa4y5y3u7mbeLL4bnQ2Sq9/fz09EY08gYUwrPQXIfe597Xnz5++b3HHN6F7jFGNPa+3ov6f2/Vv00OSVMqDhHIWvtPjybK5/xTv+I5wCY24Hf8WxGawK08BbZE91gK2Ajnv3PR/AUxArA4nwe6kn+t2nwEJAA3AZ87p0/Ds++ub3A2/xvE3VBpnmzTMvxnLKAm/EUi238r4DH+rjOt/B8AJnv/f1U4P98/N3TrbOmMeaWs/g9f2c5I9baddbadXnM6gx8Zq1dY63dc+IHz9fmbjb/Ozo6p654Np/uwbPVZvJpHvoJ4FljTDKe1+eHeSzzA54Dnebh2WT/jff+8Xi67m+8v78Iz9YVrOdI9efwfD3wkDHmSmvtp8BoYLox5giwlv99jawsnv3tSXj+PxwAxp4m9zve57YHKInntZ8fX/6++T3Hk6y1O/Ac1DYAz4ePHXi6e72vRwCT64OxiIicAWNMPJ6DtCa5ziKRQ5+wREREQoyKs4iISIjRZm0REZEQo85ZREQkxKg4i4iIhJgCr5BijHkLz1dU/rDW/unE78YYg+crDG3xnKnoAWvtioLWW6FCBVu7du2T08eOHaN0aV/PbyFnSuMbWBrfwNHYBpbGN3Byj+3y5cv3W2sr+vK7vly+bAqe76rmdRo/8HwvsJ73pznwmvff06pduzbLli07OR0fH09cXJwPceRsaHwDS+MbOBrbwNL4Bk7usTXG5Hvq2twK3KxtrZ2P55yz+WmP53KD1lq7CPiLKeTF10VERKKZPy78XY1TT9K+03vf735Yt4iIhJns7GymT5/O4sX5nTwwOhw7duyst0r4ozj7zBjzKPAoQOXKlYmPjz857+jRo6dMi39pfANL4xs4GtvA8vf4rl+/npdffpkNGzZwzjnnUKRIEb+tO1xYa0lPT6d69epnPbb+KM67OPUKKtW99/2JtXYiMBGgadOmNucnCu33CCyNb2BpfANHYxtY/hrf3bt3079/f6ZOnUqVKlV4++236dixIzEx0fWloOzsbDZs2EDx4sXZtWvXWY+tP0ZtFtDJeFwJHLbWapO2iEgUSE1NZeTIkdSvX5/p06fTr18/Nm/eTKdOnaKuMFtr6d+/P9Za6tWrV6h1+fJVqveBOKCCMWYnMBjPhcSx1v4XmI3na1Rb8HyV6sFCJRIRkZBnrWXmzJn07NmTbdu28c9//pPnn3+eCy+80HU0JzIyMli4cCH9+vXjvPPOK/T6CizO1toOBcy3wL8LnURERMLC2rVreeqpp5g3bx4XXXQR3377La1atXIdy6lhw4bRqVMnvxRmCPIBYSIicmbi4+NJSEgI2Po3btx4Rutfvnw5r7/+OrGxsbz88st06dKFokWjt5SkpaUxY8YMBg8e7NeD36J3REVEQpi1lsGDBzNs2DDXUU4RExPD448/ztChQylfvrzrOM69+uqr3HHHHX4/Kl3FWUQkxKSlpfHII4/w7rvv8tBDDzF48GA8Z0r2v59//pmrrrrK5+VLly5NuXLlApIlnBw7dozXX3+dHj16BGT9Ks4iIiEkKSmJ22+/nfj4eIYPH86AAQMCVpgBEhISqFGjRsELyilmzpzJvffeG7D1qziLiISI7du307ZtWxISEnj33Xe57777XEeSXA4fPsyIESMYNWpUQD80qTiLiISApUuXcvPNN5ORkcE333xDy5YtXUeSXNLT01myZAl9+/YNaGEGFWcREbZt28b+/fudPf6GDRt47LHHqFy5MnPmzKFBgwbOskje9u/fz+DBgxk3bhzFixcP+OOpOItI1LLWMm7cOHr16oXnlA3uXHHFFcyaNYvKlSs7zSF/duDAAX777TdGjhwZlMIMKs4iEqUyMzPp1q0br776KnfeeScPPPCAsyxFixalZcuWlCxZ0lkGydvvv//O8OHDGTNmDKVLlw7a46o4i0jUOXr0KPfccw9ffvklvXv3ZtSoUVF3Hmgp2M6dO0lKSmLs2LGUKlUqqI+tV6OIRJXdu3dzzTXXMGfOHF599VXGjBmjwix/8vvvvzNmzBjq1asX9MIM6pxFJIqsXbuWtm3bcvDgQT7//HPatm3rOpKEoISEBJKTkxk7diwlSpRwkkHFWUScy8zMJDMzM8956enppKamFvoxFixYwJ133knp0qVZsGABTZo0KfQ6JfIcOXKE1157jZEjR1KsWDFnOVScRcSphIQEWrRowZ49ewL+WI0bN+bLL7+kZs2aAX8sCT/r169n7969jB07NuDfYy6IirOIONWrVy+Sk5N57rnn8tz3u3XrVi644IJCP06pUqXo3LkzsbGxhV6XRJ7MzExmzJgR8NOl+krFWUSc+e6775g5cybPPfccAwYMyHOZ+Ph44uLightMosqKFSvYunUrgwYNch3lJB2iKCJOZGZm8tRTT1G7du2AXdlHpCDWWpYuXcodd9zhOsop1DmLiBNvvPEGa9as4eOPP9bJN8SJhQsXsnbtWrp06eI6yp+ocxaRoEtKSmLQoEHExcVx++23u44jUejYsWMkJSXx6KOPuo6SJ3XOIlFowoQJvPzyy84e/+jRoyQlJfHSSy+FxME3El3mzp3LunXr6Natm+so+VJxFolCc+fOZd++fbRp08ZZhtatW3PppZc6e3yJTtu2baN8+fIhXZhBxVkkatWpU4dp06a5jiESNF988QWJiYk88cQTrqMUSMVZREQi3o8//kizZs24+eabXUfxiQ4IExGRiDZ79my2bNkSVtfKVucsIiIR65NPPuHGG2/k3HPPdR3ljKhzFolCx44dcx1BJODmz59Penp62BVmUHEWiSpZWVl069aN7777jhYtWriOIxIwb775Jo0bN+aee+5xHeWsaLO2SJQ4duwY9913H5999hk9evRgzJgxriOJBMTatWupUKEC5cqVcx3lrKlzFokCe/fu5dprr+Xzzz/nP//5Dy+88AJFihRxHUvE78aPH0+pUqVo37696yiFos5ZJMJt2LCBtm3b8scffzBz5kxuueUW15FEAmLHjh00atTIL5cYdU2ds0gE+/7777n66qtJTU1l/vz5KswSkay1jBo1iv3793PDDTe4juMXKs4iEeqdd96hdevWVK1alUWLFnH55Ze7jiTid9Zadu7cybXXXkuTJk1cx/EbFWeRCGOtZdiwYXTq1IkWLVqwcOFCatWq5TqWiN9Zaxk6dCh79uyhefPmruP4lfY5i0SQjIwMunTpwuTJk+nUqRNvvPEGxYsXdx1LxO+ys7NZt24dHTt2pG7duq7j+J06Z5EIcfjwYdq2bcvkyZMZMmQIU6ZMUWGWiGStZeDAgWRnZ0dkYQZ1ziIRITExkbZt27Jp0yamTJlC586dXUcSCYjMzEzi4+Pp27cvsbGxruMEjDpnkTC3YsUKmjdvzs6dO/n6669VmCWijRgxgho1akR0YQZ1ziJ+k5aWxrx580hPTw/aY+7Zs4devXpRvnx55s6dy0UXXRS0xxYJpvT0dD744AMGDhxITEzk95UqziJ+8vHHH9OxY8egP+7ll1/OF198QZUqVYL+2CLB8sYbb9CuXbuoKMyg4iziN8ePHwfg66+/plKlSkF5TGMMjRo1olixYkF5PJFgS0lJ4eWXX6Z3796uowSVirOIn1100UVUq1bNdQyRsGet5fPPP+e+++5zHSXoomP7gIiIhJXk5GR69+7NnXfeSdWqVV3HCToVZxERCSmpqaksX76cfv36Rc0+5ty0WVvkDFhrSUxMJCsr65T7d+/ezb59+xylEokcBw8eZODAgbz44ouULFnSdRxnVJxFzsDLL7/Mk08+edpldFYukbNz4MABEhMTGTlyZFQXZlBxFjkjJ7rjt99++5T7N2zYQMOGDalSpQoVK1Z0EU0krO3du5dnn32WUaNGUaZMGddxnFNxFjlDxhg6dep0yn3x8fHExcW5CSQS5nbv3s3+/fsZM2YMpUuXdh0nJETnnnYREQkJ+/btY9SoUdSrV0+FOQd1ziIi4sT27ds5cOAAY8eOpUSJEq7jhBR1ziIiEnTHjx/nP//5DxdffLEKcx7UOYuISFBt2rSJ7du38/zzz2OMcR0nJKlzFhGRoMnKyuLjjz/m+uuvV2E+DXXOIiISFKtWrWLt2rU8/fTTrqOEPHXOIiIScNnZ2SxdupQOHTq4jhIW1DmLiEhALVq0iKVLl/J///d/rqOEDXXOIiISMMnJySQlJdG1a1fXUcKKOmeJekePHuXuu+8mKSmpwGV37NgRhEQikSE+Pp5ly5bRq1cv11HCjoqzRL2EhATmzJnDpZdeSuXKlU+77EUXXcTdd98dpGQi4WvLli2UK1dOhfksqTiLeA0ePJjbbrvNdQyRsPfVV1+xefPmAq/gJvlTcRYREb+ZP38+l112GTfddJPrKGFNB4SJiIhffPPNN2zatIlKlSq5jhL21DmLiEihffLJJ7Rq1Yobb7zRdZSIoOIsUeHAgQOMGjWKI0eO5DlPRM7e4sWLSUlJoWzZsq6jRAwVZ4kKvXv35u233853c1udOnVo0KBBkFOJhL/JkyfTtm1bmjdv7jpKRFFxloi3bNkyJk+eTO/evRkzZozrOCIR49dff6Vs2bIFfgVRzpwOCJOIZq2lW7duVKpUiYEDB7qOIxIxXnnlFbKysrjjjjtcR4lI6pwlok2fPp2ffvqJSZMmaX+YiJ/s2bOHunXraldQAKlzloh1/Phx+vTpQ5MmTXjggQdcxxEJe9Zann/+eRITE2ndurXrOBFNnbOElT179vDpp5+SnZ1d4LI///wzO3fuZNq0aRQpUiQI6UQil7WWXbt20aJFC6644grXcSKeirOElVdeeYXhw4f7vPxDDz3EP/7xjwAmEol81lqGDx9Oq1atuOqqq1zHiQoqzhJWMjIyKF68ODt37vRp+QoVKgQ4kUhks9ayZs0a7r33Xi688ELXcaKGirOEHWMMFStWdB1DJCoMGTKE9u3bqzAHmYqziIj8SVZWFnPnzqVXr16UKVPGdZyoo6O1RUTkT8aMGUONGjVUmB1R5ywhb9OmTfzxxx8A7Nixw3EakciWkZHBu+++S9++fYmJUf/mioqzhLQjR45w0UUXkZWVdfK+8uXLO0wkEtmmTJnCddddp8LsmIqzhLSUlBSysrJ48sknufXWWwGoVauW41QikSc1NZUXXniBAQMGYIxxHSfq+VScjTE3AeOBIsAka+2oXPNrAm8Df/Eu089aO9u/USWaNWjQgOuvv951DJGIZK1lzpw5dO7cWYU5RBS43cIYUwR4BWgDNAI6GGMa5VpsIPChtbYJcA/wqr+DioiI/6WkpNCjRw9uueUWqlev7jqOePmyU+EKYIu1dqu1Nh2YDrTPtYwFTlxVIBbY7b+IIiISCCkpKWzZsoX+/ftTtKj2coYSX/4a1YCch8juBHJfVXsI8I0x5v+A0kCrvFZkjHkUeBSgcuXKxMfHn5x39OjRU6bFv8J1fA8ePAjA5s2bQzp/uI5vONDYBsbRo0d544036NixI+vXr2f9+vWuI0Wcwrx2/fVRqQMwxVr7gjHmKuAdY0xja+0pVyew1k4EJgI0bdrUxsXFnZwXHx9Pzmnxr3Ad37179wJQv379kM4fruMbDjS2/nfw4EF27NjBlClTWLVqlcY3QArz2vVls/YuoEaO6ere+3J6GPgQwFr7M1AS0EmNRURCzP79+xk0aBC1a9fmvPPOcx1H8uFLcV4K1DPG1DHGFMdzwNesXMskAtcDGGMa4inO+/wZVERECmfPnj3s2rWLUaNGERsb6zqOnEaBxdlamwl0Bb4GNuA5KnudMeZZY8yt3sV6Av8yxqwC3gcesNbaQIUWEZEzk5SUxLBhw6hbt65OyRkGfNrn7P3O8uxc9z2T4/Z64O/+jSYiIv6QmJjI7t27efHFFylRooTrOOIDnZ9NRCSCpaWlMX78eJo0aaLCHEb0xTYRkQj166+/smnTJp5//nmd+SvMqHMWEYlA1lo+/vhjbrrpJhXmMKTOWUQkwqxdu5Zly5bRv39/11HkLKlzFhGJINnZ2SxbtoxOnTq5jiKFoM5ZRCRCLFu2jPnz59OjRw/XUaSQ1DmLiESAw4cPc/DgQbp37+46iviBOmcJmLFjx/LDDz8Uah1paWl+SiMSuRYsWMDChQvp16+f6yjiJyrOEjD/+c9/OHbsGHXq1CnUeq666iquuuoqP6USiSybNm2iXLly9O3b13UU8SMVZwmo9u3b89Zbb7mOIRKR5s6dy+rVq7WPOQKpOIuIhKH58+dzySWX0KpVK9dRJAB0QJiISJiJj49n/fr1VKpUyXUUCRB1ziIiYeTTTz8lLi6OuLg411EkgNQ5i4iEiZUrV3LkyBHOO+8811EkwFScJSDWrFnDrl27qFq1qusoIhHhnXfeoXz58nTu3Nl1FAkCFWfxO2st3bt3JzY2VidEEPGDxMRESpQoQY0aNVxHkSBRcRa/mzVrFvPmzWPo0KGUL1/edRyRsPb666+TlJTE3Xff7TqKBJGKs/hVWloaPXv2pGHDhjz22GOu44iEtX379lGzZk0uvfRS11EkyHS0tvjV+PHjSUhI4KuvvqJYsWKu44iErXHjxtGsWTPatGnjOoo4oOIsfrNnzx6GDx/OzTffTOvWrV3HEQlL1lp27drF1VdfTfPmzV3HEUe0WVv8ZsaMGSQnJzNq1CjXUUTCkrWWkSNHsm3bNhXmKKfOWfwmIyMDgGrVqjlOIhJ+rLWsXLmSDh06FPpiMRL+1DmLiISA4cOHk5mZqcIsgDpnERGnsrOzmT17Nj169KB06dKu40iIUOcsIuLQiy++SK1atVSY5RTqnEVEHMjMzGTy5Mn07NkTY4zrOBJi1DmLiDjw7rvv0rJlSxVmyZM6ZxGRIEpLS2P06NEMGjRIhVnypc5ZRCRIrLXMnTuXzp07qzDLaak4i4gEwfHjx+nevTs33HADtWrVch1HQpyKs4hIgKWkpLBmzRr69etH8eLFXceRMKDiLCISQEeOHKFXr140aNCAKlWquI4jYUIHhImIBEhSUhKJiYk8++yzxMbGuo4jYUSds4hIABw8eJCBAwdSq1Ytypcv7zqOhBl1ziIifrZv3z527drFyJEjKVu2rOs4EobUOYuI+FFycjJDhw6lbt26Ksxy1tQ5i4j4ya5du9i2bRsvvviijsqWQlHnLCLiB5mZmYwfP56mTZuqMEuhqXMWESmkrVu3smrVKsaMGeM6ikQIdc4iIoVgrWXGjBncfPPNrqNIBFHnLCJyljZs2MCCBQvo3bu36ygSYdQ5i4ichaysLJYvX87DDz/sOopEIHXOIiJn6JdffuGbb76hb9++rqNIhFLnLCJyBpKSkkhKStKmbAkoFWcRER/99NNPvPLKK1x33XXExOjtUwJHry4RER9s2LCB8847j6efftp1FIkCKs4iIgX44Ycf+OKLL2jQoAHGGNdxJArogDARkdP44YcfaNCgAS1btnQdRaKIOmcRkXz89NNPrFmzhsqVK7uOIlFGnbOISB4+++wzrr76aq6++mrXUSQKqTgLKSkpTJ06laNHjxZqPfPnz/dTIhG31q9fz/79+6lYsaLrKBKlVJyj3L59+7j11ltZtGiRX9ZXqVIlSpUq5Zd1ibjw3nvvceWVV+rMX+KUinMU27x5M23atGH37t189NFHtG7dutDrLFmyJMWKFfNDOpHg27NnDzExMVx44YWuo0iUU3GOUgsWLOCf//wnRYoU4fvvv+fKK690HUnEqUmTJnHppZfSoUMH11FEdLR2NJo+fTqtWrWiQoUK/PzzzyrMEvUOHjzI+eefT7NmzVxHEQFUnKOKtZZRo0bRoUMHmjdvzs8//6zNdxL1JkyYwKpVq2jXrp3rKCInabN2BEtISGDr1q0ArFq1ivfee49JkybRoUMHJk+eTIkSJRwnFHFr586dNG/enObNm7uOInIKFecINW3aNB588EHS09NPuf/pp5/m2Wef1Un7JeqNGjWK5s2bc+2117qOIvInKs4RxlrLiBEjGDhwIC1btmTYsGHExMSwYsUKrr/+eho1auQ6oohT1lqWL1/OvffeS82aNV3HEcmTinMEycjI4PHHH+fNN9+kY8eOTJo06eSm64yMDBVmEWD06NG0bNlShVlCmopzhDhy5Ah33nkn3377LYMGDWLo0KG6eo5IDtnZ2Xz++ed069aNc845x3UckdNScY4AO3bsoF27dmzYsIG33nqLBx980HUkkZDzyiuv8I9//EOFWcKCinOYW7lyJe3atePo0aPMmTOHVq1auY4kElKysrJ444036Nq1q7YmSdhQcQ5j2dnZ3HjjjZQsWZIff/yRiy++2HUkkZDzwQcfEBcXp8IsYUXfpwljWVlZ7Nu3jy5duqgwi+SSnp7OkCFDuOeee2jQoIHrOCJnRMVZRCJOdnY2P/zwA507d9Z3+iUs6VUrIhElJSWF7t2706JFC+rUqeM6jshZ0T5nEYkYx48fZ8OGDfTp00dHZUtYU+csIhEhOTmZ3r17U7t2bapVq+Y6jkihqHMOQSNHjuSll14qcDlrLYCOQpWod/jwYbZv386QIUMoX7686zgihabiHIJ+/vlnsrKyuOuuuwpctkiRItx9991BSCUSmg4dOsSAAQMYPnw45cqVcx1HxC9UnENUzZo1ee2111zHEAlp+/fvJzExkZEjRxIbG+s6jojfaJ+ziISllJQUhgwZQr169VSYJeKocxaRsPP777+zYcMGxo0bR7FixVzHEfE7dc4iElays7N56aWXuPLKK1WYJWKpcw4BBw4c4JFHHiE5ORnwXMxC15oV+bPt27ezaNEiRo8e7TqKSED51DkbY24yxmwyxmwxxvTLZ5m7jTHrjTHrjDHT/Bszsq1evZqZM2eyd+9eUlNTadCgAffee6/rWCIh55NPPuH22293HUMk4ArsnI0xRYBXgBuAncBSY8wsa+36HMvUA/oDf7fWJhljKgUqcCR7+eWXadmypesYIiFn06ZNfPvtt/To0cN1FJGg8KVzvgLYYq3daq1NB6YD7XMt8y/gFWttEoC19g//xhSRaJWVlcWKFSt47LHHXEcRCRpfinM1YEeO6Z3e+3KqD9Q3xiw0xiwyxtzkr4AiEr1Wr17NtGnT6NChA0WL6hAZiR7+erUXBeoBcUB1YL4x5mJr7aGcCxljHgUeBahcuTLx8fEn5x09evSU6WiycuVKAH755ZeTp+T0t2ge32DQ+Prf4cOH2bZtG+3bt9fYBpBeu4FTmLH1pTjvAmrkmK7uvS+nncBia20GsM0YsxlPsV6acyFr7URgIkDTpk1tXFzcyXnx8fHknI40+/fv54UXXiAtLe1P83bs8GyYaNKkScD2OUf6+Lqm8fWvJUuW8P333zN06FCNbYBpfAOnMGPrS3FeCtQzxtTBU5TvAXIfSjwT6ABMNsZUwLOZe+tZJYpQc+bMYdSoUZQuXTrPi79XrVqV2rVrBz+YSIhZt24dsbGxDBkyxHUUEWcKLM7W2kxjTFfga6AI8Ja1dp0x5llgmbV2lnfejcaY9UAW0NtaeyCQwcPNic3Vq1ev5oILLnCcRiQ0LVy4kPnz59OvXz9dbU2imk/7nK21s4HZue57JsdtC/Tw/oiInLH58+dTv359rr76ahVmiXo6faeIOLds2TJWrFhBlSpVVJhFUHEWEcc+//xzqlatylNPPeU6ikjI0BcHC+m7774jMTGxwOUWLlwYhDQi4SUhIYHff/+dqlWruo4iElJUnAshNTWVG264gezsbJ+WL168uK47K+L1wQcfcPHFF/Poo4+6jiISclScCyErK4vs7Gz69etHly5dCly+bNmylCtXLgjJRELbgQMHyMzMpFGjRq6jiIQkFWc/KFeunL6jLOKjKVOmULduXe677z7XUURClg4IE5GgOXz4MBUrVqRFixauo4iENHXOIhIUr776KnXr1qVdu3auo4iEPBVnEQm4HTt20KxZM5o1a+Y6ikhY0GZtEQmoF154gY0bN6owi5wBdc4iEhDWWpYsWcI999xDtWq5LwEvIqejzllEAuLFF18kMzNThVnkLKhzFhG/stby6aef8u9//5uSJUu6jiMSltQ5i4hfTZw4kVq1aqkwixSCOmcR8YusrCxeffVVunbtqitLiRSSOmcR8YtPPvmE6667ToVZxA9UnEWkUDIyMhg0aBC33XYbF110kes4IhFBxVlEzlp2djYLFy6kc+fOFC2qvWQi/qLiLCJnJTU1le7du3P55ZdTt25d13FEIoo+6orIGUtJSWHTpk306tWLMmXKuI4jEnHUOYvIGTl27Bi9e/ematWq1KhRw3UckYikzvkMTZ06ldGjR2OtJTs723UckaBKTk5m27ZtDBo0iEqVKrmOIxKx1DmfgV27dvHEE09gjKFx48ZccskldOjQgZtvvtl1NJGAS05Opl+/flStWpXKlSu7jiMS0dQ5n4H+/fuTkZHBrFmzuOCCC1zHEQmagwcPsnXrVkaMGEFsbKzrOCIRT52zjxYvXsw777xDz549VZglqqSnp/PMM89Qr149FWaRIFHn7IPs7Gy6detGlSpV6N+/v+s4IkGzd+9eVq5cyUsvvaTvMYsEkTpnH0ybNo3FixczatQofW1Eooa1lgkTJtCiRQsVZpEg0/+4AqSmptK3b1+aNWvG/fff7zqOSFDs2LGD+Ph4nnvuOddRRKKSOucCbNu2jd27d9O1a1diYjRcEh1mzpzJXXfd5TqGSNRS5+yjEiVKuI4gEnAJCQnMmjWL7t27u44iEtXUCooI4Lm61IoVK+jatavrKCJRT52ziLBu3To+/PBDhg4d6jqKiKDOWSTq/fHHHxw6dIhnnnnGdRQR8VLnnIfly5fz1VdfAZ43LpFItXz5cj799FOGDRuGMcZ1HBHxUnHOwzPPPMPs2bNPThcvXpxatWo5TCTif2vXrqVMmTIqzCIhSJu185CVlUWzZs1IT08nPT2dY8eOceWVV7qOJeI3S5YsYebMmdSrV0+FWSQEqXPOR0xMDMWKFXMdQ8TvFixYwIUXXsjTTz+twiwSotQ5i0SR1atXs2TJEqpWrarCLBLCVJxFosTs2bOJjY2lZ8+erqOISAFUnEWiwI4dO9i+fbsObBQJEyrOIhHu448/5sCBAzzxxBOuo4iIj1ScRSLY4cOHSUlJ4W9/+5vrKCJyBnS0tkiEeuedd6hWrZoudSoShtQ5i0SgI0eOUL58ea677jrXUUTkLKhzFokwr7/+OtWrV6ddu3auo4jIWVJxFokgv/32G02bNuXyyy93HUVECkGbtXOx1rJnzx6KFtXnFgkv48ePZ/369SrMIhFAFSiXDz/8kFWrVvH666+7jiLiE2stP/30E3fffTfnn3++6zgi4gfqnHNISUmhT58+XHrppTz88MOu44j4ZMKECWRmZqowi0QQdc45PP/88yQmJjJ16lSKFCniOo7IaVlr+eijj3jssccoUaKE6zgi4kfqnL127tzJqFGjuPPOO2nZsqXrOCIFmjx5MrVq1VJhFolA6py9+vXrR1ZWFmPHjnUdReS0srOzmTBhAt26ddOVpUQilDpnYN26dbz33nv06tWL2rVru44jclpffPEF1113nQqzSARTccazSRugbdu2jpOI5C8zM5NBgwbRunVrLrnkEtdxRCSAVJxzUCcioSorK4slS5Zw//33ax+zSBRQcRYJcenp6fTq1YuGDRtSv35913FEJAh0QJhICEtNTWXz5s089dRTnHfeea7jiEiQqHMWCVHHjx+nd+/eVKxYkVq1armOIyJBpM5ZJAQdO3aMhIQEBgwYoDN/iUQhdc4iIebYsWP06dOHKlWqqDCLRCl1ziIh5NChQ2zatIkRI0YQGxvrOo6IOKLOWSREZGZm8swzz1C/fn0VZpEop85ZJATs27ePxYsXM27cOF10RUTUOYu4Zq3l5ZdfJi4uToVZRAB1ziJO7dq1i6+//pqhQ4e6jiIiIUSds4gj1lpmzZpFhw4dXEcRkRCjzlnEgW3btvHBBx/Qr18/11FEJASpcxYJsrS0NFauXEmPHj1cRxGREKXiLBJEGzZsYOjQodx2220UL17cdRwRCVEqziJBsmfPHg4fPsywYcNcRxGREKfiLBIEK1euZPz48VxxxRX6upSIFEjFWSTA1q5dS+nSpXnuueeIidF/OREpmN4pRAJoxYoVfPzxx9StW1eFWUR8pncLkQBZuHAhFSpUYPDgwRhjXMcRkTCi4iwSABs3buTHH3+kRo0aKswicsZUnEX87JtvviEmJoa+ffuqMIvIWfGpOBtjbjLGbDLGbDHG5HtKI2PMHcYYa4xp6r+IIuFj7969bNy4kfr167uOIiJhrMDibIwpArwCtAEaAR2MMY3yWK4M0A1Y7O+QIuFg5syZbN++nSeffNJ1FBEJc750zlcAW6y1W6216cB0oH0eyw0DRgOpfswnEhZSUlI4cuQIzZs3dx1FRCKAL8W5GrAjx/RO730nGWMuA2pYa7/0YzaRsPD++++zZs0aOnXq5DqKiESIQl+VyhgTA7wIPODDso8CjwJUrlyZ+Pj4k/OOHj16ynQwrVq1CvB8JzUtLc1JhkBzOb6R7NixY/z22280btxY4xsgeu0GlsY3cAoztr4U511AjRzT1b33nVAGaAzEe49MrQLMMsbcaq1dlnNF1tqJwESApk2b2ri4uJPz4uPjyTkdTCcK8mWXXcZVV13lJEOguRzfSPXWW29Rrlw5+vXrp/ENII1tYGl8A6cwY+tLcV4K1DPG1MFTlO8B7j0x01p7GKhwYtoYEw/0yl2YRSLJ1q1bueyyy/jb3/7mOoqIRKAC9zlbazOBrsDXwAbgQ2vtOmPMs8aYWwMdMBgOHDgAoNMrik9eeeUV1q1bp8IsIgHj0z5na+1sYHau+57JZ9m4wscKnoyMDIYNG8aFF16oN1sp0IIFC7jrrruoVKmS6ygiEsEKfUBYuHvttdfYuHEjn332GSVKlHAdR0LYa6+9xl//+lcVZhEJuKguzvv372fw4MG0atWKW265xXUcCVHWWqZPn84jjzxCsWLFXMcRkSgQ1TtZBw8eTHJyMuPGjdM5kCVf06ZNo3bt2irMIhI0Uds5r1mzhv/+9788/vjjNG7c2HUcCUHZ2dm89NJLdOvWjSJFiriOIyJRJCo7Z2st3bt3JzY2lqFDh7qOIyHqm2++4dprr1VhFpGgi8riPGvWLObNm8fQoUMpX7686zgSYrKyshg4cCDXXHMNTZo0cR1HRKJQ1BXntLQ0evbsScOGDXnsscdcx5EQk5WVxYoVK7jvvvsoVaqU6zgiEqWirjiPHz+ehIQExo0bpwN85BQZGRn07t2bWrVq0bBhQ9dxRCSKRdUBYXv27GH48OHcfPPNtG7d2nUcCSFpaWn8+uuvdO3aVd9jFhHnoqpzfvrpp0lNTeWFF15wHUVCSGpqKr179+Yvf/kLF1xwges4IiLRU5xXr17N5MmTefLJJ6lfv77rOBIijh8/zubNm+nXrx/Vq1d3HUdEBIii4rxkyRKstfz73/92HUVCRGpqKn369KFSpUpUrVrVdRwRkZOiap8zoIPABIAjR46wZs0aRowYQdmyZV3HERE5RdR0ziInZGdnM2jQIBo0aKDCLCIhKeo6Z4luBw4cYP78+YwbN07X7xaRkKV3J4kqr776Ktdff70Ks4iENHXOEhX27NnDZ599xqBBg1xHEREpUNS0D99++y3nnHMOsbGxrqNIkFlr+fzzz7n//vtdRxER8UlUdM4LFizgww8/ZMiQIZQpU8Z1HAmi3377jalTp6pjFpGwEvGdc1ZWFt26daNGjRr07t3bdRwJotTUVFavXk2fPn1cRxEROSMR3zlPmTKFX375hffff19XGYoimzdvZtKkSYwePRpjjOs4IiJnJKI75yNHjjBgwAD+/ve/8//+3/9zHUeCZPfu3Rw+fJgRI0aoMItIWIqozjklJYWvvvqKzMxMAL744gv27dvH7Nmz9SYdJdasWcO7777LiBEjKFKkiOs4IiJnJaKK8/3338+MGTNOua9Lly5cfvnljhJJMK1du5aSJUsycuRIfY9ZRMJaxBTn+Ph4ZsyYQd++fU9+ZSYmJoYGDRo4TibBsHbt2pNH5Kswi0i4i4jifOKI7Fq1ajF48GDOOecc15EkiH7++WeqVKnC0KFDtftCRCJCRLQYkyZNYvXq1YwdO1aFOcps3bqV77//ntq1a6swi0jECPvifOjQIQYOHMg111zDnXfe6TqOBNG8efM4fvw4/fv3V2EWkYgSdpu1s7Oz2bJlC9ZaACZMmMCBAwd46aWX9AYdRQ4ePMjatWu5/vrrXUcREfG7sCvO9957Lx988MEp9z3yyCM0adLEUSIJti+++ILY2Fi6devmOoqISECEVXGeO3cuH3zwAY899hjXXHMNACVKlODmm292nEyCJTU1lYMHD+pvLiIRLWyKc2ZmJk899RR16tRh3LhxlCxZ0nUkCbIPP/yQkiVL0qlTJ9dRREQCKmyK88SJE1m3bh0zZsxQYY5CR44coWzZstx0002uo4iIBFxYFOeDBw8yaNAg4uLiuO2221zHkSB7++23KVWqFHfddZfrKCIiQREWxXno0KEcOnRIR2RHoV9//ZXLLruMiy++2HUUEZGgCcni3L17d1599dWT0+np6XTp0oVLL73UYSoJttdff50qVarQvn1711FERIIqJIvzqlWrqFSpEh07dgSgTJkydO3a1XEqCabvv/+eO+64gwoVKriOIiISdCFZnAHq1KnDyJEjXccQByZNmkTNmjVVmEUkaoVscZboY63l3Xff5YEHHqBoUb00RSR6hf25tSVyfPzxx9SuXVuFWUSint4FxTlrLS+++CJPPvkkxYoVcx1HRMQ5dc7i3Pfff0/Lli1VmEVEvFScxZns7GwGDhxI06ZNadq0qes4IiIhQ5u1xYmsrCzWrFnDPffcQ9myZV3HEREJKeqcJegyMjLo27cvFStWpHHjxq7jiIiEHHXOElTp6els2bKFLl26UK1aNddxRERCkjpnCZq0tDT69OlDqVKlqFevnus4IiIhS52zBEVKSgqbN2+md+/e6phFRAoQcp2ztZaEhAQqVqzoOor4SUZGBr1796ZChQoqzCIiPgi54rx+/XoSExO56aabXEcRP0hOTuann35i5MiRKswiIj4KueI8e/ZsANq0aeM4iRSWtZYhQ4bQqFEjypQp4zqOiEjYCLl9znPmzOHiiy+mevXqrqNIISQlJfHtt98yduxYYmJC7jOgiEhIC6l3zSNHjrBgwQLatm3rOooU0sSJE7nxxhtVmEVEzkJIdc5z584lMzNTm7TD2B9//MGHH35I3759XUcREQlbIdXWzJkzh7Jly3L11Ve7jiJnwVrLl19+yYMPPug6iohIWAuZztlay+zZs7nxxht1daIwtHPnTiZOnMizzz7rOoqISNgLmc45ISGB3bt3a5N2GEpJSWHt2rUMGDDAdRQRkYgQMsV5yZIlAPp+c5hJSEjg6aefpnXr1pQsWdJ1HBGRiBAyxXnx4sU0adKEqlWruo4iPtq5cyeHDx9m9OjRGGNcxxERiRghUZwPHTrE2rVrtUk7jGzYsIEJEyZwySWX6BgBERE/C4nivHjxYrKzs7n++utdRxEfrFu3jqJFizJy5EiKFg2ZYwpFRCJGSBTnjIwMAMqWLes4iRRk48aNTJs2jQsvvJAiRYq4jiMiEpFCojhLeFiyZAlFihRh+PDhOvOXiEgA6R1WfLJz506++uor6tatq4O/REQCTDsMpUA//PADZcqUYdCgQSrMIiJBoM5ZTis5OZlffvmFJk2aqDCLiASJOmfJ15w5cyhWrBhPPfWU6ygiIlFFnbPkKT09nX379tGqVSvXUUREoo46Z/mTTz75hOzsbDp16uQ6iohIVFJxllMcPnyYc889lxtvvNF1FBGRqKXiLCe9++67xMTEcO+997qOIiIS1VScBfCc+euyyy6jUaNGrqOIiEQ9HRAmvPnmm6xbt06FWUQkRKhzjnLz5s3jtttuo1y5cq6jiIiIlzrnKDZ16lTS0tJUmEVEQow65yg1depU7r33Xl3yUUQkBKlzjkKzZs2iZs2aKswiIiHKp+JsjLnJGLPJGLPFGNMvj/k9jDHrjTGrjTHzjDG1/B9VCstaywsvvEDr1q2Ji4tzHUdERPJRYHE2xhQBXgHaAI2ADsaY3If1/gI0tdZeAnwMjPF3UCm8hQsX0qJFC0qUKOE6ioiInIYvnfMVwBZr7VZrbTowHWifcwFr7ffW2uPeyUVAdf/GlMLIzs7mrbfeomHDhjRv3tx1HBERKYAvOx2rATtyTO8ETvcO/zAwJ68ZxphHgUcBKleuTHx8PABr1qwBYPny5Rw9etSHSOKrrKwsEhMTadas2clxFv87evToydez+JfGNrA0voFTmLH16xFBxpiOQFOgZV7zrbUTgYkATZs2tSf2e54oyJdffjlNmzb1Z6SolpmZyYABA/j3v//Ntm3btJ85gOLj4zW+AaKxDSyNb+AUZmx92ay9C6iRY7q6975TGGNaAU8Dt1pr084qjfhNRkYGW7Zs4eGHH6ZWLR2fJyISTnwpzkuBesaYOsaY4sA9wKycCxhjmgCv4ynMf/g/ppyJ9PR0+vTpQ7FixfjrX//qOo6IiJyhAjdrW2szjTFdga+BIsBb1tp1xphngWXW2lnAWOBc4CNjDECitfbWAOaWfKSmprJx40Z69epFtWrVXMcREZGz4NM+Z2vtbGB2rvueyXG7lZ9zyVnIysqiT58+9O7dW4VZRCSM6RRREeLYsWMsWrSIkSNHUrp0addxRESkEHT6zgjx7LPP0rhxYxVmEZEIoM45zB06dIgvv/ySUaNG4d3fLyIiYU6dc5h78803adOmjQqziEgEUeccpvbv38/UqVPp2bOn6ygiIuJn6pzDkLWWr776in/961+uo4iISACoOIeZ3bt3M2DAADp27EiZMmVcxxERkQBQcQ4jx44dY/369TzzzDMFLywiImFLxTlMbN++nQEDBnDddddxzjnnuI4jIiIBpOIcBnbu3MmhQ4cYO3YsMTH6k4mIRDq904e4zZs3M27cOC666CKKFy/uOo6IiASBinMIW79+PQCjR4+mWLFijtOIiEiwqDiHqISEBKZOncqFF15I0aL6OrqISDRRcQ5By5cvJy0tjREjRlCkSBHXcUREJMhUnEPMH3/8weeff07Dhg118JeISJTS9tIQ8uOPP1K0aFGGDBniOoqIiDik1ixEpKSksHTpUpo3b+46ioiIOKbOOQR8++23pKen0717d9dRREQkBKhzdiwjI4O9e/fSrl0711FERCREqHN2aNasWRw9epSOHTu6jiIiIiFExdmRpKQkSpcuza233uo6ioiIhBgVZwemT59Oeno6nTp1ch1FRERCkIpzkK1bt44mTZrw17/+1XUUEREJUTogLIimTp3KunXrVJhFROS01DkHyTfffEP79u2JjY11HUVEREKcOucgmD59OmlpaSrMIiLiE3XOATZlyhTuu+8+XfJRRER8ps45gL766iuqV6+uwiwiImdEnXMAWGt54YUXePzxxyldurTrOCIiEmbUOfuZtZalS5dy1VVXqTCLiMhZUXH2o+zsbAYPHkzNmjX5+9//7jqOiIiEKRVnP8nOzmbz5s3885//pEqVKq7jiIhIGFNx9oOsrCz69+9P0aJFueyyy1zHERGRMKcDwgopMzOThIQEHnzwQerWres6joiIRAB1zoWQkZFBnz59MMbQoEED13FERCRCqHM+S2lpaaxbt46ePXtSrVo113FERCSCqHM+C9nZ2fTt25fy5curMIuIiN+pcz5Dx48fZ/78+YwcOZJzzjnHdRwREYlA6pzP0HPPPcell16qwiwiIgGjztlHR44c4dNPP2X48OEYY1zHERGRCKbO2UeTJ0+mXbt2KswiIhJw6pwLcPDgQSZNmkSfPn1cRxERkSihzvk0srOz+fbbb+nSpYvrKCIiEkVUnPOxZ88e+vbty913301sbKzrOCIiEkVUnPOQnJzMxo0bGTJkiPYxi4hI0Kk455KYmMiAAQNo0aKFrscsIiJOqDjnsGPHDg4dOsTzzz9P0aI6Vk5ERNxQcfZKSEhg3LhxNGjQgBIlSriOIyIiUUztIbBx40YARo8eTbFixRynERGRaBf1nXNiYiKTJ0+mXr16KswiIhISorpzXrlyJTExMYwcOZKYmKj/nCIiIiEiaivSoUOH+PTTT2ncuLEKs4iIhJSo7JwXLVpEeno6Q4cOdR1FRETkT6KuZUxPT+fnn3/mH//4h+soIiIieYqqzvm7777j0KFDdO/e3XUUERGRfEVN55yRkcHvv//O7bff7jqKiIjIaUVF5/zll1+yb98+HnjgAddRREREChTxxXn//v2ULl2adu3auY4iIiLik4guzh999BHJyck89NBDrqOIiIj4LGKL8+rVq2nSpAl169Z1HUVEROSMROQBYe+//z5r1qxRYRYRkbAUcZ3znDlzaNeuHWXLlnUdRURE5KxEVHGeMWMGMTExKswiIhLWIqY4T5kyhQ4dOuhazCIiEvYiYp/zd999R5UqVVSYRUQkIoR152yt5cUXX+SRRx4hNjbWdRwRERG/CNvO2VrL6tWradasmQqziIhElLAsztZahg0bxnnnncc111zjOo6IiIhfhd1m7ezsbLZu3UqbNm2oWbOm6zgiIiJ+F1adc3Z2NgMHDiQjI4NmzZq5jiMiIhIQYdM5Z2VlkZCQQMeOHWnYsKHrOCIiIgETFp1zZmYmffv2JSsri0aNGrmOIyIiElAh3zlnZGSwatUqevbsyfnnn+86joiISMCFdOdsraVfv36UK1dOhVlERKJGyHbOqampzJ07l+eee46SJUu6jiMiIhI0Ids5jxkzhiZNmqgwi4hI1PGpOBtjbjLGbDLGbDHG9MtjfgljzAfe+YuNMbXPNtDRo0d58803GTRoENWqVTvb1YiIiIStAouzMaYI8ArQBmgEdDDG5D5k+mEgyVpbFxgHjD7bQO+88w633norxpizXYWIiEhY86VzvgLYYq3daq1NB6YD7XMt0x5423v7Y+B6cxbV9a233uLxxx+nYsWKZ/qrIiIiEcOX4lwN2JFjeqf3vjyXsdZmAoeB8mca5q677jrTXxEREYk4QT1a2xjzKPAoQOXKlYmPjwc832UePHgwx44dO3mf+NfRo0c1tgGk8Q0cjW1gaXwDpzBj60tx3gXUyDFd3XtfXsvsNMYUBWKBA7lXZK2dCEwEaNq0qY2Lizs577zzziPntPhXfHy8xjeANL6Bo7ENLI1v4BRmbH3ZrL0UqGeMqWOMKQ7cA8zKtcwsoLP39p3Ad9Zae1aJREREolyBnbO1NtMY0xX4GigCvGWtXWeMeRZYZq2dBbwJvGOM2QIcxFPARURE5CwYVw2uMWYf8FuOuyoA+52EiQ4a38DS+AaOxjawNL6Bk3tsa1lrffo6krPinJsxZpm1tqnrHJFK4xtYGt/A0dgGlsY3cAoztiF7+k4REZFopeIsIiISYkKpOE90HSDCaXwDS+MbOBrbwNL4Bs5Zj23I7HMWERERj1DqnEVERAQHxTmYl5+MRj6Mbw9jzHpjzGpjzDxjTC0XOcNRQWObY7k7jDHWGKMjYM+AL+NrjLnb+/pdZ4yZFuyM4cqH94WaxpjvjTG/eN8b2rrIGY6MMW8ZY/4wxqzNZ74xxkzwjv1qY8xlPq3YWhu0HzwnMUkALgCKA6uARrmWeQL4r/f2PcAHwcwYzj8+ju+1QCnv7cc1vv4bW+9yZYD5wCKgqevc4fLj42u3HvALcJ53upLr3OHw4+PYTgQe995uBGx3nTtcfoBrgMuAtfnMbwvMAQxwJbDYl/UGu3MO2uUno1SB42ut/d5ae9w7uQjPudKlYL68dgGG4bmeeWoww0UAX8b3X8Ar1tokAGvtH0HOGK58GVsLlPXejgV2BzFfWLPWzsdzZsz8tAemWo9FwF+MMecXtN5gF+egXX4ySvkyvjk9jOcTnRSswLH1bq6qYa39MpjBIoQvr936QH1jzEJjzCJjzE1BSxfefBnbIUBHY8xOYDbwf8GJFhXO9H0ZCPIlIyV0GGM6Ak2Blq6zRAJjTAzwIvCA4yiRrCieTdtxeLb4zDfGXGytPeQyVIToAEyx1r5gjLkKz7USGltrs10Hi1bB7pzP5PKTnO7yk5InX8YXY0wr4GngVmttWpCyhbuCxrYM0BiIN8Zsx7NvaZYOCvOZL6/dncAsa22GtXYbsBlPsZbT82VsHwY+BLDW/gyUxHNeaCk8n96Xcwt2cdblJwOrwPE1xjQBXsdTmLXPznenHVtr7WFrbQVrbW1rbW08+/NvtdYucxM37Pjy3jATT9eMMaYCns3cW4OYMVz5MraJwPUAxpiGeIrzvqCmjFyzgE7eo7avBA5ba38v6JeCulnb6vKTAeXj+I4FzgU+8h5nl2itvdVZ6DDh49jKWfJxfL8GbjTGrAeygN7WWm1VK4CPY9sTeMMY0x3PwWEPqCnyjTHmfTwfGit499kPBooBWGv/i2cffltgC3AceNCn9Wr8RUREQovOECYiIhJiVJxFRERCjIqziIhIiFFxFhERCTEqziIiIiFGxVlERCTEqDiLiIiEGBVnERGREPP/AV7/z/CtxdJNAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_roc(y_test, y_pred, model_name):\n",
    "    fpr, tpr, thr = roc_curve(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(fpr, tpr, 'k-')\n",
    "    ax.plot([0, 1], [0, 1], 'k--', linewidth=.5)  # roc curve for random model\n",
    "    ax.grid(True)\n",
    "    ax.set(title='ROC Curve for {} on PIMA diabetes problem'.format(model_name),\n",
    "           xlim=[-0.01, 1.01], ylim=[-0.01, 1.01])\n",
    "plot_roc(y_test, y_pred_prob_rf[:, 1], 'RF')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Single Hidden Layer Neural Network\n",
    "\n",
    "We will use the Sequential model to quickly build a neural network.  Our first network will be a single layer network.  We have 8 variables, so we set the input shape to 8.  Let's start by having a single hidden layer with 12 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## First let's normalize the data\n",
    "## This aids the training of neural nets by providing numerical stability\n",
    "## Random Forest does not need this as it finds a split only, as opposed to performing matrix multiplications\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X_train_norm = normalizer.fit_transform(X_train)\n",
    "X_test_norm = normalizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model \n",
    "# Input size is 8-dimensional\n",
    "# 1 hidden layer, 12 hidden nodes, sigmoid activation\n",
    "# Final layer has just one node with a sigmoid activation (standard for binary classification)\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(12,input_shape = (8,),activation = 'sigmoid'))\n",
    "model_1.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                108       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 13        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#  This is a nice tool to view the model you have created and count the parameters\n",
    "\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comprehension question:\n",
    "Why do we have 121 parameters?  Does that make sense?\n",
    "\n",
    "Let's fit our model for 200 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "18/18 [==============================] - 1s 21ms/step - loss: 1.0618 - accuracy: 0.3455 - val_loss: 1.0002 - val_accuracy: 0.3594\n",
      "Epoch 2/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0210 - accuracy: 0.3455 - val_loss: 0.9636 - val_accuracy: 0.3594\n",
      "Epoch 3/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9834 - accuracy: 0.3455 - val_loss: 0.9300 - val_accuracy: 0.3594\n",
      "Epoch 4/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9489 - accuracy: 0.3455 - val_loss: 0.8993 - val_accuracy: 0.3594\n",
      "Epoch 5/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.9174 - accuracy: 0.3455 - val_loss: 0.8714 - val_accuracy: 0.3594\n",
      "Epoch 6/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8887 - accuracy: 0.3438 - val_loss: 0.8460 - val_accuracy: 0.3594\n",
      "Epoch 7/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8626 - accuracy: 0.3490 - val_loss: 0.8230 - val_accuracy: 0.3646\n",
      "Epoch 8/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8389 - accuracy: 0.3507 - val_loss: 0.8022 - val_accuracy: 0.3646\n",
      "Epoch 9/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.8174 - accuracy: 0.3507 - val_loss: 0.7834 - val_accuracy: 0.3750\n",
      "Epoch 10/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7980 - accuracy: 0.3524 - val_loss: 0.7665 - val_accuracy: 0.4115\n",
      "Epoch 11/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7804 - accuracy: 0.3628 - val_loss: 0.7512 - val_accuracy: 0.4219\n",
      "Epoch 12/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7645 - accuracy: 0.3750 - val_loss: 0.7375 - val_accuracy: 0.4271\n",
      "Epoch 13/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7502 - accuracy: 0.3924 - val_loss: 0.7252 - val_accuracy: 0.4375\n",
      "Epoch 14/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7373 - accuracy: 0.4010 - val_loss: 0.7141 - val_accuracy: 0.4427\n",
      "Epoch 15/200\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.7257 - accuracy: 0.4219 - val_loss: 0.7042 - val_accuracy: 0.4479\n",
      "Epoch 16/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7152 - accuracy: 0.4479 - val_loss: 0.6953 - val_accuracy: 0.4688\n",
      "Epoch 17/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7058 - accuracy: 0.4896 - val_loss: 0.6873 - val_accuracy: 0.5000\n",
      "Epoch 18/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6973 - accuracy: 0.5278 - val_loss: 0.6800 - val_accuracy: 0.5156\n",
      "Epoch 19/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6896 - accuracy: 0.5747 - val_loss: 0.6736 - val_accuracy: 0.5781\n",
      "Epoch 20/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6827 - accuracy: 0.6076 - val_loss: 0.6678 - val_accuracy: 0.6146\n",
      "Epoch 21/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6764 - accuracy: 0.6146 - val_loss: 0.6625 - val_accuracy: 0.6562\n",
      "Epoch 22/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.6319 - val_loss: 0.6578 - val_accuracy: 0.6562\n",
      "Epoch 23/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6656 - accuracy: 0.6406 - val_loss: 0.6535 - val_accuracy: 0.6510\n",
      "Epoch 24/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.6441 - val_loss: 0.6497 - val_accuracy: 0.6562\n",
      "Epoch 25/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6567 - accuracy: 0.6510 - val_loss: 0.6462 - val_accuracy: 0.6667\n",
      "Epoch 26/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.6545 - val_loss: 0.6431 - val_accuracy: 0.6823\n",
      "Epoch 27/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.6493 - val_loss: 0.6402 - val_accuracy: 0.6615\n",
      "Epoch 28/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.6615 - val_loss: 0.6376 - val_accuracy: 0.6667\n",
      "Epoch 29/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6433 - accuracy: 0.6615 - val_loss: 0.6353 - val_accuracy: 0.6667\n",
      "Epoch 30/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6407 - accuracy: 0.6615 - val_loss: 0.6331 - val_accuracy: 0.6719\n",
      "Epoch 31/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.6615 - val_loss: 0.6311 - val_accuracy: 0.6667\n",
      "Epoch 32/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6360 - accuracy: 0.6615 - val_loss: 0.6294 - val_accuracy: 0.6615\n",
      "Epoch 33/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6339 - accuracy: 0.6667 - val_loss: 0.6277 - val_accuracy: 0.6615\n",
      "Epoch 34/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.6615 - val_loss: 0.6262 - val_accuracy: 0.6615\n",
      "Epoch 35/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6303 - accuracy: 0.6615 - val_loss: 0.6248 - val_accuracy: 0.6719\n",
      "Epoch 36/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.6667 - val_loss: 0.6235 - val_accuracy: 0.6719\n",
      "Epoch 37/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6272 - accuracy: 0.6684 - val_loss: 0.6223 - val_accuracy: 0.6719\n",
      "Epoch 38/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6258 - accuracy: 0.6701 - val_loss: 0.6212 - val_accuracy: 0.6667\n",
      "Epoch 39/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.6719 - val_loss: 0.6202 - val_accuracy: 0.6823\n",
      "Epoch 40/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.6736 - val_loss: 0.6192 - val_accuracy: 0.6875\n",
      "Epoch 41/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.6736 - val_loss: 0.6183 - val_accuracy: 0.6875\n",
      "Epoch 42/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6210 - accuracy: 0.6719 - val_loss: 0.6175 - val_accuracy: 0.6875\n",
      "Epoch 43/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.6736 - val_loss: 0.6167 - val_accuracy: 0.6875\n",
      "Epoch 44/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6190 - accuracy: 0.6701 - val_loss: 0.6159 - val_accuracy: 0.6875\n",
      "Epoch 45/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.6684 - val_loss: 0.6152 - val_accuracy: 0.6823\n",
      "Epoch 46/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.6684 - val_loss: 0.6145 - val_accuracy: 0.6875\n",
      "Epoch 47/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.6649 - val_loss: 0.6139 - val_accuracy: 0.6875\n",
      "Epoch 48/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6157 - accuracy: 0.6632 - val_loss: 0.6132 - val_accuracy: 0.6875\n",
      "Epoch 49/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6150 - accuracy: 0.6615 - val_loss: 0.6126 - val_accuracy: 0.6875\n",
      "Epoch 50/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6143 - accuracy: 0.6632 - val_loss: 0.6121 - val_accuracy: 0.6875\n",
      "Epoch 51/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.6649 - val_loss: 0.6115 - val_accuracy: 0.6875\n",
      "Epoch 52/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6129 - accuracy: 0.6649 - val_loss: 0.6110 - val_accuracy: 0.6875\n",
      "Epoch 53/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.6649 - val_loss: 0.6105 - val_accuracy: 0.6875\n",
      "Epoch 54/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6117 - accuracy: 0.6649 - val_loss: 0.6099 - val_accuracy: 0.6875\n",
      "Epoch 55/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6111 - accuracy: 0.6649 - val_loss: 0.6095 - val_accuracy: 0.6875\n",
      "Epoch 56/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6105 - accuracy: 0.6632 - val_loss: 0.6090 - val_accuracy: 0.6875\n",
      "Epoch 57/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6100 - accuracy: 0.6632 - val_loss: 0.6085 - val_accuracy: 0.6875\n",
      "Epoch 58/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6094 - accuracy: 0.6615 - val_loss: 0.6080 - val_accuracy: 0.6875\n",
      "Epoch 59/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6089 - accuracy: 0.6615 - val_loss: 0.6076 - val_accuracy: 0.6875\n",
      "Epoch 60/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6084 - accuracy: 0.6615 - val_loss: 0.6072 - val_accuracy: 0.6875\n",
      "Epoch 61/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6079 - accuracy: 0.6615 - val_loss: 0.6067 - val_accuracy: 0.6875\n",
      "Epoch 62/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.6649 - val_loss: 0.6063 - val_accuracy: 0.6875\n",
      "Epoch 63/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.6649 - val_loss: 0.6059 - val_accuracy: 0.6875\n",
      "Epoch 64/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6064 - accuracy: 0.6649 - val_loss: 0.6054 - val_accuracy: 0.6875\n",
      "Epoch 65/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6059 - accuracy: 0.6649 - val_loss: 0.6050 - val_accuracy: 0.6875\n",
      "Epoch 66/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6054 - accuracy: 0.6649 - val_loss: 0.6046 - val_accuracy: 0.6875\n",
      "Epoch 67/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.6649 - val_loss: 0.6042 - val_accuracy: 0.6875\n",
      "Epoch 68/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6046 - accuracy: 0.6649 - val_loss: 0.6038 - val_accuracy: 0.6875\n",
      "Epoch 69/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6041 - accuracy: 0.6649 - val_loss: 0.6034 - val_accuracy: 0.6875\n",
      "Epoch 70/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6037 - accuracy: 0.6649 - val_loss: 0.6030 - val_accuracy: 0.6875\n",
      "Epoch 71/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6032 - accuracy: 0.6649 - val_loss: 0.6026 - val_accuracy: 0.6875\n",
      "Epoch 72/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6028 - accuracy: 0.6667 - val_loss: 0.6022 - val_accuracy: 0.6875\n",
      "Epoch 73/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6024 - accuracy: 0.6667 - val_loss: 0.6019 - val_accuracy: 0.6875\n",
      "Epoch 74/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6019 - accuracy: 0.6667 - val_loss: 0.6015 - val_accuracy: 0.6927\n",
      "Epoch 75/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6015 - accuracy: 0.6667 - val_loss: 0.6011 - val_accuracy: 0.6927\n",
      "Epoch 76/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6011 - accuracy: 0.6667 - val_loss: 0.6007 - val_accuracy: 0.6927\n",
      "Epoch 77/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6007 - accuracy: 0.6667 - val_loss: 0.6003 - val_accuracy: 0.6927\n",
      "Epoch 78/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6003 - accuracy: 0.6667 - val_loss: 0.6000 - val_accuracy: 0.6927\n",
      "Epoch 79/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5999 - accuracy: 0.6667 - val_loss: 0.5996 - val_accuracy: 0.6927\n",
      "Epoch 80/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5995 - accuracy: 0.6667 - val_loss: 0.5992 - val_accuracy: 0.6927\n",
      "Epoch 81/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.6667 - val_loss: 0.5988 - val_accuracy: 0.6927\n",
      "Epoch 82/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5987 - accuracy: 0.6667 - val_loss: 0.5985 - val_accuracy: 0.6927\n",
      "Epoch 83/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5983 - accuracy: 0.6667 - val_loss: 0.5981 - val_accuracy: 0.6927\n",
      "Epoch 84/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5979 - accuracy: 0.6667 - val_loss: 0.5977 - val_accuracy: 0.6927\n",
      "Epoch 85/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.6667 - val_loss: 0.5974 - val_accuracy: 0.6927\n",
      "Epoch 86/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5971 - accuracy: 0.6667 - val_loss: 0.5970 - val_accuracy: 0.6927\n",
      "Epoch 87/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.6667 - val_loss: 0.5966 - val_accuracy: 0.6927\n",
      "Epoch 88/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5964 - accuracy: 0.6667 - val_loss: 0.5963 - val_accuracy: 0.6927\n",
      "Epoch 89/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.6684 - val_loss: 0.5959 - val_accuracy: 0.6927\n",
      "Epoch 90/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5956 - accuracy: 0.6684 - val_loss: 0.5955 - val_accuracy: 0.6927\n",
      "Epoch 91/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5953 - accuracy: 0.6684 - val_loss: 0.5952 - val_accuracy: 0.6927\n",
      "Epoch 92/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.6684 - val_loss: 0.5948 - val_accuracy: 0.6927\n",
      "Epoch 93/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5945 - accuracy: 0.6684 - val_loss: 0.5945 - val_accuracy: 0.6927\n",
      "Epoch 94/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5941 - accuracy: 0.6684 - val_loss: 0.5941 - val_accuracy: 0.6927\n",
      "Epoch 95/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.6684 - val_loss: 0.5938 - val_accuracy: 0.6927\n",
      "Epoch 96/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.6701 - val_loss: 0.5934 - val_accuracy: 0.6875\n",
      "Epoch 97/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.6719 - val_loss: 0.5931 - val_accuracy: 0.6875\n",
      "Epoch 98/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.6719 - val_loss: 0.5927 - val_accuracy: 0.6875\n",
      "Epoch 99/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5923 - accuracy: 0.6736 - val_loss: 0.5923 - val_accuracy: 0.6927\n",
      "Epoch 100/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.6736 - val_loss: 0.5920 - val_accuracy: 0.6927\n",
      "Epoch 101/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5916 - accuracy: 0.6736 - val_loss: 0.5916 - val_accuracy: 0.6875\n",
      "Epoch 102/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5912 - accuracy: 0.6736 - val_loss: 0.5913 - val_accuracy: 0.6875\n",
      "Epoch 103/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.6736 - val_loss: 0.5910 - val_accuracy: 0.6875\n",
      "Epoch 104/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.6736 - val_loss: 0.5906 - val_accuracy: 0.6875\n",
      "Epoch 105/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.6736 - val_loss: 0.5903 - val_accuracy: 0.6875\n",
      "Epoch 106/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5898 - accuracy: 0.6736 - val_loss: 0.5899 - val_accuracy: 0.6875\n",
      "Epoch 107/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.6736 - val_loss: 0.5896 - val_accuracy: 0.6875\n",
      "Epoch 108/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.6736 - val_loss: 0.5892 - val_accuracy: 0.6927\n",
      "Epoch 109/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.6753 - val_loss: 0.5889 - val_accuracy: 0.6927\n",
      "Epoch 110/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.6736 - val_loss: 0.5886 - val_accuracy: 0.6927\n",
      "Epoch 111/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5880 - accuracy: 0.6753 - val_loss: 0.5882 - val_accuracy: 0.6927\n",
      "Epoch 112/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.6736 - val_loss: 0.5879 - val_accuracy: 0.6927\n",
      "Epoch 113/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.6736 - val_loss: 0.5875 - val_accuracy: 0.6927\n",
      "Epoch 114/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.6736 - val_loss: 0.5872 - val_accuracy: 0.6927\n",
      "Epoch 115/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.6736 - val_loss: 0.5869 - val_accuracy: 0.6927\n",
      "Epoch 116/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.6736 - val_loss: 0.5865 - val_accuracy: 0.6927\n",
      "Epoch 117/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5860 - accuracy: 0.6736 - val_loss: 0.5862 - val_accuracy: 0.6927\n",
      "Epoch 118/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5856 - accuracy: 0.6736 - val_loss: 0.5859 - val_accuracy: 0.6927\n",
      "Epoch 119/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.6736 - val_loss: 0.5855 - val_accuracy: 0.6927\n",
      "Epoch 120/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.6753 - val_loss: 0.5852 - val_accuracy: 0.6927\n",
      "Epoch 121/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.6753 - val_loss: 0.5849 - val_accuracy: 0.6979\n",
      "Epoch 122/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.6753 - val_loss: 0.5845 - val_accuracy: 0.6979\n",
      "Epoch 123/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.6753 - val_loss: 0.5842 - val_accuracy: 0.6979\n",
      "Epoch 124/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.6753 - val_loss: 0.5839 - val_accuracy: 0.6979\n",
      "Epoch 125/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.6753 - val_loss: 0.5836 - val_accuracy: 0.6979\n",
      "Epoch 126/200\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5829 - accuracy: 0.6753 - val_loss: 0.5832 - val_accuracy: 0.6979\n",
      "Epoch 127/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5826 - accuracy: 0.6753 - val_loss: 0.5829 - val_accuracy: 0.6979\n",
      "Epoch 128/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.6753 - val_loss: 0.5826 - val_accuracy: 0.6979\n",
      "Epoch 129/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.6753 - val_loss: 0.5823 - val_accuracy: 0.6979\n",
      "Epoch 130/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5816 - accuracy: 0.6753 - val_loss: 0.5820 - val_accuracy: 0.6979\n",
      "Epoch 131/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5812 - accuracy: 0.6753 - val_loss: 0.5816 - val_accuracy: 0.6979\n",
      "Epoch 132/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.6753 - val_loss: 0.5813 - val_accuracy: 0.6979\n",
      "Epoch 133/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.6753 - val_loss: 0.5810 - val_accuracy: 0.6979\n",
      "Epoch 134/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.6788 - val_loss: 0.5807 - val_accuracy: 0.6979\n",
      "Epoch 135/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.6788 - val_loss: 0.5804 - val_accuracy: 0.6979\n",
      "Epoch 136/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.6823 - val_loss: 0.5801 - val_accuracy: 0.6979\n",
      "Epoch 137/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.6823 - val_loss: 0.5797 - val_accuracy: 0.7031\n",
      "Epoch 138/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5790 - accuracy: 0.6840 - val_loss: 0.5794 - val_accuracy: 0.7031\n",
      "Epoch 139/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5787 - accuracy: 0.6840 - val_loss: 0.5791 - val_accuracy: 0.7031\n",
      "Epoch 140/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.6840 - val_loss: 0.5788 - val_accuracy: 0.7031\n",
      "Epoch 141/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.6840 - val_loss: 0.5785 - val_accuracy: 0.7031\n",
      "Epoch 142/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5777 - accuracy: 0.6840 - val_loss: 0.5782 - val_accuracy: 0.7031\n",
      "Epoch 143/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5774 - accuracy: 0.6892 - val_loss: 0.5779 - val_accuracy: 0.7031\n",
      "Epoch 144/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5771 - accuracy: 0.6892 - val_loss: 0.5776 - val_accuracy: 0.7031\n",
      "Epoch 145/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5767 - accuracy: 0.6892 - val_loss: 0.5773 - val_accuracy: 0.7031\n",
      "Epoch 146/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5765 - accuracy: 0.6910 - val_loss: 0.5770 - val_accuracy: 0.7031\n",
      "Epoch 147/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5761 - accuracy: 0.6927 - val_loss: 0.5767 - val_accuracy: 0.7031\n",
      "Epoch 148/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5758 - accuracy: 0.6944 - val_loss: 0.5764 - val_accuracy: 0.7031\n",
      "Epoch 149/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5755 - accuracy: 0.6944 - val_loss: 0.5760 - val_accuracy: 0.7083\n",
      "Epoch 150/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.6944 - val_loss: 0.5757 - val_accuracy: 0.7031\n",
      "Epoch 151/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5749 - accuracy: 0.6962 - val_loss: 0.5754 - val_accuracy: 0.7031\n",
      "Epoch 152/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5746 - accuracy: 0.6962 - val_loss: 0.5751 - val_accuracy: 0.7031\n",
      "Epoch 153/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5743 - accuracy: 0.6962 - val_loss: 0.5748 - val_accuracy: 0.7031\n",
      "Epoch 154/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5739 - accuracy: 0.6979 - val_loss: 0.5745 - val_accuracy: 0.7031\n",
      "Epoch 155/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5736 - accuracy: 0.6979 - val_loss: 0.5743 - val_accuracy: 0.7031\n",
      "Epoch 156/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.6979 - val_loss: 0.5740 - val_accuracy: 0.7031\n",
      "Epoch 157/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5730 - accuracy: 0.6979 - val_loss: 0.5737 - val_accuracy: 0.7083\n",
      "Epoch 158/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5727 - accuracy: 0.6979 - val_loss: 0.5734 - val_accuracy: 0.7083\n",
      "Epoch 159/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5724 - accuracy: 0.6979 - val_loss: 0.5731 - val_accuracy: 0.7083\n",
      "Epoch 160/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5721 - accuracy: 0.6979 - val_loss: 0.5728 - val_accuracy: 0.7083\n",
      "Epoch 161/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.6979 - val_loss: 0.5725 - val_accuracy: 0.7135\n",
      "Epoch 162/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5715 - accuracy: 0.6979 - val_loss: 0.5722 - val_accuracy: 0.7188\n",
      "Epoch 163/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5712 - accuracy: 0.6997 - val_loss: 0.5719 - val_accuracy: 0.7188\n",
      "Epoch 164/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5709 - accuracy: 0.6997 - val_loss: 0.5716 - val_accuracy: 0.7188\n",
      "Epoch 165/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5706 - accuracy: 0.6997 - val_loss: 0.5713 - val_accuracy: 0.7188\n",
      "Epoch 166/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5703 - accuracy: 0.7014 - val_loss: 0.5710 - val_accuracy: 0.7188\n",
      "Epoch 167/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5700 - accuracy: 0.6997 - val_loss: 0.5708 - val_accuracy: 0.7188\n",
      "Epoch 168/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5697 - accuracy: 0.6979 - val_loss: 0.5705 - val_accuracy: 0.7188\n",
      "Epoch 169/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5694 - accuracy: 0.7014 - val_loss: 0.5702 - val_accuracy: 0.7188\n",
      "Epoch 170/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5691 - accuracy: 0.7014 - val_loss: 0.5699 - val_accuracy: 0.7188\n",
      "Epoch 171/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5688 - accuracy: 0.7014 - val_loss: 0.5696 - val_accuracy: 0.7188\n",
      "Epoch 172/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5685 - accuracy: 0.7049 - val_loss: 0.5693 - val_accuracy: 0.7188\n",
      "Epoch 173/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5683 - accuracy: 0.7049 - val_loss: 0.5690 - val_accuracy: 0.7240\n",
      "Epoch 174/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5679 - accuracy: 0.7049 - val_loss: 0.5688 - val_accuracy: 0.7240\n",
      "Epoch 175/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5677 - accuracy: 0.7049 - val_loss: 0.5685 - val_accuracy: 0.7240\n",
      "Epoch 176/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.7049 - val_loss: 0.5682 - val_accuracy: 0.7240\n",
      "Epoch 177/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.7049 - val_loss: 0.5679 - val_accuracy: 0.7240\n",
      "Epoch 178/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7031 - val_loss: 0.5677 - val_accuracy: 0.7240\n",
      "Epoch 179/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7031 - val_loss: 0.5674 - val_accuracy: 0.7240\n",
      "Epoch 180/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7049 - val_loss: 0.5671 - val_accuracy: 0.7240\n",
      "Epoch 181/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7031 - val_loss: 0.5668 - val_accuracy: 0.7240\n",
      "Epoch 182/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.7031 - val_loss: 0.5666 - val_accuracy: 0.7240\n",
      "Epoch 183/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.7066 - val_loss: 0.5663 - val_accuracy: 0.7240\n",
      "Epoch 184/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.7066 - val_loss: 0.5660 - val_accuracy: 0.7240\n",
      "Epoch 185/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5647 - accuracy: 0.7066 - val_loss: 0.5657 - val_accuracy: 0.7240\n",
      "Epoch 186/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7066 - val_loss: 0.5655 - val_accuracy: 0.7240\n",
      "Epoch 187/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.7083 - val_loss: 0.5652 - val_accuracy: 0.7240\n",
      "Epoch 188/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.7083 - val_loss: 0.5649 - val_accuracy: 0.7240\n",
      "Epoch 189/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7101 - val_loss: 0.5647 - val_accuracy: 0.7240\n",
      "Epoch 190/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7118 - val_loss: 0.5644 - val_accuracy: 0.7240\n",
      "Epoch 191/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7101 - val_loss: 0.5641 - val_accuracy: 0.7240\n",
      "Epoch 192/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7135 - val_loss: 0.5638 - val_accuracy: 0.7240\n",
      "Epoch 193/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.7135 - val_loss: 0.5636 - val_accuracy: 0.7240\n",
      "Epoch 194/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5622 - accuracy: 0.7135 - val_loss: 0.5633 - val_accuracy: 0.7240\n",
      "Epoch 195/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5619 - accuracy: 0.7135 - val_loss: 0.5631 - val_accuracy: 0.7188\n",
      "Epoch 196/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5617 - accuracy: 0.7135 - val_loss: 0.5628 - val_accuracy: 0.7188\n",
      "Epoch 197/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5614 - accuracy: 0.7135 - val_loss: 0.5625 - val_accuracy: 0.7188\n",
      "Epoch 198/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5611 - accuracy: 0.7135 - val_loss: 0.5623 - val_accuracy: 0.7188\n",
      "Epoch 199/200\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.7135 - val_loss: 0.5620 - val_accuracy: 0.7188\n",
      "Epoch 200/200\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7135 - val_loss: 0.5617 - val_accuracy: 0.7188\n"
     ]
    }
   ],
   "source": [
    "# Fit(Train) the Model\n",
    "\n",
    "# Compile the model with Optimizer, Loss Function and Metrics\n",
    "# Roc-Auc is not available in Keras as an off the shelf metric yet, so we will skip it here.\n",
    "\n",
    "model_1.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_1 = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=200)\n",
    "# the fit function returns the run history. \n",
    "# It is very convenient, as it contains information about the model fit, iterations etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Like we did for the Random Forest, we generate two kinds of predictions\n",
    "#  One is a hard decision, the other is a probabilitistic score.\n",
    "\n",
    "y_pred_class_nn_1 = np.argmax(model_1.predict(X_test_norm), axis=-1) #model_1.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_1 = model_1.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check out the outputs to get a feel for how keras apis work.\n",
    "y_pred_class_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38930708],\n",
       "       [0.54023635],\n",
       "       [0.24288532],\n",
       "       [0.27876648],\n",
       "       [0.23541752],\n",
       "       [0.52359915],\n",
       "       [0.2623118 ],\n",
       "       [0.35675097],\n",
       "       [0.5305075 ],\n",
       "       [0.3809927 ]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob_nn_1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.641\n",
      "roc-auc is 0.787\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print model performance and plot the roc curve\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_1)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_1)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_1, 'NN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There may be some variation in exact numbers due to randomness, but you should get results in the same ballpark as the Random Forest - between 75% and 85% accuracy, between .8 and .9 for AUC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the `run_hist_1` object that was created, specifically its `history` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_1.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the training loss and the validation loss over the different epochs and see how it looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e91b9fe5b0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss\")\n",
    "ax.plot(run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the losses are still going down on both the training set and the validation set.  This suggests that the model might benefit from further training.  Let's train the model a little more and see what happens. Note that it will pick up from where it left off. Train for 1000 more epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5603 - accuracy: 0.7153 - val_loss: 0.5615 - val_accuracy: 0.7135\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.7153 - val_loss: 0.5612 - val_accuracy: 0.7135\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7135 - val_loss: 0.5610 - val_accuracy: 0.7135\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7101 - val_loss: 0.5607 - val_accuracy: 0.7135\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5592 - accuracy: 0.7135 - val_loss: 0.5605 - val_accuracy: 0.7135\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5589 - accuracy: 0.7118 - val_loss: 0.5602 - val_accuracy: 0.7188\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5586 - accuracy: 0.7118 - val_loss: 0.5599 - val_accuracy: 0.7188\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.7153 - val_loss: 0.5597 - val_accuracy: 0.7240\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5581 - accuracy: 0.7135 - val_loss: 0.5594 - val_accuracy: 0.7240\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5578 - accuracy: 0.7153 - val_loss: 0.5592 - val_accuracy: 0.7240\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5575 - accuracy: 0.7153 - val_loss: 0.5589 - val_accuracy: 0.7240\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.7153 - val_loss: 0.5587 - val_accuracy: 0.7240\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5570 - accuracy: 0.7153 - val_loss: 0.5584 - val_accuracy: 0.7240\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5567 - accuracy: 0.7153 - val_loss: 0.5582 - val_accuracy: 0.7240\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.7153 - val_loss: 0.5579 - val_accuracy: 0.7240\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5562 - accuracy: 0.7153 - val_loss: 0.5577 - val_accuracy: 0.7292\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7170 - val_loss: 0.5574 - val_accuracy: 0.7292\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5557 - accuracy: 0.7170 - val_loss: 0.5572 - val_accuracy: 0.7292\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7153 - val_loss: 0.5569 - val_accuracy: 0.7240\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5551 - accuracy: 0.7153 - val_loss: 0.5567 - val_accuracy: 0.7240\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.7153 - val_loss: 0.5564 - val_accuracy: 0.7292\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7153 - val_loss: 0.5562 - val_accuracy: 0.7292\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7153 - val_loss: 0.5560 - val_accuracy: 0.7292\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7153 - val_loss: 0.5557 - val_accuracy: 0.7292\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7153 - val_loss: 0.5555 - val_accuracy: 0.7292\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7170 - val_loss: 0.5552 - val_accuracy: 0.7292\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7170 - val_loss: 0.5550 - val_accuracy: 0.7292\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5531 - accuracy: 0.7153 - val_loss: 0.5547 - val_accuracy: 0.7292\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5528 - accuracy: 0.7170 - val_loss: 0.5545 - val_accuracy: 0.7344\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7170 - val_loss: 0.5543 - val_accuracy: 0.7344\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.7170 - val_loss: 0.5540 - val_accuracy: 0.7344\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7170 - val_loss: 0.5538 - val_accuracy: 0.7344\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7170 - val_loss: 0.5536 - val_accuracy: 0.7344\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5515 - accuracy: 0.7170 - val_loss: 0.5533 - val_accuracy: 0.7344\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7170 - val_loss: 0.5531 - val_accuracy: 0.7344\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7170 - val_loss: 0.5528 - val_accuracy: 0.7344\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.7170 - val_loss: 0.5526 - val_accuracy: 0.7344\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7170 - val_loss: 0.5524 - val_accuracy: 0.7396\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7188 - val_loss: 0.5521 - val_accuracy: 0.7396\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5500 - accuracy: 0.7188 - val_loss: 0.5519 - val_accuracy: 0.7396\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5498 - accuracy: 0.7188 - val_loss: 0.5517 - val_accuracy: 0.7396\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7188 - val_loss: 0.5515 - val_accuracy: 0.7396\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7188 - val_loss: 0.5512 - val_accuracy: 0.7396\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7205 - val_loss: 0.5510 - val_accuracy: 0.7396\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5487 - accuracy: 0.7205 - val_loss: 0.5508 - val_accuracy: 0.7396\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7205 - val_loss: 0.5505 - val_accuracy: 0.7396\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7205 - val_loss: 0.5503 - val_accuracy: 0.7396\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7205 - val_loss: 0.5501 - val_accuracy: 0.7396\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5477 - accuracy: 0.7205 - val_loss: 0.5499 - val_accuracy: 0.7396\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7205 - val_loss: 0.5496 - val_accuracy: 0.7396\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7205 - val_loss: 0.5494 - val_accuracy: 0.7396\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7205 - val_loss: 0.5492 - val_accuracy: 0.7448\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5468 - accuracy: 0.7205 - val_loss: 0.5490 - val_accuracy: 0.7448\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.7222 - val_loss: 0.5487 - val_accuracy: 0.7448\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.7205 - val_loss: 0.5485 - val_accuracy: 0.7448\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5461 - accuracy: 0.7222 - val_loss: 0.5483 - val_accuracy: 0.7448\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5458 - accuracy: 0.7240 - val_loss: 0.5481 - val_accuracy: 0.7448\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5456 - accuracy: 0.7240 - val_loss: 0.5478 - val_accuracy: 0.7448\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.7240 - val_loss: 0.5476 - val_accuracy: 0.7448\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.7222 - val_loss: 0.5474 - val_accuracy: 0.7448\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.7222 - val_loss: 0.5472 - val_accuracy: 0.7448\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7222 - val_loss: 0.5470 - val_accuracy: 0.7448\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7240 - val_loss: 0.5467 - val_accuracy: 0.7448\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5441 - accuracy: 0.7205 - val_loss: 0.5465 - val_accuracy: 0.7448\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7205 - val_loss: 0.5463 - val_accuracy: 0.7448\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7205 - val_loss: 0.5461 - val_accuracy: 0.7448\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7222 - val_loss: 0.5459 - val_accuracy: 0.7448\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5431 - accuracy: 0.7222 - val_loss: 0.5457 - val_accuracy: 0.7448\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7205 - val_loss: 0.5455 - val_accuracy: 0.7448\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7240 - val_loss: 0.5452 - val_accuracy: 0.7448\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7240 - val_loss: 0.5450 - val_accuracy: 0.7500\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7222 - val_loss: 0.5448 - val_accuracy: 0.7500\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7257 - val_loss: 0.5446 - val_accuracy: 0.7500\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.7274 - val_loss: 0.5444 - val_accuracy: 0.7500\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7292 - val_loss: 0.5442 - val_accuracy: 0.7500\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7292 - val_loss: 0.5440 - val_accuracy: 0.7500\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7309 - val_loss: 0.5438 - val_accuracy: 0.7500\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7292 - val_loss: 0.5436 - val_accuracy: 0.7500\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7292 - val_loss: 0.5434 - val_accuracy: 0.7448\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7292 - val_loss: 0.5431 - val_accuracy: 0.7448\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7292 - val_loss: 0.5429 - val_accuracy: 0.7448\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7292 - val_loss: 0.5427 - val_accuracy: 0.7448\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.7292 - val_loss: 0.5425 - val_accuracy: 0.7448\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7292 - val_loss: 0.5423 - val_accuracy: 0.7500\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7292 - val_loss: 0.5421 - val_accuracy: 0.7500\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7292 - val_loss: 0.5419 - val_accuracy: 0.7500\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7309 - val_loss: 0.5417 - val_accuracy: 0.7500\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7309 - val_loss: 0.5415 - val_accuracy: 0.7500\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7309 - val_loss: 0.5413 - val_accuracy: 0.7500\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7309 - val_loss: 0.5411 - val_accuracy: 0.7500\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7309 - val_loss: 0.5409 - val_accuracy: 0.7500\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7326 - val_loss: 0.5407 - val_accuracy: 0.7500\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7326 - val_loss: 0.5405 - val_accuracy: 0.7500\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5371 - accuracy: 0.7326 - val_loss: 0.5403 - val_accuracy: 0.7500\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7326 - val_loss: 0.5401 - val_accuracy: 0.7500\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7344 - val_loss: 0.5399 - val_accuracy: 0.7500\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7344 - val_loss: 0.5397 - val_accuracy: 0.7500\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7326 - val_loss: 0.5395 - val_accuracy: 0.7500\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7344 - val_loss: 0.5393 - val_accuracy: 0.7500\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.7344 - val_loss: 0.5391 - val_accuracy: 0.7500\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.7344 - val_loss: 0.5389 - val_accuracy: 0.7500\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5353 - accuracy: 0.7361 - val_loss: 0.5387 - val_accuracy: 0.7500\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7361 - val_loss: 0.5385 - val_accuracy: 0.7500\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7361 - val_loss: 0.5384 - val_accuracy: 0.7500\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5347 - accuracy: 0.7361 - val_loss: 0.5382 - val_accuracy: 0.7500\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7361 - val_loss: 0.5380 - val_accuracy: 0.7500\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7361 - val_loss: 0.5378 - val_accuracy: 0.7500\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7361 - val_loss: 0.5376 - val_accuracy: 0.7500\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5338 - accuracy: 0.7361 - val_loss: 0.5374 - val_accuracy: 0.7500\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7361 - val_loss: 0.5372 - val_accuracy: 0.7500\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7361 - val_loss: 0.5370 - val_accuracy: 0.7500\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5332 - accuracy: 0.7361 - val_loss: 0.5368 - val_accuracy: 0.7500\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.7361 - val_loss: 0.5366 - val_accuracy: 0.7500\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7361 - val_loss: 0.5365 - val_accuracy: 0.7448\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5325 - accuracy: 0.7361 - val_loss: 0.5363 - val_accuracy: 0.7448\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7361 - val_loss: 0.5361 - val_accuracy: 0.7448\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7361 - val_loss: 0.5359 - val_accuracy: 0.7448\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7378 - val_loss: 0.5357 - val_accuracy: 0.7448\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5317 - accuracy: 0.7378 - val_loss: 0.5355 - val_accuracy: 0.7448\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5315 - accuracy: 0.7396 - val_loss: 0.5353 - val_accuracy: 0.7448\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.7396 - val_loss: 0.5352 - val_accuracy: 0.7448\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7396 - val_loss: 0.5350 - val_accuracy: 0.7448\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7396 - val_loss: 0.5348 - val_accuracy: 0.7448\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.7396 - val_loss: 0.5346 - val_accuracy: 0.7448\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7396 - val_loss: 0.5344 - val_accuracy: 0.7448\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.7396 - val_loss: 0.5343 - val_accuracy: 0.7448\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7396 - val_loss: 0.5341 - val_accuracy: 0.7448\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7396 - val_loss: 0.5339 - val_accuracy: 0.7448\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7396 - val_loss: 0.5337 - val_accuracy: 0.7448\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.7396 - val_loss: 0.5335 - val_accuracy: 0.7448\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7396 - val_loss: 0.5334 - val_accuracy: 0.7448\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7396 - val_loss: 0.5332 - val_accuracy: 0.7448\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7396 - val_loss: 0.5330 - val_accuracy: 0.7448\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5285 - accuracy: 0.7396 - val_loss: 0.5328 - val_accuracy: 0.7448\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5283 - accuracy: 0.7413 - val_loss: 0.5327 - val_accuracy: 0.7500\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5281 - accuracy: 0.7413 - val_loss: 0.5325 - val_accuracy: 0.7500\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.7413 - val_loss: 0.5323 - val_accuracy: 0.7500\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.7413 - val_loss: 0.5321 - val_accuracy: 0.7500\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.7413 - val_loss: 0.5320 - val_accuracy: 0.7500\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.7431 - val_loss: 0.5318 - val_accuracy: 0.7500\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5271 - accuracy: 0.7413 - val_loss: 0.5316 - val_accuracy: 0.7500\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7413 - val_loss: 0.5314 - val_accuracy: 0.7500\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7413 - val_loss: 0.5313 - val_accuracy: 0.7500\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.7413 - val_loss: 0.5311 - val_accuracy: 0.7552\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5263 - accuracy: 0.7413 - val_loss: 0.5309 - val_accuracy: 0.7552\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7413 - val_loss: 0.5308 - val_accuracy: 0.7552\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.7431 - val_loss: 0.5306 - val_accuracy: 0.7552\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7431 - val_loss: 0.5304 - val_accuracy: 0.7552\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5255 - accuracy: 0.7431 - val_loss: 0.5303 - val_accuracy: 0.7552\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5253 - accuracy: 0.7431 - val_loss: 0.5301 - val_accuracy: 0.7552\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7431 - val_loss: 0.5299 - val_accuracy: 0.7552\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5249 - accuracy: 0.7465 - val_loss: 0.5298 - val_accuracy: 0.7552\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5247 - accuracy: 0.7465 - val_loss: 0.5296 - val_accuracy: 0.7604\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5245 - accuracy: 0.7465 - val_loss: 0.5294 - val_accuracy: 0.7656\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5243 - accuracy: 0.7465 - val_loss: 0.5293 - val_accuracy: 0.7656\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7483 - val_loss: 0.5291 - val_accuracy: 0.7656\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7483 - val_loss: 0.5289 - val_accuracy: 0.7656\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5237 - accuracy: 0.7483 - val_loss: 0.5288 - val_accuracy: 0.7656\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5235 - accuracy: 0.7483 - val_loss: 0.5286 - val_accuracy: 0.7656\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7465 - val_loss: 0.5284 - val_accuracy: 0.7656\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5231 - accuracy: 0.7465 - val_loss: 0.5283 - val_accuracy: 0.7656\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.7465 - val_loss: 0.5281 - val_accuracy: 0.7656\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7465 - val_loss: 0.5280 - val_accuracy: 0.7656\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7465 - val_loss: 0.5278 - val_accuracy: 0.7656\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5224 - accuracy: 0.7465 - val_loss: 0.5276 - val_accuracy: 0.7656\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.7465 - val_loss: 0.5275 - val_accuracy: 0.7656\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7465 - val_loss: 0.5273 - val_accuracy: 0.7656\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.7465 - val_loss: 0.5272 - val_accuracy: 0.7656\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5216 - accuracy: 0.7465 - val_loss: 0.5270 - val_accuracy: 0.7656\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.7483 - val_loss: 0.5268 - val_accuracy: 0.7656\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.7483 - val_loss: 0.5267 - val_accuracy: 0.7656\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7483 - val_loss: 0.5265 - val_accuracy: 0.7656\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.7483 - val_loss: 0.5264 - val_accuracy: 0.7656\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.7483 - val_loss: 0.5262 - val_accuracy: 0.7656\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5205 - accuracy: 0.7483 - val_loss: 0.5261 - val_accuracy: 0.7656\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5203 - accuracy: 0.7483 - val_loss: 0.5259 - val_accuracy: 0.7656\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.7483 - val_loss: 0.5258 - val_accuracy: 0.7656\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7483 - val_loss: 0.5256 - val_accuracy: 0.7656\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7483 - val_loss: 0.5255 - val_accuracy: 0.7656\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.7500 - val_loss: 0.5253 - val_accuracy: 0.7656\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7500 - val_loss: 0.5252 - val_accuracy: 0.7708\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.7500 - val_loss: 0.5250 - val_accuracy: 0.7708\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7500 - val_loss: 0.5249 - val_accuracy: 0.7708\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.7500 - val_loss: 0.5247 - val_accuracy: 0.7708\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7483 - val_loss: 0.5246 - val_accuracy: 0.7708\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.7465 - val_loss: 0.5244 - val_accuracy: 0.7708\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.7465 - val_loss: 0.5243 - val_accuracy: 0.7708\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.7465 - val_loss: 0.5241 - val_accuracy: 0.7708\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7465 - val_loss: 0.5240 - val_accuracy: 0.7760\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.7465 - val_loss: 0.5238 - val_accuracy: 0.7760\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5175 - accuracy: 0.7483 - val_loss: 0.5237 - val_accuracy: 0.7760\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5174 - accuracy: 0.7483 - val_loss: 0.5235 - val_accuracy: 0.7760\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.7483 - val_loss: 0.5234 - val_accuracy: 0.7760\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7483 - val_loss: 0.5232 - val_accuracy: 0.7760\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5168 - accuracy: 0.7500 - val_loss: 0.5231 - val_accuracy: 0.7708\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7483 - val_loss: 0.5229 - val_accuracy: 0.7708\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5165 - accuracy: 0.7483 - val_loss: 0.5228 - val_accuracy: 0.7708\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.7483 - val_loss: 0.5227 - val_accuracy: 0.7708\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.7500 - val_loss: 0.5225 - val_accuracy: 0.7708\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.7483 - val_loss: 0.5224 - val_accuracy: 0.7708\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5158 - accuracy: 0.7483 - val_loss: 0.5222 - val_accuracy: 0.7708\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5156 - accuracy: 0.7483 - val_loss: 0.5221 - val_accuracy: 0.7656\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.5818 - accuracy: 0.65 - 0s 3ms/step - loss: 0.5154 - accuracy: 0.7465 - val_loss: 0.5219 - val_accuracy: 0.7708\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.7483 - val_loss: 0.5218 - val_accuracy: 0.7708\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5151 - accuracy: 0.7465 - val_loss: 0.5217 - val_accuracy: 0.7708\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5149 - accuracy: 0.7500 - val_loss: 0.5215 - val_accuracy: 0.7708\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7500 - val_loss: 0.5214 - val_accuracy: 0.7708\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.7500 - val_loss: 0.5213 - val_accuracy: 0.7760\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5143 - accuracy: 0.7500 - val_loss: 0.5211 - val_accuracy: 0.7760\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5142 - accuracy: 0.7500 - val_loss: 0.5210 - val_accuracy: 0.7760\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.7500 - val_loss: 0.5208 - val_accuracy: 0.7760\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7500 - val_loss: 0.5207 - val_accuracy: 0.7760\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.7517 - val_loss: 0.5206 - val_accuracy: 0.7760\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5135 - accuracy: 0.7500 - val_loss: 0.5204 - val_accuracy: 0.7760\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7500 - val_loss: 0.5203 - val_accuracy: 0.7760\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5132 - accuracy: 0.7483 - val_loss: 0.5202 - val_accuracy: 0.7760\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.7517 - val_loss: 0.5200 - val_accuracy: 0.7760\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7517 - val_loss: 0.5199 - val_accuracy: 0.7760\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7483 - val_loss: 0.5198 - val_accuracy: 0.7760\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7500 - val_loss: 0.5196 - val_accuracy: 0.7760\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7483 - val_loss: 0.5195 - val_accuracy: 0.7760\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7500 - val_loss: 0.5194 - val_accuracy: 0.7760\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.7500 - val_loss: 0.5192 - val_accuracy: 0.7760\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5118 - accuracy: 0.7535 - val_loss: 0.5191 - val_accuracy: 0.7760\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7500 - val_loss: 0.5190 - val_accuracy: 0.7760\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7517 - val_loss: 0.5188 - val_accuracy: 0.7760\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.7500 - val_loss: 0.5187 - val_accuracy: 0.7760\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7517 - val_loss: 0.5186 - val_accuracy: 0.7708\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7517 - val_loss: 0.5184 - val_accuracy: 0.7708\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7708\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7517 - val_loss: 0.5182 - val_accuracy: 0.7708\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7517 - val_loss: 0.5181 - val_accuracy: 0.7708\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5103 - accuracy: 0.7517 - val_loss: 0.5179 - val_accuracy: 0.7708\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5102 - accuracy: 0.7517 - val_loss: 0.5178 - val_accuracy: 0.7708\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7517 - val_loss: 0.5177 - val_accuracy: 0.7708\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7517 - val_loss: 0.5176 - val_accuracy: 0.7708\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7535 - val_loss: 0.5174 - val_accuracy: 0.7708\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7517 - val_loss: 0.5173 - val_accuracy: 0.7708\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7535 - val_loss: 0.5172 - val_accuracy: 0.7708\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7535 - val_loss: 0.5171 - val_accuracy: 0.7708\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7535 - val_loss: 0.5169 - val_accuracy: 0.7708\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5089 - accuracy: 0.7535 - val_loss: 0.5168 - val_accuracy: 0.7708\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7535 - val_loss: 0.5167 - val_accuracy: 0.7708\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7535 - val_loss: 0.5166 - val_accuracy: 0.7708\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.7535 - val_loss: 0.5164 - val_accuracy: 0.7708\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7535 - val_loss: 0.5163 - val_accuracy: 0.7708\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5081 - accuracy: 0.7535 - val_loss: 0.5162 - val_accuracy: 0.7708\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.7535 - val_loss: 0.5161 - val_accuracy: 0.7708\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.7552 - val_loss: 0.5160 - val_accuracy: 0.7708\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7552 - val_loss: 0.5158 - val_accuracy: 0.7708\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7552 - val_loss: 0.5157 - val_accuracy: 0.7708\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5073 - accuracy: 0.7552 - val_loss: 0.5156 - val_accuracy: 0.7708\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7552 - val_loss: 0.5155 - val_accuracy: 0.7708\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7552 - val_loss: 0.5154 - val_accuracy: 0.7708\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7535 - val_loss: 0.5152 - val_accuracy: 0.7708\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.7552 - val_loss: 0.5151 - val_accuracy: 0.7708\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7569 - val_loss: 0.5150 - val_accuracy: 0.7708\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.7552 - val_loss: 0.5149 - val_accuracy: 0.7708\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7569 - val_loss: 0.5148 - val_accuracy: 0.7708\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.7552 - val_loss: 0.5147 - val_accuracy: 0.7708\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7569 - val_loss: 0.5146 - val_accuracy: 0.7760\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.7552 - val_loss: 0.5144 - val_accuracy: 0.7760\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7552 - val_loss: 0.5143 - val_accuracy: 0.7760\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7552 - val_loss: 0.5142 - val_accuracy: 0.7760\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5053 - accuracy: 0.7552 - val_loss: 0.5141 - val_accuracy: 0.7760\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7552 - val_loss: 0.5140 - val_accuracy: 0.7760\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7552 - val_loss: 0.5139 - val_accuracy: 0.7760\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7552 - val_loss: 0.5138 - val_accuracy: 0.7760\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5047 - accuracy: 0.7552 - val_loss: 0.5136 - val_accuracy: 0.7760\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7552 - val_loss: 0.5135 - val_accuracy: 0.7760\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5044 - accuracy: 0.7552 - val_loss: 0.5134 - val_accuracy: 0.7708\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5042 - accuracy: 0.7535 - val_loss: 0.5133 - val_accuracy: 0.7708\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.7535 - val_loss: 0.5132 - val_accuracy: 0.7708\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7535 - val_loss: 0.5131 - val_accuracy: 0.7708\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.7535 - val_loss: 0.5130 - val_accuracy: 0.7656\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5037 - accuracy: 0.7535 - val_loss: 0.5129 - val_accuracy: 0.7656\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.7535 - val_loss: 0.5128 - val_accuracy: 0.7656\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7535 - val_loss: 0.5127 - val_accuracy: 0.7656\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7535 - val_loss: 0.5125 - val_accuracy: 0.7656\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5031 - accuracy: 0.7535 - val_loss: 0.5124 - val_accuracy: 0.7656\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7552 - val_loss: 0.5123 - val_accuracy: 0.7656\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5028 - accuracy: 0.7552 - val_loss: 0.5122 - val_accuracy: 0.7656\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.7552 - val_loss: 0.5121 - val_accuracy: 0.7656\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7552 - val_loss: 0.5120 - val_accuracy: 0.7656\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.7552 - val_loss: 0.5119 - val_accuracy: 0.7656\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.7552 - val_loss: 0.5118 - val_accuracy: 0.7656\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7552 - val_loss: 0.5117 - val_accuracy: 0.7656\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.7552 - val_loss: 0.5116 - val_accuracy: 0.7656\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.7535 - val_loss: 0.5115 - val_accuracy: 0.7656\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5016 - accuracy: 0.7535 - val_loss: 0.5114 - val_accuracy: 0.7656\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.7535 - val_loss: 0.5113 - val_accuracy: 0.7656\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5014 - accuracy: 0.7535 - val_loss: 0.5112 - val_accuracy: 0.7656\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.7535 - val_loss: 0.5111 - val_accuracy: 0.7656\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.7552 - val_loss: 0.5110 - val_accuracy: 0.7656\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5010 - accuracy: 0.7552 - val_loss: 0.5109 - val_accuracy: 0.7656\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.7552 - val_loss: 0.5108 - val_accuracy: 0.7656\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7552 - val_loss: 0.5107 - val_accuracy: 0.7656\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7552 - val_loss: 0.5106 - val_accuracy: 0.7656\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5004 - accuracy: 0.7552 - val_loss: 0.5105 - val_accuracy: 0.7656\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7552 - val_loss: 0.5104 - val_accuracy: 0.7656\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7552 - val_loss: 0.5103 - val_accuracy: 0.7656\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.7552 - val_loss: 0.5102 - val_accuracy: 0.7656\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7552 - val_loss: 0.5101 - val_accuracy: 0.7656\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7552 - val_loss: 0.5100 - val_accuracy: 0.7656\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4996 - accuracy: 0.7569 - val_loss: 0.5099 - val_accuracy: 0.7656\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4994 - accuracy: 0.7569 - val_loss: 0.5098 - val_accuracy: 0.7656\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.7569 - val_loss: 0.5097 - val_accuracy: 0.7656\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.7569 - val_loss: 0.5096 - val_accuracy: 0.7656\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7569 - val_loss: 0.5095 - val_accuracy: 0.7656\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7569 - val_loss: 0.5094 - val_accuracy: 0.7656\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.7569 - val_loss: 0.5093 - val_accuracy: 0.7656\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.7569 - val_loss: 0.5092 - val_accuracy: 0.7656\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7569 - val_loss: 0.5091 - val_accuracy: 0.7656\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7569 - val_loss: 0.5090 - val_accuracy: 0.7656\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7569 - val_loss: 0.5089 - val_accuracy: 0.7656\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.7569 - val_loss: 0.5088 - val_accuracy: 0.7656\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7569 - val_loss: 0.5087 - val_accuracy: 0.7656\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4978 - accuracy: 0.7569 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4977 - accuracy: 0.7569 - val_loss: 0.5086 - val_accuracy: 0.7656\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7569 - val_loss: 0.5085 - val_accuracy: 0.7656\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.7569 - val_loss: 0.5084 - val_accuracy: 0.7656\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7569 - val_loss: 0.5083 - val_accuracy: 0.7656\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.7569 - val_loss: 0.5082 - val_accuracy: 0.7656\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7552 - val_loss: 0.5081 - val_accuracy: 0.7656\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.7569 - val_loss: 0.5080 - val_accuracy: 0.7656\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.7552 - val_loss: 0.5079 - val_accuracy: 0.7708\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4967 - accuracy: 0.7552 - val_loss: 0.5078 - val_accuracy: 0.7708\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4966 - accuracy: 0.7552 - val_loss: 0.5077 - val_accuracy: 0.7708\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4964 - accuracy: 0.7552 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.7552 - val_loss: 0.5076 - val_accuracy: 0.7708\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.7552 - val_loss: 0.5075 - val_accuracy: 0.7708\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.7552 - val_loss: 0.5074 - val_accuracy: 0.7708\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7552 - val_loss: 0.5073 - val_accuracy: 0.7708\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4958 - accuracy: 0.7569 - val_loss: 0.5072 - val_accuracy: 0.7708\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.7569 - val_loss: 0.5071 - val_accuracy: 0.7708\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4955 - accuracy: 0.7569 - val_loss: 0.5070 - val_accuracy: 0.7708\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4954 - accuracy: 0.7569 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.7569 - val_loss: 0.5069 - val_accuracy: 0.7708\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4952 - accuracy: 0.7569 - val_loss: 0.5068 - val_accuracy: 0.7708\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7569 - val_loss: 0.5067 - val_accuracy: 0.7708\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7569 - val_loss: 0.5066 - val_accuracy: 0.7708\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4948 - accuracy: 0.7569 - val_loss: 0.5065 - val_accuracy: 0.7708\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7587 - val_loss: 0.5064 - val_accuracy: 0.7708\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4945 - accuracy: 0.7569 - val_loss: 0.5063 - val_accuracy: 0.7708\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4944 - accuracy: 0.7552 - val_loss: 0.5063 - val_accuracy: 0.7656\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.7569 - val_loss: 0.5062 - val_accuracy: 0.7656\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.7587 - val_loss: 0.5061 - val_accuracy: 0.7656\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4941 - accuracy: 0.7587 - val_loss: 0.5060 - val_accuracy: 0.7656\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.7604 - val_loss: 0.5059 - val_accuracy: 0.7656\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.7587 - val_loss: 0.5058 - val_accuracy: 0.7656\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7604 - val_loss: 0.5058 - val_accuracy: 0.7604\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7604 - val_loss: 0.5057 - val_accuracy: 0.7604\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7587 - val_loss: 0.5056 - val_accuracy: 0.7604\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.7587 - val_loss: 0.5055 - val_accuracy: 0.7604\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4932 - accuracy: 0.7604 - val_loss: 0.5054 - val_accuracy: 0.7604\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7587 - val_loss: 0.5054 - val_accuracy: 0.7604\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4930 - accuracy: 0.7587 - val_loss: 0.5053 - val_accuracy: 0.7604\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4929 - accuracy: 0.7587 - val_loss: 0.5052 - val_accuracy: 0.7604\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.7587 - val_loss: 0.5051 - val_accuracy: 0.7604\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7604 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.7604 - val_loss: 0.5050 - val_accuracy: 0.7604\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.7604 - val_loss: 0.5049 - val_accuracy: 0.7604\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7587 - val_loss: 0.5048 - val_accuracy: 0.7604\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7587 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7587 - val_loss: 0.5047 - val_accuracy: 0.7604\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.7587 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7604 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.7604 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4916 - accuracy: 0.7604 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7587 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7587 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.7604 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7604 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.7604 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7604 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7604 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.7604 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.7604 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7604 - val_loss: 0.5036 - val_accuracy: 0.7604\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7604 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.7604 - val_loss: 0.5035 - val_accuracy: 0.7604\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4902 - accuracy: 0.7604 - val_loss: 0.5034 - val_accuracy: 0.7604\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7604 - val_loss: 0.5033 - val_accuracy: 0.7604\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7604 - val_loss: 0.5032 - val_accuracy: 0.7604\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4898 - accuracy: 0.7604 - val_loss: 0.5032 - val_accuracy: 0.7604\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7604 - val_loss: 0.5031 - val_accuracy: 0.7604\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.7604 - val_loss: 0.5030 - val_accuracy: 0.7604\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.7604 - val_loss: 0.5030 - val_accuracy: 0.7604\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7604 - val_loss: 0.5029 - val_accuracy: 0.7604\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4893 - accuracy: 0.7604 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.7604 - val_loss: 0.5028 - val_accuracy: 0.7604\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.7604 - val_loss: 0.5027 - val_accuracy: 0.7604\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.7604 - val_loss: 0.5026 - val_accuracy: 0.7604\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.7604 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7604 - val_loss: 0.5025 - val_accuracy: 0.7604\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7604 - val_loss: 0.5024 - val_accuracy: 0.7604\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4885 - accuracy: 0.7604 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.7604 - val_loss: 0.5023 - val_accuracy: 0.7604\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.7604 - val_loss: 0.5022 - val_accuracy: 0.7604\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.7604 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.7604 - val_loss: 0.5021 - val_accuracy: 0.7604\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7604 - val_loss: 0.5020 - val_accuracy: 0.7604\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7604 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7604 - val_loss: 0.5019 - val_accuracy: 0.7604\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4877 - accuracy: 0.7604 - val_loss: 0.5018 - val_accuracy: 0.7604\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.7604 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7604 - val_loss: 0.5017 - val_accuracy: 0.7604\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4874 - accuracy: 0.7604 - val_loss: 0.5016 - val_accuracy: 0.7604\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.7604 - val_loss: 0.5016 - val_accuracy: 0.7604\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.7604 - val_loss: 0.5015 - val_accuracy: 0.7604\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.7604 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4870 - accuracy: 0.7604 - val_loss: 0.5014 - val_accuracy: 0.7604\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7604 - val_loss: 0.5013 - val_accuracy: 0.7604\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.7604 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.7604 - val_loss: 0.5012 - val_accuracy: 0.7604\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7604 - val_loss: 0.5011 - val_accuracy: 0.7604\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.7604 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4864 - accuracy: 0.7604 - val_loss: 0.5010 - val_accuracy: 0.7604\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.7604 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7604 - val_loss: 0.5009 - val_accuracy: 0.7604\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7604 - val_loss: 0.5008 - val_accuracy: 0.7604\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7604 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.7604 - val_loss: 0.5007 - val_accuracy: 0.7604\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.7604 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7604 - val_loss: 0.5006 - val_accuracy: 0.7604\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7604 - val_loss: 0.5005 - val_accuracy: 0.7604\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7604 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4854 - accuracy: 0.7604 - val_loss: 0.5004 - val_accuracy: 0.7604\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7622 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7604 - val_loss: 0.5003 - val_accuracy: 0.7604\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.7622 - val_loss: 0.5002 - val_accuracy: 0.7604\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7622 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.7622 - val_loss: 0.5001 - val_accuracy: 0.7604\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.7622 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7622 - val_loss: 0.5000 - val_accuracy: 0.7604\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.7622 - val_loss: 0.4999 - val_accuracy: 0.7604\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7622 - val_loss: 0.4999 - val_accuracy: 0.7604\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7622 - val_loss: 0.4998 - val_accuracy: 0.7604\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.7622 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.7622 - val_loss: 0.4997 - val_accuracy: 0.7604\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7622 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7622 - val_loss: 0.4996 - val_accuracy: 0.7604\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7622 - val_loss: 0.4995 - val_accuracy: 0.7604\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7622 - val_loss: 0.4995 - val_accuracy: 0.7604\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7639 - val_loss: 0.4994 - val_accuracy: 0.7604\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4838 - accuracy: 0.7639 - val_loss: 0.4994 - val_accuracy: 0.7604\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7639 - val_loss: 0.4993 - val_accuracy: 0.7604\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.7639 - val_loss: 0.4992 - val_accuracy: 0.7604\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7639 - val_loss: 0.4992 - val_accuracy: 0.7604\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.7639 - val_loss: 0.4991 - val_accuracy: 0.7604\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7639 - val_loss: 0.4991 - val_accuracy: 0.7604\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4832 - accuracy: 0.7639 - val_loss: 0.4990 - val_accuracy: 0.7604\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7639 - val_loss: 0.4990 - val_accuracy: 0.7604\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4830 - accuracy: 0.7622 - val_loss: 0.4989 - val_accuracy: 0.7604\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7622 - val_loss: 0.4989 - val_accuracy: 0.7604\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.7622 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7622 - val_loss: 0.4988 - val_accuracy: 0.7604\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.7622 - val_loss: 0.4987 - val_accuracy: 0.7604\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4826 - accuracy: 0.7622 - val_loss: 0.4987 - val_accuracy: 0.7604\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7622 - val_loss: 0.4986 - val_accuracy: 0.7604\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.7622 - val_loss: 0.4986 - val_accuracy: 0.7604\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4823 - accuracy: 0.7622 - val_loss: 0.4985 - val_accuracy: 0.7604\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.7622 - val_loss: 0.4985 - val_accuracy: 0.7604\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.7622 - val_loss: 0.4984 - val_accuracy: 0.7604\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4821 - accuracy: 0.7622 - val_loss: 0.4984 - val_accuracy: 0.7604\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.7639 - val_loss: 0.4983 - val_accuracy: 0.7604\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4819 - accuracy: 0.7639 - val_loss: 0.4983 - val_accuracy: 0.7604\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7639 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.7639 - val_loss: 0.4982 - val_accuracy: 0.7604\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.7639 - val_loss: 0.4981 - val_accuracy: 0.7604\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7639 - val_loss: 0.4981 - val_accuracy: 0.7604\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4815 - accuracy: 0.7639 - val_loss: 0.4980 - val_accuracy: 0.7604\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7639 - val_loss: 0.4980 - val_accuracy: 0.7552\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4813 - accuracy: 0.7639 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7639 - val_loss: 0.4979 - val_accuracy: 0.7552\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7639 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7639 - val_loss: 0.4978 - val_accuracy: 0.7552\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.7656 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7656 - val_loss: 0.4977 - val_accuracy: 0.7552\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4808 - accuracy: 0.7656 - val_loss: 0.4976 - val_accuracy: 0.7552\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7656 - val_loss: 0.4976 - val_accuracy: 0.7552\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4806 - accuracy: 0.7656 - val_loss: 0.4975 - val_accuracy: 0.7552\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4806 - accuracy: 0.7656 - val_loss: 0.4975 - val_accuracy: 0.7552\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7656 - val_loss: 0.4974 - val_accuracy: 0.7552\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7656 - val_loss: 0.4974 - val_accuracy: 0.7552\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4803 - accuracy: 0.7656 - val_loss: 0.4974 - val_accuracy: 0.7552\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.7656 - val_loss: 0.4973 - val_accuracy: 0.7552\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.7656 - val_loss: 0.4973 - val_accuracy: 0.7552\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.7656 - val_loss: 0.4972 - val_accuracy: 0.7552\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7656 - val_loss: 0.4972 - val_accuracy: 0.7552\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4799 - accuracy: 0.7656 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.7656 - val_loss: 0.4971 - val_accuracy: 0.7500\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7656 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4797 - accuracy: 0.7656 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.7656 - val_loss: 0.4970 - val_accuracy: 0.7500\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4795 - accuracy: 0.7656 - val_loss: 0.4969 - val_accuracy: 0.7500\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7656 - val_loss: 0.4969 - val_accuracy: 0.7500\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4794 - accuracy: 0.7656 - val_loss: 0.4968 - val_accuracy: 0.7500\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.7656 - val_loss: 0.4968 - val_accuracy: 0.7500\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.7656 - val_loss: 0.4967 - val_accuracy: 0.7500\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7656 - val_loss: 0.4967 - val_accuracy: 0.7500\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4791 - accuracy: 0.7656 - val_loss: 0.4967 - val_accuracy: 0.7500\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7656 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4789 - accuracy: 0.7656 - val_loss: 0.4966 - val_accuracy: 0.7500\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7656 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.7656 - val_loss: 0.4965 - val_accuracy: 0.7500\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.7656 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4786 - accuracy: 0.7656 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7656 - val_loss: 0.4964 - val_accuracy: 0.7500\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7656 - val_loss: 0.4963 - val_accuracy: 0.7500\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4784 - accuracy: 0.7656 - val_loss: 0.4963 - val_accuracy: 0.7500\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.7656 - val_loss: 0.4962 - val_accuracy: 0.7500\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.7656 - val_loss: 0.4962 - val_accuracy: 0.7500\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.7656 - val_loss: 0.4962 - val_accuracy: 0.7500\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.6015 - accuracy: 0.68 - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7656 - val_loss: 0.4961 - val_accuracy: 0.7500\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.5075 - accuracy: 0.75 - 0s 3ms/step - loss: 0.4780 - accuracy: 0.7656 - val_loss: 0.4961 - val_accuracy: 0.7500\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7656 - val_loss: 0.4960 - val_accuracy: 0.7500\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.7656 - val_loss: 0.4960 - val_accuracy: 0.7500\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4778 - accuracy: 0.7656 - val_loss: 0.4960 - val_accuracy: 0.7500\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4777 - accuracy: 0.7656 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7656 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7674 - val_loss: 0.4959 - val_accuracy: 0.7500\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4775 - accuracy: 0.7656 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.7656 - val_loss: 0.4958 - val_accuracy: 0.7500\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7656 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7674 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.7656 - val_loss: 0.4957 - val_accuracy: 0.7500\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7674 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7674 - val_loss: 0.4956 - val_accuracy: 0.7500\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7674 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.7674 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7674 - val_loss: 0.4955 - val_accuracy: 0.7500\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7674 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4767 - accuracy: 0.7674 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7674 - val_loss: 0.4954 - val_accuracy: 0.7500\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7674 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7674 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4764 - accuracy: 0.7674 - val_loss: 0.4953 - val_accuracy: 0.7500\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7674 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7691 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7691 - val_loss: 0.4952 - val_accuracy: 0.7500\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7691 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7691 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.7691 - val_loss: 0.4951 - val_accuracy: 0.7500\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7691 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7708 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7691 - val_loss: 0.4950 - val_accuracy: 0.7500\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7691 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4757 - accuracy: 0.7708 - val_loss: 0.4949 - val_accuracy: 0.7500\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7726 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7708 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4755 - accuracy: 0.7726 - val_loss: 0.4948 - val_accuracy: 0.7500\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4754 - accuracy: 0.7726 - val_loss: 0.4947 - val_accuracy: 0.7500\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7726 - val_loss: 0.4947 - val_accuracy: 0.7500\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7726 - val_loss: 0.4947 - val_accuracy: 0.7500\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7743 - val_loss: 0.4947 - val_accuracy: 0.7552\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7743 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7743 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7743 - val_loss: 0.4946 - val_accuracy: 0.7552\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.7743 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4749 - accuracy: 0.7743 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7743 - val_loss: 0.4945 - val_accuracy: 0.7552\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7743 - val_loss: 0.4944 - val_accuracy: 0.7552\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.7726 - val_loss: 0.4944 - val_accuracy: 0.7552\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4747 - accuracy: 0.7708 - val_loss: 0.4944 - val_accuracy: 0.7552\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7552\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4745 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7552\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7743 - val_loss: 0.4943 - val_accuracy: 0.7552\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7708 - val_loss: 0.4942 - val_accuracy: 0.7604\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.7708 - val_loss: 0.4942 - val_accuracy: 0.7604\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.7708 - val_loss: 0.4942 - val_accuracy: 0.7604\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.7726 - val_loss: 0.4942 - val_accuracy: 0.7604\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7708 - val_loss: 0.4941 - val_accuracy: 0.7604\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7604\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7604\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7708 - val_loss: 0.4940 - val_accuracy: 0.7604\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7726 - val_loss: 0.4940 - val_accuracy: 0.7604\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7726 - val_loss: 0.4940 - val_accuracy: 0.7604\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.7726 - val_loss: 0.4939 - val_accuracy: 0.7604\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7726 - val_loss: 0.4939 - val_accuracy: 0.7604\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7726 - val_loss: 0.4939 - val_accuracy: 0.7604\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.7726 - val_loss: 0.4939 - val_accuracy: 0.7604\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7726 - val_loss: 0.4938 - val_accuracy: 0.7604\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7726 - val_loss: 0.4938 - val_accuracy: 0.7604\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7726 - val_loss: 0.4938 - val_accuracy: 0.7604\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7726 - val_loss: 0.4938 - val_accuracy: 0.7604\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7726 - val_loss: 0.4937 - val_accuracy: 0.7604\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7726 - val_loss: 0.4937 - val_accuracy: 0.7604\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7726 - val_loss: 0.4937 - val_accuracy: 0.7604\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7726 - val_loss: 0.4936 - val_accuracy: 0.7604\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.7726 - val_loss: 0.4936 - val_accuracy: 0.7604\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7726 - val_loss: 0.4936 - val_accuracy: 0.7604\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7726 - val_loss: 0.4936 - val_accuracy: 0.7604\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4549 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4729 - accuracy: 0.7708 - val_loss: 0.4935 - val_accuracy: 0.7604\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7708 - val_loss: 0.4935 - val_accuracy: 0.7604\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7708 - val_loss: 0.4935 - val_accuracy: 0.7604\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7726 - val_loss: 0.4935 - val_accuracy: 0.7604\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7726 - val_loss: 0.4934 - val_accuracy: 0.7604\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.7726 - val_loss: 0.4934 - val_accuracy: 0.7604\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7726 - val_loss: 0.4934 - val_accuracy: 0.7604\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7708 - val_loss: 0.4934 - val_accuracy: 0.7604\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7708 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4724 - accuracy: 0.7708 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7726 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7726 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7726 - val_loss: 0.4932 - val_accuracy: 0.7604\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7708 - val_loss: 0.4932 - val_accuracy: 0.7604\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7726 - val_loss: 0.4932 - val_accuracy: 0.7604\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7708 - val_loss: 0.4932 - val_accuracy: 0.7604\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7708 - val_loss: 0.4931 - val_accuracy: 0.7604\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7708 - val_loss: 0.4931 - val_accuracy: 0.7604\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7708 - val_loss: 0.4931 - val_accuracy: 0.7604\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7708 - val_loss: 0.4931 - val_accuracy: 0.7552\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7708 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7726 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4717 - accuracy: 0.7726 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7708 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7708 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.7708 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7708 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7708 - val_loss: 0.4929 - val_accuracy: 0.7552\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7708 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7708 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4713 - accuracy: 0.7726 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7708 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7708 - val_loss: 0.4928 - val_accuracy: 0.7552\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7708 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7708 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7708 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7708 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.7708 - val_loss: 0.4927 - val_accuracy: 0.7552\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7708 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7708 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7708 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7708 - val_loss: 0.4926 - val_accuracy: 0.7552\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4706 - accuracy: 0.7708 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.7708 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7708 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.7708 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7708 - val_loss: 0.4925 - val_accuracy: 0.7552\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7708 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7708 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7708 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7708 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7708 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7708 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7708 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7708 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7708 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7708 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7691 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7708 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4698 - accuracy: 0.7691 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7691 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7691 - val_loss: 0.4922 - val_accuracy: 0.7552\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7691 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7691 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.7691 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7691 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7691 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7691 - val_loss: 0.4921 - val_accuracy: 0.7552\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7691 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7691 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7691 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7691 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.7691 - val_loss: 0.4920 - val_accuracy: 0.7552\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7691 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7691 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7691 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7691 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7691 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4689 - accuracy: 0.7691 - val_loss: 0.4919 - val_accuracy: 0.7552\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7708 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7726 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7726 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7743 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7743 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4687 - accuracy: 0.7743 - val_loss: 0.4918 - val_accuracy: 0.7552\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7726 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7743 - val_loss: 0.4917 - val_accuracy: 0.7552\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7743 - val_loss: 0.4916 - val_accuracy: 0.7552\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4678 - accuracy: 0.7743 - val_loss: 0.4915 - val_accuracy: 0.7552\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7743 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7743 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4677 - accuracy: 0.7743 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7726 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7726 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7726 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7726 - val_loss: 0.4914 - val_accuracy: 0.7552\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4675 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4673 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7726 - val_loss: 0.4913 - val_accuracy: 0.7552\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7726 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7726 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4671 - accuracy: 0.7726 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7726 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4670 - accuracy: 0.7726 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7726 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7726 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7743 - val_loss: 0.4912 - val_accuracy: 0.7552\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7743 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.7743 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.7743 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7743 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7743 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7760 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7743 - val_loss: 0.4911 - val_accuracy: 0.7552\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7743 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7760 - val_loss: 0.4910 - val_accuracy: 0.7552\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7552\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7778 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7760 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7778 - val_loss: 0.4909 - val_accuracy: 0.7604\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7795 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7778 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7795 - val_loss: 0.4908 - val_accuracy: 0.7604\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7795 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7778 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7795 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7778 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7795 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7795 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7778 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7795 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7795 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7795 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7795 - val_loss: 0.4907 - val_accuracy: 0.7604\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7795 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7795 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7795 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7795 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7795 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7778 - val_loss: 0.4906 - val_accuracy: 0.7604\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4643 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7778 - val_loss: 0.4905 - val_accuracy: 0.7604\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4640 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4639 - accuracy: 0.7778 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7795 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7795 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7795 - val_loss: 0.4904 - val_accuracy: 0.7604\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4637 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7795 - val_loss: 0.4903 - val_accuracy: 0.7604\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4632 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.4902 - val_accuracy: 0.7604\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4621 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4901 - val_accuracy: 0.7604\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4616 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4615 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4612 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4611 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7604\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7795 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7656\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.7778 - val_loss: 0.4900 - val_accuracy: 0.7708\n"
     ]
    }
   ],
   "source": [
    "## Note that when we call \"fit\" again, it picks up where it left off\n",
    "run_hist_1b = model_1.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1e91bbba700>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_1.history[\"loss\"])\n",
    "m = len(run_hist_1b.history['loss'])\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"loss\"],'r', marker='.', label=\"Train Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"loss\"], 'hotpink', marker='.', label=\"Train Loss - Run 2\")\n",
    "\n",
    "ax.plot(range(n), run_hist_1.history[\"val_loss\"],'b', marker='.', label=\"Validation Loss - Run 1\")\n",
    "ax.plot(range(n, n+m), run_hist_1b.history[\"val_loss\"], 'LightSkyBlue', marker='.',  label=\"Validation Loss - Run 2\")\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this graph begins where the other left off.  While the training loss is still going down, it looks like the validation loss has stabilized (or even gotten worse!).  This suggests that our network will not benefit from further training.  What is the appropriate number of epochs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "For this exercise, do the following in the cells below:\n",
    "- Build a model with two hidden layers, each with 6 nodes\n",
    "- Use the \"relu\" activation function for the hidden layers, and \"sigmoid\" for the final layer\n",
    "- Use a learning rate of .003 and train for 1500 epochs\n",
    "- Graph the trajectory of the loss functions, accuracy on both train and test set\n",
    "- Plot the roc curve for the predictions\n",
    "\n",
    "Experiment with different learning rates, numbers of epochs, and network structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1500\n",
      "18/18 [==============================] - 1s 12ms/step - loss: 0.8004 - accuracy: 0.3750 - val_loss: 0.7770 - val_accuracy: 0.4167\n",
      "Epoch 2/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7818 - accuracy: 0.3819 - val_loss: 0.7616 - val_accuracy: 0.4271\n",
      "Epoch 3/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.7650 - accuracy: 0.3906 - val_loss: 0.7477 - val_accuracy: 0.4219\n",
      "Epoch 4/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7500 - accuracy: 0.4045 - val_loss: 0.7353 - val_accuracy: 0.4323\n",
      "Epoch 5/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7365 - accuracy: 0.4288 - val_loss: 0.7241 - val_accuracy: 0.4635\n",
      "Epoch 6/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7243 - accuracy: 0.4549 - val_loss: 0.7140 - val_accuracy: 0.5000\n",
      "Epoch 7/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7133 - accuracy: 0.4809 - val_loss: 0.7049 - val_accuracy: 0.5260\n",
      "Epoch 8/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.7032 - accuracy: 0.5174 - val_loss: 0.6967 - val_accuracy: 0.5312\n",
      "Epoch 9/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6940 - accuracy: 0.5521 - val_loss: 0.6893 - val_accuracy: 0.5469\n",
      "Epoch 10/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6857 - accuracy: 0.5694 - val_loss: 0.6825 - val_accuracy: 0.5833\n",
      "Epoch 11/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6780 - accuracy: 0.6076 - val_loss: 0.6764 - val_accuracy: 0.6302\n",
      "Epoch 12/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6709 - accuracy: 0.6233 - val_loss: 0.6707 - val_accuracy: 0.6458\n",
      "Epoch 13/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.6644 - accuracy: 0.6372 - val_loss: 0.6656 - val_accuracy: 0.6823\n",
      "Epoch 14/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6583 - accuracy: 0.6510 - val_loss: 0.6608 - val_accuracy: 0.6771\n",
      "Epoch 15/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.6667 - val_loss: 0.6564 - val_accuracy: 0.6979\n",
      "Epoch 16/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.6771 - val_loss: 0.6524 - val_accuracy: 0.6979\n",
      "Epoch 17/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6429 - accuracy: 0.6771 - val_loss: 0.6487 - val_accuracy: 0.7031\n",
      "Epoch 18/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6385 - accuracy: 0.6875 - val_loss: 0.6452 - val_accuracy: 0.7031\n",
      "Epoch 19/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6344 - accuracy: 0.6823 - val_loss: 0.6420 - val_accuracy: 0.7031\n",
      "Epoch 20/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6305 - accuracy: 0.6892 - val_loss: 0.6390 - val_accuracy: 0.7031\n",
      "Epoch 21/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.6875 - val_loss: 0.6362 - val_accuracy: 0.7031\n",
      "Epoch 22/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.6858 - val_loss: 0.6336 - val_accuracy: 0.6823\n",
      "Epoch 23/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6204 - accuracy: 0.6910 - val_loss: 0.6312 - val_accuracy: 0.6719\n",
      "Epoch 24/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6174 - accuracy: 0.6892 - val_loss: 0.6289 - val_accuracy: 0.6771\n",
      "Epoch 25/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.6875 - val_loss: 0.6267 - val_accuracy: 0.6771\n",
      "Epoch 26/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.6892 - val_loss: 0.6247 - val_accuracy: 0.6719\n",
      "Epoch 27/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6093 - accuracy: 0.6858 - val_loss: 0.6228 - val_accuracy: 0.6719\n",
      "Epoch 28/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6069 - accuracy: 0.6823 - val_loss: 0.6209 - val_accuracy: 0.6667\n",
      "Epoch 29/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6046 - accuracy: 0.6788 - val_loss: 0.6192 - val_accuracy: 0.6615\n",
      "Epoch 30/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6024 - accuracy: 0.6823 - val_loss: 0.6176 - val_accuracy: 0.6667\n",
      "Epoch 31/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.6003 - accuracy: 0.6771 - val_loss: 0.6160 - val_accuracy: 0.6667\n",
      "Epoch 32/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5983 - accuracy: 0.6771 - val_loss: 0.6145 - val_accuracy: 0.6667\n",
      "Epoch 33/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.6753 - val_loss: 0.6131 - val_accuracy: 0.6667\n",
      "Epoch 34/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5945 - accuracy: 0.6771 - val_loss: 0.6117 - val_accuracy: 0.6719\n",
      "Epoch 35/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.6736 - val_loss: 0.6104 - val_accuracy: 0.6719\n",
      "Epoch 36/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5910 - accuracy: 0.6736 - val_loss: 0.6091 - val_accuracy: 0.6667\n",
      "Epoch 37/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5893 - accuracy: 0.6771 - val_loss: 0.6079 - val_accuracy: 0.6667\n",
      "Epoch 38/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5877 - accuracy: 0.6771 - val_loss: 0.6067 - val_accuracy: 0.6667\n",
      "Epoch 39/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5862 - accuracy: 0.6771 - val_loss: 0.6056 - val_accuracy: 0.6667\n",
      "Epoch 40/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.6771 - val_loss: 0.6045 - val_accuracy: 0.6615\n",
      "Epoch 41/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5832 - accuracy: 0.6771 - val_loss: 0.6034 - val_accuracy: 0.6615\n",
      "Epoch 42/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5818 - accuracy: 0.6771 - val_loss: 0.6024 - val_accuracy: 0.6615\n",
      "Epoch 43/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5803 - accuracy: 0.6771 - val_loss: 0.6014 - val_accuracy: 0.6615\n",
      "Epoch 44/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.6788 - val_loss: 0.6004 - val_accuracy: 0.6615\n",
      "Epoch 45/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5776 - accuracy: 0.6788 - val_loss: 0.5994 - val_accuracy: 0.6615\n",
      "Epoch 46/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.6788 - val_loss: 0.5984 - val_accuracy: 0.6615\n",
      "Epoch 47/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5750 - accuracy: 0.6771 - val_loss: 0.5975 - val_accuracy: 0.6615\n",
      "Epoch 48/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5738 - accuracy: 0.6771 - val_loss: 0.5966 - val_accuracy: 0.6615\n",
      "Epoch 49/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5725 - accuracy: 0.6788 - val_loss: 0.5957 - val_accuracy: 0.6615\n",
      "Epoch 50/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5713 - accuracy: 0.6771 - val_loss: 0.5948 - val_accuracy: 0.6615\n",
      "Epoch 51/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5701 - accuracy: 0.6788 - val_loss: 0.5940 - val_accuracy: 0.6615\n",
      "Epoch 52/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.6788 - val_loss: 0.5931 - val_accuracy: 0.6615\n",
      "Epoch 53/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5677 - accuracy: 0.6788 - val_loss: 0.5923 - val_accuracy: 0.6615\n",
      "Epoch 54/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.6806 - val_loss: 0.5915 - val_accuracy: 0.6667\n",
      "Epoch 55/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5655 - accuracy: 0.6806 - val_loss: 0.5906 - val_accuracy: 0.6667\n",
      "Epoch 56/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.6788 - val_loss: 0.5898 - val_accuracy: 0.6667\n",
      "Epoch 57/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.5633 - accuracy: 0.6788 - val_loss: 0.5890 - val_accuracy: 0.6719\n",
      "Epoch 58/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5622 - accuracy: 0.6788 - val_loss: 0.5883 - val_accuracy: 0.6719\n",
      "Epoch 59/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.6788 - val_loss: 0.5875 - val_accuracy: 0.6719\n",
      "Epoch 60/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.6806 - val_loss: 0.5867 - val_accuracy: 0.6667\n",
      "Epoch 61/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5590 - accuracy: 0.6788 - val_loss: 0.5859 - val_accuracy: 0.6667\n",
      "Epoch 62/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.6806 - val_loss: 0.5852 - val_accuracy: 0.6667\n",
      "Epoch 63/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5569 - accuracy: 0.6806 - val_loss: 0.5845 - val_accuracy: 0.6667\n",
      "Epoch 64/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5560 - accuracy: 0.6806 - val_loss: 0.5837 - val_accuracy: 0.6667\n",
      "Epoch 65/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.6823 - val_loss: 0.5830 - val_accuracy: 0.6667\n",
      "Epoch 66/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5539 - accuracy: 0.6788 - val_loss: 0.5823 - val_accuracy: 0.6667\n",
      "Epoch 67/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5529 - accuracy: 0.6788 - val_loss: 0.5816 - val_accuracy: 0.6667\n",
      "Epoch 68/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5519 - accuracy: 0.6771 - val_loss: 0.5809 - val_accuracy: 0.6667\n",
      "Epoch 69/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.6771 - val_loss: 0.5803 - val_accuracy: 0.6667\n",
      "Epoch 70/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.6771 - val_loss: 0.5796 - val_accuracy: 0.6667\n",
      "Epoch 71/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5491 - accuracy: 0.6771 - val_loss: 0.5790 - val_accuracy: 0.6667\n",
      "Epoch 72/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.5481 - accuracy: 0.6771 - val_loss: 0.5783 - val_accuracy: 0.6667\n",
      "Epoch 73/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5472 - accuracy: 0.6823 - val_loss: 0.5777 - val_accuracy: 0.6667\n",
      "Epoch 74/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.6823 - val_loss: 0.5770 - val_accuracy: 0.6667\n",
      "Epoch 75/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5453 - accuracy: 0.6840 - val_loss: 0.5764 - val_accuracy: 0.6667\n",
      "Epoch 76/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5444 - accuracy: 0.6858 - val_loss: 0.5757 - val_accuracy: 0.6667\n",
      "Epoch 77/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.6858 - val_loss: 0.5751 - val_accuracy: 0.6667\n",
      "Epoch 78/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.6875 - val_loss: 0.5745 - val_accuracy: 0.6719\n",
      "Epoch 79/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5418 - accuracy: 0.6875 - val_loss: 0.5739 - val_accuracy: 0.6719\n",
      "Epoch 80/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.6840 - val_loss: 0.5733 - val_accuracy: 0.6719\n",
      "Epoch 81/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.6840 - val_loss: 0.5727 - val_accuracy: 0.6771\n",
      "Epoch 82/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.6840 - val_loss: 0.5721 - val_accuracy: 0.6771\n",
      "Epoch 83/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.6823 - val_loss: 0.5715 - val_accuracy: 0.6771\n",
      "Epoch 84/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.6840 - val_loss: 0.5709 - val_accuracy: 0.6771\n",
      "Epoch 85/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.6840 - val_loss: 0.5703 - val_accuracy: 0.6771\n",
      "Epoch 86/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.6858 - val_loss: 0.5697 - val_accuracy: 0.6823\n",
      "Epoch 87/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5349 - accuracy: 0.6858 - val_loss: 0.5691 - val_accuracy: 0.6823\n",
      "Epoch 88/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5341 - accuracy: 0.6858 - val_loss: 0.5686 - val_accuracy: 0.6823\n",
      "Epoch 89/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.6858 - val_loss: 0.5680 - val_accuracy: 0.6823\n",
      "Epoch 90/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.6840 - val_loss: 0.5675 - val_accuracy: 0.6823\n",
      "Epoch 91/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.6858 - val_loss: 0.5669 - val_accuracy: 0.6823\n",
      "Epoch 92/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5310 - accuracy: 0.6840 - val_loss: 0.5664 - val_accuracy: 0.6875\n",
      "Epoch 93/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.6840 - val_loss: 0.5658 - val_accuracy: 0.6875\n",
      "Epoch 94/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5294 - accuracy: 0.6875 - val_loss: 0.5653 - val_accuracy: 0.6927\n",
      "Epoch 95/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.6892 - val_loss: 0.5648 - val_accuracy: 0.6927\n",
      "Epoch 96/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.6892 - val_loss: 0.5643 - val_accuracy: 0.6927\n",
      "Epoch 97/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.6927 - val_loss: 0.5638 - val_accuracy: 0.6875\n",
      "Epoch 98/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.6944 - val_loss: 0.5633 - val_accuracy: 0.6875\n",
      "Epoch 99/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.6944 - val_loss: 0.5628 - val_accuracy: 0.6927\n",
      "Epoch 100/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.6962 - val_loss: 0.5623 - val_accuracy: 0.6927\n",
      "Epoch 101/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.6962 - val_loss: 0.5618 - val_accuracy: 0.6927\n",
      "Epoch 102/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.6962 - val_loss: 0.5614 - val_accuracy: 0.6927\n",
      "Epoch 103/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.6979 - val_loss: 0.5609 - val_accuracy: 0.6927\n",
      "Epoch 104/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5223 - accuracy: 0.6979 - val_loss: 0.5604 - val_accuracy: 0.6927\n",
      "Epoch 105/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5216 - accuracy: 0.6997 - val_loss: 0.5599 - val_accuracy: 0.6927\n",
      "Epoch 106/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.7014 - val_loss: 0.5595 - val_accuracy: 0.6927\n",
      "Epoch 107/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.7014 - val_loss: 0.5590 - val_accuracy: 0.6927\n",
      "Epoch 108/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5197 - accuracy: 0.7014 - val_loss: 0.5586 - val_accuracy: 0.6875\n",
      "Epoch 109/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5190 - accuracy: 0.6997 - val_loss: 0.5581 - val_accuracy: 0.6875\n",
      "Epoch 110/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5184 - accuracy: 0.6997 - val_loss: 0.5577 - val_accuracy: 0.6875\n",
      "Epoch 111/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5177 - accuracy: 0.6997 - val_loss: 0.5572 - val_accuracy: 0.6927\n",
      "Epoch 112/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7031 - val_loss: 0.5568 - val_accuracy: 0.6927\n",
      "Epoch 113/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.6997 - val_loss: 0.5563 - val_accuracy: 0.6979\n",
      "Epoch 114/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.6997 - val_loss: 0.5559 - val_accuracy: 0.6979\n",
      "Epoch 115/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5153 - accuracy: 0.7049 - val_loss: 0.5555 - val_accuracy: 0.6979\n",
      "Epoch 116/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5147 - accuracy: 0.7031 - val_loss: 0.5551 - val_accuracy: 0.6979\n",
      "Epoch 117/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7049 - val_loss: 0.5546 - val_accuracy: 0.6979\n",
      "Epoch 118/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5134 - accuracy: 0.7049 - val_loss: 0.5542 - val_accuracy: 0.6979\n",
      "Epoch 119/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.7101 - val_loss: 0.5538 - val_accuracy: 0.6979\n",
      "Epoch 120/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7118 - val_loss: 0.5534 - val_accuracy: 0.6979\n",
      "Epoch 121/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7135 - val_loss: 0.5530 - val_accuracy: 0.6979\n",
      "Epoch 122/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7118 - val_loss: 0.5526 - val_accuracy: 0.7083\n",
      "Epoch 123/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.7118 - val_loss: 0.5522 - val_accuracy: 0.7083\n",
      "Epoch 124/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5099 - accuracy: 0.7135 - val_loss: 0.5518 - val_accuracy: 0.7083\n",
      "Epoch 125/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.7135 - val_loss: 0.5514 - val_accuracy: 0.7083\n",
      "Epoch 126/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7135 - val_loss: 0.5510 - val_accuracy: 0.7083\n",
      "Epoch 127/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.7135 - val_loss: 0.5506 - val_accuracy: 0.7083\n",
      "Epoch 128/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7153 - val_loss: 0.5502 - val_accuracy: 0.7135\n",
      "Epoch 129/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.7188 - val_loss: 0.5499 - val_accuracy: 0.7083\n",
      "Epoch 130/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.7188 - val_loss: 0.5495 - val_accuracy: 0.7135\n",
      "Epoch 131/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5060 - accuracy: 0.7188 - val_loss: 0.5491 - val_accuracy: 0.7135\n",
      "Epoch 132/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.7188 - val_loss: 0.5487 - val_accuracy: 0.7135\n",
      "Epoch 133/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7188 - val_loss: 0.5484 - val_accuracy: 0.7135\n",
      "Epoch 134/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7188 - val_loss: 0.5480 - val_accuracy: 0.7083\n",
      "Epoch 135/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5040 - accuracy: 0.7222 - val_loss: 0.5477 - val_accuracy: 0.7083\n",
      "Epoch 136/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5034 - accuracy: 0.7205 - val_loss: 0.5473 - val_accuracy: 0.7083\n",
      "Epoch 137/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7188 - val_loss: 0.5470 - val_accuracy: 0.7083\n",
      "Epoch 138/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7257 - val_loss: 0.5467 - val_accuracy: 0.7083\n",
      "Epoch 139/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.7222 - val_loss: 0.5463 - val_accuracy: 0.7083\n",
      "Epoch 140/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5015 - accuracy: 0.7222 - val_loss: 0.5460 - val_accuracy: 0.7083\n",
      "Epoch 141/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5011 - accuracy: 0.7240 - val_loss: 0.5457 - val_accuracy: 0.7083\n",
      "Epoch 142/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.7240 - val_loss: 0.5453 - val_accuracy: 0.6979\n",
      "Epoch 143/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.5001 - accuracy: 0.7240 - val_loss: 0.5450 - val_accuracy: 0.6979\n",
      "Epoch 144/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4996 - accuracy: 0.7274 - val_loss: 0.5447 - val_accuracy: 0.6979\n",
      "Epoch 145/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4992 - accuracy: 0.7274 - val_loss: 0.5444 - val_accuracy: 0.6927\n",
      "Epoch 146/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.7274 - val_loss: 0.5441 - val_accuracy: 0.6927\n",
      "Epoch 147/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4983 - accuracy: 0.7292 - val_loss: 0.5438 - val_accuracy: 0.6979\n",
      "Epoch 148/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4978 - accuracy: 0.7292 - val_loss: 0.5435 - val_accuracy: 0.6979\n",
      "Epoch 149/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.7274 - val_loss: 0.5433 - val_accuracy: 0.6979\n",
      "Epoch 150/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.7257 - val_loss: 0.5430 - val_accuracy: 0.6979\n",
      "Epoch 151/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.7257 - val_loss: 0.5427 - val_accuracy: 0.6979\n",
      "Epoch 152/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4961 - accuracy: 0.7257 - val_loss: 0.5424 - val_accuracy: 0.6927\n",
      "Epoch 153/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.7257 - val_loss: 0.5421 - val_accuracy: 0.6979\n",
      "Epoch 154/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.7222 - val_loss: 0.5419 - val_accuracy: 0.6979\n",
      "Epoch 155/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4948 - accuracy: 0.7240 - val_loss: 0.5416 - val_accuracy: 0.6979\n",
      "Epoch 156/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4944 - accuracy: 0.7240 - val_loss: 0.5413 - val_accuracy: 0.6979\n",
      "Epoch 157/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7274 - val_loss: 0.5411 - val_accuracy: 0.6979\n",
      "Epoch 158/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4937 - accuracy: 0.7292 - val_loss: 0.5409 - val_accuracy: 0.6979\n",
      "Epoch 159/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.7309 - val_loss: 0.5406 - val_accuracy: 0.6979\n",
      "Epoch 160/1500\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.7309 - val_loss: 0.5404 - val_accuracy: 0.6979\n",
      "Epoch 161/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4925 - accuracy: 0.7326 - val_loss: 0.5401 - val_accuracy: 0.6979\n",
      "Epoch 162/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.7326 - val_loss: 0.5399 - val_accuracy: 0.6979\n",
      "Epoch 163/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7344 - val_loss: 0.5397 - val_accuracy: 0.6979\n",
      "Epoch 164/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4914 - accuracy: 0.7326 - val_loss: 0.5395 - val_accuracy: 0.6927\n",
      "Epoch 165/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7326 - val_loss: 0.5392 - val_accuracy: 0.6927\n",
      "Epoch 166/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4908 - accuracy: 0.7326 - val_loss: 0.5390 - val_accuracy: 0.6875\n",
      "Epoch 167/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4904 - accuracy: 0.7292 - val_loss: 0.5388 - val_accuracy: 0.6927\n",
      "Epoch 168/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7309 - val_loss: 0.5386 - val_accuracy: 0.6927\n",
      "Epoch 169/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.7309 - val_loss: 0.5384 - val_accuracy: 0.6979\n",
      "Epoch 170/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7326 - val_loss: 0.5382 - val_accuracy: 0.6979\n",
      "Epoch 171/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4891 - accuracy: 0.7361 - val_loss: 0.5380 - val_accuracy: 0.6979\n",
      "Epoch 172/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7378 - val_loss: 0.5378 - val_accuracy: 0.6979\n",
      "Epoch 173/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4884 - accuracy: 0.7396 - val_loss: 0.5376 - val_accuracy: 0.6979\n",
      "Epoch 174/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.7396 - val_loss: 0.5374 - val_accuracy: 0.6927\n",
      "Epoch 175/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4878 - accuracy: 0.7396 - val_loss: 0.5372 - val_accuracy: 0.7031\n",
      "Epoch 176/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.7413 - val_loss: 0.5370 - val_accuracy: 0.7031\n",
      "Epoch 177/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4872 - accuracy: 0.7413 - val_loss: 0.5368 - val_accuracy: 0.7083\n",
      "Epoch 178/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4869 - accuracy: 0.7431 - val_loss: 0.5366 - val_accuracy: 0.7083\n",
      "Epoch 179/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4866 - accuracy: 0.7431 - val_loss: 0.5365 - val_accuracy: 0.7083\n",
      "Epoch 180/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4863 - accuracy: 0.7448 - val_loss: 0.5363 - val_accuracy: 0.7083\n",
      "Epoch 181/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4860 - accuracy: 0.7448 - val_loss: 0.5361 - val_accuracy: 0.7135\n",
      "Epoch 182/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4856 - accuracy: 0.7431 - val_loss: 0.5359 - val_accuracy: 0.7135\n",
      "Epoch 183/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4854 - accuracy: 0.7448 - val_loss: 0.5357 - val_accuracy: 0.7135\n",
      "Epoch 184/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7448 - val_loss: 0.5355 - val_accuracy: 0.7188\n",
      "Epoch 185/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.7465 - val_loss: 0.5354 - val_accuracy: 0.7188\n",
      "Epoch 186/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4845 - accuracy: 0.7465 - val_loss: 0.5352 - val_accuracy: 0.7188\n",
      "Epoch 187/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7483 - val_loss: 0.5350 - val_accuracy: 0.7240\n",
      "Epoch 188/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4839 - accuracy: 0.7465 - val_loss: 0.5348 - val_accuracy: 0.7240\n",
      "Epoch 189/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.7465 - val_loss: 0.5347 - val_accuracy: 0.7292\n",
      "Epoch 190/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4833 - accuracy: 0.7483 - val_loss: 0.5345 - val_accuracy: 0.7292\n",
      "Epoch 191/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7483 - val_loss: 0.5343 - val_accuracy: 0.7292\n",
      "Epoch 192/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.7465 - val_loss: 0.5342 - val_accuracy: 0.7292\n",
      "Epoch 193/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.7483 - val_loss: 0.5340 - val_accuracy: 0.7292\n",
      "Epoch 194/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4823 - accuracy: 0.7465 - val_loss: 0.5339 - val_accuracy: 0.7344\n",
      "Epoch 195/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7465 - val_loss: 0.5337 - val_accuracy: 0.7396\n",
      "Epoch 196/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7465 - val_loss: 0.5336 - val_accuracy: 0.7344\n",
      "Epoch 197/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4816 - accuracy: 0.7483 - val_loss: 0.5334 - val_accuracy: 0.7344\n",
      "Epoch 198/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7483 - val_loss: 0.5332 - val_accuracy: 0.7344\n",
      "Epoch 199/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4810 - accuracy: 0.7500 - val_loss: 0.5331 - val_accuracy: 0.7344\n",
      "Epoch 200/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7500 - val_loss: 0.5330 - val_accuracy: 0.7344\n",
      "Epoch 201/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.7500 - val_loss: 0.5328 - val_accuracy: 0.7292\n",
      "Epoch 202/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4802 - accuracy: 0.7500 - val_loss: 0.5327 - val_accuracy: 0.7292\n",
      "Epoch 203/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4800 - accuracy: 0.7500 - val_loss: 0.5326 - val_accuracy: 0.7292\n",
      "Epoch 204/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4798 - accuracy: 0.7500 - val_loss: 0.5324 - val_accuracy: 0.7292\n",
      "Epoch 205/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7500 - val_loss: 0.5323 - val_accuracy: 0.7292\n",
      "Epoch 206/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7500 - val_loss: 0.5322 - val_accuracy: 0.7240\n",
      "Epoch 207/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7517 - val_loss: 0.5321 - val_accuracy: 0.7240\n",
      "Epoch 208/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4788 - accuracy: 0.7517 - val_loss: 0.5319 - val_accuracy: 0.7240\n",
      "Epoch 209/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4785 - accuracy: 0.7535 - val_loss: 0.5318 - val_accuracy: 0.7240\n",
      "Epoch 210/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4784 - accuracy: 0.7552 - val_loss: 0.5317 - val_accuracy: 0.7240\n",
      "Epoch 211/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.7535 - val_loss: 0.5316 - val_accuracy: 0.7240\n",
      "Epoch 212/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.7552 - val_loss: 0.5314 - val_accuracy: 0.7240\n",
      "Epoch 213/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.7552 - val_loss: 0.5313 - val_accuracy: 0.7240\n",
      "Epoch 214/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4774 - accuracy: 0.7569 - val_loss: 0.5312 - val_accuracy: 0.7240\n",
      "Epoch 215/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4773 - accuracy: 0.7587 - val_loss: 0.5311 - val_accuracy: 0.7240\n",
      "Epoch 216/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7587 - val_loss: 0.5310 - val_accuracy: 0.7240\n",
      "Epoch 217/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4768 - accuracy: 0.7604 - val_loss: 0.5309 - val_accuracy: 0.7240\n",
      "Epoch 218/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7622 - val_loss: 0.5308 - val_accuracy: 0.7188\n",
      "Epoch 219/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7622 - val_loss: 0.5307 - val_accuracy: 0.7188\n",
      "Epoch 220/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4762 - accuracy: 0.7604 - val_loss: 0.5305 - val_accuracy: 0.7188\n",
      "Epoch 221/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7622 - val_loss: 0.5304 - val_accuracy: 0.7188\n",
      "Epoch 222/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.7622 - val_loss: 0.5303 - val_accuracy: 0.7188\n",
      "Epoch 223/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7639 - val_loss: 0.5302 - val_accuracy: 0.7135\n",
      "Epoch 224/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4754 - accuracy: 0.7622 - val_loss: 0.5301 - val_accuracy: 0.7188\n",
      "Epoch 225/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7622 - val_loss: 0.5300 - val_accuracy: 0.7135\n",
      "Epoch 226/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4750 - accuracy: 0.7622 - val_loss: 0.5299 - val_accuracy: 0.7135\n",
      "Epoch 227/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7639 - val_loss: 0.5298 - val_accuracy: 0.7135\n",
      "Epoch 228/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4746 - accuracy: 0.7639 - val_loss: 0.5297 - val_accuracy: 0.7188\n",
      "Epoch 229/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7639 - val_loss: 0.5296 - val_accuracy: 0.7188\n",
      "Epoch 230/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4742 - accuracy: 0.7639 - val_loss: 0.5295 - val_accuracy: 0.7188\n",
      "Epoch 231/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.7639 - val_loss: 0.5295 - val_accuracy: 0.7188\n",
      "Epoch 232/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7622 - val_loss: 0.5294 - val_accuracy: 0.7188\n",
      "Epoch 233/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4737 - accuracy: 0.7622 - val_loss: 0.5293 - val_accuracy: 0.7188\n",
      "Epoch 234/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7622 - val_loss: 0.5292 - val_accuracy: 0.7135\n",
      "Epoch 235/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.7622 - val_loss: 0.5291 - val_accuracy: 0.7188\n",
      "Epoch 236/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7604 - val_loss: 0.5290 - val_accuracy: 0.7188\n",
      "Epoch 237/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4730 - accuracy: 0.7604 - val_loss: 0.5289 - val_accuracy: 0.7188\n",
      "Epoch 238/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7639 - val_loss: 0.5288 - val_accuracy: 0.7188\n",
      "Epoch 239/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4727 - accuracy: 0.7622 - val_loss: 0.5287 - val_accuracy: 0.7240\n",
      "Epoch 240/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4725 - accuracy: 0.7604 - val_loss: 0.5286 - val_accuracy: 0.7240\n",
      "Epoch 241/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7622 - val_loss: 0.5286 - val_accuracy: 0.7240\n",
      "Epoch 242/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7604 - val_loss: 0.5285 - val_accuracy: 0.7240\n",
      "Epoch 243/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7639 - val_loss: 0.5284 - val_accuracy: 0.7292\n",
      "Epoch 244/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7622 - val_loss: 0.5283 - val_accuracy: 0.7292\n",
      "Epoch 245/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4718 - accuracy: 0.7639 - val_loss: 0.5282 - val_accuracy: 0.7292\n",
      "Epoch 246/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.7622 - val_loss: 0.5281 - val_accuracy: 0.7292\n",
      "Epoch 247/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7622 - val_loss: 0.5281 - val_accuracy: 0.7292\n",
      "Epoch 248/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7622 - val_loss: 0.5280 - val_accuracy: 0.7292\n",
      "Epoch 249/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7622 - val_loss: 0.5279 - val_accuracy: 0.7292\n",
      "Epoch 250/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7639 - val_loss: 0.5278 - val_accuracy: 0.7292\n",
      "Epoch 251/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7639 - val_loss: 0.5277 - val_accuracy: 0.7292\n",
      "Epoch 252/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.7639 - val_loss: 0.5277 - val_accuracy: 0.7292\n",
      "Epoch 253/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4706 - accuracy: 0.7639 - val_loss: 0.5276 - val_accuracy: 0.7292\n",
      "Epoch 254/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7639 - val_loss: 0.5275 - val_accuracy: 0.7292\n",
      "Epoch 255/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7622 - val_loss: 0.5274 - val_accuracy: 0.7292\n",
      "Epoch 256/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4701 - accuracy: 0.7639 - val_loss: 0.5274 - val_accuracy: 0.7292\n",
      "Epoch 257/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7622 - val_loss: 0.5273 - val_accuracy: 0.7292\n",
      "Epoch 258/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.7639 - val_loss: 0.5272 - val_accuracy: 0.7292\n",
      "Epoch 259/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4697 - accuracy: 0.7604 - val_loss: 0.5271 - val_accuracy: 0.7292\n",
      "Epoch 260/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.7639 - val_loss: 0.5271 - val_accuracy: 0.7240\n",
      "Epoch 261/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4694 - accuracy: 0.7622 - val_loss: 0.5270 - val_accuracy: 0.7240\n",
      "Epoch 262/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4693 - accuracy: 0.7604 - val_loss: 0.5269 - val_accuracy: 0.7240\n",
      "Epoch 263/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.7587 - val_loss: 0.5269 - val_accuracy: 0.7292\n",
      "Epoch 264/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4690 - accuracy: 0.7587 - val_loss: 0.5268 - val_accuracy: 0.7292\n",
      "Epoch 265/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.7604 - val_loss: 0.5267 - val_accuracy: 0.7292\n",
      "Epoch 266/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4687 - accuracy: 0.7622 - val_loss: 0.5267 - val_accuracy: 0.7344\n",
      "Epoch 267/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.7622 - val_loss: 0.5266 - val_accuracy: 0.7344\n",
      "Epoch 268/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.7622 - val_loss: 0.5265 - val_accuracy: 0.7344\n",
      "Epoch 269/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7639 - val_loss: 0.5265 - val_accuracy: 0.7344\n",
      "Epoch 270/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7604 - val_loss: 0.5264 - val_accuracy: 0.7344\n",
      "Epoch 271/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7639 - val_loss: 0.5264 - val_accuracy: 0.7344\n",
      "Epoch 272/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.7604 - val_loss: 0.5263 - val_accuracy: 0.7344\n",
      "Epoch 273/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4679 - accuracy: 0.7604 - val_loss: 0.5262 - val_accuracy: 0.7344\n",
      "Epoch 274/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3895 - accuracy: 0.87 - 0s 4ms/step - loss: 0.4678 - accuracy: 0.7622 - val_loss: 0.5262 - val_accuracy: 0.7344\n",
      "Epoch 275/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.7622 - val_loss: 0.5261 - val_accuracy: 0.7344\n",
      "Epoch 276/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7622 - val_loss: 0.5261 - val_accuracy: 0.7344\n",
      "Epoch 277/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.7639 - val_loss: 0.5260 - val_accuracy: 0.7344\n",
      "Epoch 278/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.7656 - val_loss: 0.5260 - val_accuracy: 0.7344\n",
      "Epoch 279/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7639 - val_loss: 0.5259 - val_accuracy: 0.7344\n",
      "Epoch 280/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7656 - val_loss: 0.5259 - val_accuracy: 0.7344\n",
      "Epoch 281/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.7656 - val_loss: 0.5258 - val_accuracy: 0.7292\n",
      "Epoch 282/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7656 - val_loss: 0.5258 - val_accuracy: 0.7292\n",
      "Epoch 283/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4668 - accuracy: 0.7639 - val_loss: 0.5257 - val_accuracy: 0.7292\n",
      "Epoch 284/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.7639 - val_loss: 0.5257 - val_accuracy: 0.7292\n",
      "Epoch 285/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7639 - val_loss: 0.5256 - val_accuracy: 0.7292\n",
      "Epoch 286/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4664 - accuracy: 0.7639 - val_loss: 0.5256 - val_accuracy: 0.7292\n",
      "Epoch 287/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.7639 - val_loss: 0.5255 - val_accuracy: 0.7292\n",
      "Epoch 288/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4663 - accuracy: 0.7639 - val_loss: 0.5255 - val_accuracy: 0.7292\n",
      "Epoch 289/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7639 - val_loss: 0.5254 - val_accuracy: 0.7292\n",
      "Epoch 290/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7639 - val_loss: 0.5254 - val_accuracy: 0.7292\n",
      "Epoch 291/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7639 - val_loss: 0.5253 - val_accuracy: 0.7292\n",
      "Epoch 292/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7656 - val_loss: 0.5252 - val_accuracy: 0.7292\n",
      "Epoch 293/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.7656 - val_loss: 0.5252 - val_accuracy: 0.7292\n",
      "Epoch 294/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.7674 - val_loss: 0.5251 - val_accuracy: 0.7292\n",
      "Epoch 295/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.7656 - val_loss: 0.5251 - val_accuracy: 0.7292\n",
      "Epoch 296/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.7656 - val_loss: 0.5250 - val_accuracy: 0.7292\n",
      "Epoch 297/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7674 - val_loss: 0.5250 - val_accuracy: 0.7292\n",
      "Epoch 298/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4652 - accuracy: 0.7691 - val_loss: 0.5249 - val_accuracy: 0.7292\n",
      "Epoch 299/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.7691 - val_loss: 0.5249 - val_accuracy: 0.7292\n",
      "Epoch 300/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.7691 - val_loss: 0.5248 - val_accuracy: 0.7292\n",
      "Epoch 301/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.7691 - val_loss: 0.5248 - val_accuracy: 0.7292\n",
      "Epoch 302/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.7691 - val_loss: 0.5247 - val_accuracy: 0.7292\n",
      "Epoch 303/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7691 - val_loss: 0.5247 - val_accuracy: 0.7292\n",
      "Epoch 304/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7708 - val_loss: 0.5246 - val_accuracy: 0.7292\n",
      "Epoch 305/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4645 - accuracy: 0.7708 - val_loss: 0.5246 - val_accuracy: 0.7292\n",
      "Epoch 306/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7708 - val_loss: 0.5245 - val_accuracy: 0.7292\n",
      "Epoch 307/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.7708 - val_loss: 0.5245 - val_accuracy: 0.7292\n",
      "Epoch 308/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7691 - val_loss: 0.5244 - val_accuracy: 0.7292\n",
      "Epoch 309/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4641 - accuracy: 0.7708 - val_loss: 0.5244 - val_accuracy: 0.7292\n",
      "Epoch 310/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4641 - accuracy: 0.7691 - val_loss: 0.5243 - val_accuracy: 0.7292\n",
      "Epoch 311/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7708 - val_loss: 0.5243 - val_accuracy: 0.7292\n",
      "Epoch 312/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.7726 - val_loss: 0.5242 - val_accuracy: 0.7292\n",
      "Epoch 313/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4638 - accuracy: 0.7726 - val_loss: 0.5242 - val_accuracy: 0.7292\n",
      "Epoch 314/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4637 - accuracy: 0.7708 - val_loss: 0.5241 - val_accuracy: 0.7292\n",
      "Epoch 315/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7726 - val_loss: 0.5241 - val_accuracy: 0.7292\n",
      "Epoch 316/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7726 - val_loss: 0.5240 - val_accuracy: 0.7292\n",
      "Epoch 317/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.7726 - val_loss: 0.5240 - val_accuracy: 0.7292\n",
      "Epoch 318/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7708 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
      "Epoch 319/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7726 - val_loss: 0.5239 - val_accuracy: 0.7292\n",
      "Epoch 320/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.7708 - val_loss: 0.5238 - val_accuracy: 0.7292\n",
      "Epoch 321/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4631 - accuracy: 0.7708 - val_loss: 0.5238 - val_accuracy: 0.7292\n",
      "Epoch 322/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.7726 - val_loss: 0.5237 - val_accuracy: 0.7292\n",
      "Epoch 323/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.7708 - val_loss: 0.5236 - val_accuracy: 0.7292\n",
      "Epoch 324/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7726 - val_loss: 0.5236 - val_accuracy: 0.7396\n",
      "Epoch 325/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.7743 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
      "Epoch 326/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7726 - val_loss: 0.5235 - val_accuracy: 0.7396\n",
      "Epoch 327/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7726 - val_loss: 0.5234 - val_accuracy: 0.7396\n",
      "Epoch 328/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7726 - val_loss: 0.5234 - val_accuracy: 0.7396\n",
      "Epoch 329/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7726 - val_loss: 0.5233 - val_accuracy: 0.7396\n",
      "Epoch 330/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7726 - val_loss: 0.5233 - val_accuracy: 0.7344\n",
      "Epoch 331/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7726 - val_loss: 0.5233 - val_accuracy: 0.7344\n",
      "Epoch 332/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4622 - accuracy: 0.7726 - val_loss: 0.5232 - val_accuracy: 0.7344\n",
      "Epoch 333/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.7726 - val_loss: 0.5232 - val_accuracy: 0.7344\n",
      "Epoch 334/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.7726 - val_loss: 0.5231 - val_accuracy: 0.7396\n",
      "Epoch 335/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4619 - accuracy: 0.7726 - val_loss: 0.5231 - val_accuracy: 0.7396\n",
      "Epoch 336/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7726 - val_loss: 0.5230 - val_accuracy: 0.7396\n",
      "Epoch 337/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4617 - accuracy: 0.7726 - val_loss: 0.5230 - val_accuracy: 0.7396\n",
      "Epoch 338/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.7726 - val_loss: 0.5230 - val_accuracy: 0.7396\n",
      "Epoch 339/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.7726 - val_loss: 0.5229 - val_accuracy: 0.7396\n",
      "Epoch 340/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.7726 - val_loss: 0.5229 - val_accuracy: 0.7448\n",
      "Epoch 341/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7726 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
      "Epoch 342/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7726 - val_loss: 0.5228 - val_accuracy: 0.7448\n",
      "Epoch 343/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7726 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
      "Epoch 344/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.7726 - val_loss: 0.5227 - val_accuracy: 0.7448\n",
      "Epoch 345/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7708 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
      "Epoch 346/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7726 - val_loss: 0.5226 - val_accuracy: 0.7448\n",
      "Epoch 347/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.7726 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
      "Epoch 348/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7726 - val_loss: 0.5225 - val_accuracy: 0.7448\n",
      "Epoch 349/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4609 - accuracy: 0.7726 - val_loss: 0.5224 - val_accuracy: 0.7448\n",
      "Epoch 350/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4608 - accuracy: 0.7708 - val_loss: 0.5224 - val_accuracy: 0.7396\n",
      "Epoch 351/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7743 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
      "Epoch 352/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4606 - accuracy: 0.7726 - val_loss: 0.5223 - val_accuracy: 0.7396\n",
      "Epoch 353/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.7726 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
      "Epoch 354/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7708 - val_loss: 0.5222 - val_accuracy: 0.7396\n",
      "Epoch 355/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4605 - accuracy: 0.7708 - val_loss: 0.5221 - val_accuracy: 0.7396\n",
      "Epoch 356/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4604 - accuracy: 0.7708 - val_loss: 0.5221 - val_accuracy: 0.7396\n",
      "Epoch 357/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7708 - val_loss: 0.5220 - val_accuracy: 0.7396\n",
      "Epoch 358/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4603 - accuracy: 0.7708 - val_loss: 0.5220 - val_accuracy: 0.7396\n",
      "Epoch 359/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7708 - val_loss: 0.5220 - val_accuracy: 0.7396\n",
      "Epoch 360/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7708 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
      "Epoch 361/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7708 - val_loss: 0.5219 - val_accuracy: 0.7396\n",
      "Epoch 362/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7708 - val_loss: 0.5218 - val_accuracy: 0.7396\n",
      "Epoch 363/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7708 - val_loss: 0.5218 - val_accuracy: 0.7396\n",
      "Epoch 364/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7708 - val_loss: 0.5217 - val_accuracy: 0.7396\n",
      "Epoch 365/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7708 - val_loss: 0.5217 - val_accuracy: 0.7396\n",
      "Epoch 366/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7726 - val_loss: 0.5217 - val_accuracy: 0.7396\n",
      "Epoch 367/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4597 - accuracy: 0.7708 - val_loss: 0.5216 - val_accuracy: 0.7396\n",
      "Epoch 368/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4596 - accuracy: 0.7726 - val_loss: 0.5216 - val_accuracy: 0.7396\n",
      "Epoch 369/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7726 - val_loss: 0.5215 - val_accuracy: 0.7396\n",
      "Epoch 370/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7726 - val_loss: 0.5215 - val_accuracy: 0.7396\n",
      "Epoch 371/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7726 - val_loss: 0.5214 - val_accuracy: 0.7396\n",
      "Epoch 372/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7726 - val_loss: 0.5214 - val_accuracy: 0.7396\n",
      "Epoch 373/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.7708 - val_loss: 0.5214 - val_accuracy: 0.7396\n",
      "Epoch 374/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4593 - accuracy: 0.7708 - val_loss: 0.5213 - val_accuracy: 0.7396\n",
      "Epoch 375/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7726 - val_loss: 0.5213 - val_accuracy: 0.7396\n",
      "Epoch 376/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.7708 - val_loss: 0.5212 - val_accuracy: 0.7396\n",
      "Epoch 377/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7726 - val_loss: 0.5212 - val_accuracy: 0.7344\n",
      "Epoch 378/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4590 - accuracy: 0.7708 - val_loss: 0.5212 - val_accuracy: 0.7344\n",
      "Epoch 379/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4589 - accuracy: 0.7726 - val_loss: 0.5211 - val_accuracy: 0.7344\n",
      "Epoch 380/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4588 - accuracy: 0.7708 - val_loss: 0.5211 - val_accuracy: 0.7344\n",
      "Epoch 381/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7708 - val_loss: 0.5210 - val_accuracy: 0.7344\n",
      "Epoch 382/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.7708 - val_loss: 0.5210 - val_accuracy: 0.7344\n",
      "Epoch 383/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4587 - accuracy: 0.7691 - val_loss: 0.5209 - val_accuracy: 0.7344\n",
      "Epoch 384/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7691 - val_loss: 0.5209 - val_accuracy: 0.7344\n",
      "Epoch 385/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.7674 - val_loss: 0.5208 - val_accuracy: 0.7344\n",
      "Epoch 386/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7691 - val_loss: 0.5208 - val_accuracy: 0.7396\n",
      "Epoch 387/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4585 - accuracy: 0.7691 - val_loss: 0.5207 - val_accuracy: 0.7396\n",
      "Epoch 388/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7691 - val_loss: 0.5207 - val_accuracy: 0.7396\n",
      "Epoch 389/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.7674 - val_loss: 0.5206 - val_accuracy: 0.7396\n",
      "Epoch 390/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7691 - val_loss: 0.5206 - val_accuracy: 0.7396\n",
      "Epoch 391/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4583 - accuracy: 0.7691 - val_loss: 0.5206 - val_accuracy: 0.7396\n",
      "Epoch 392/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7691 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
      "Epoch 393/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7674 - val_loss: 0.5205 - val_accuracy: 0.7396\n",
      "Epoch 394/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.7691 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
      "Epoch 395/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.2982 - accuracy: 0.84 - 0s 3ms/step - loss: 0.4581 - accuracy: 0.7691 - val_loss: 0.5204 - val_accuracy: 0.7396\n",
      "Epoch 396/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7691 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
      "Epoch 397/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4580 - accuracy: 0.7691 - val_loss: 0.5203 - val_accuracy: 0.7396\n",
      "Epoch 398/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4579 - accuracy: 0.7691 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 399/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.7691 - val_loss: 0.5202 - val_accuracy: 0.7396\n",
      "Epoch 400/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4578 - accuracy: 0.7708 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 401/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.7691 - val_loss: 0.5201 - val_accuracy: 0.7396\n",
      "Epoch 402/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7691 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 403/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.7691 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 404/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7708 - val_loss: 0.5200 - val_accuracy: 0.7396\n",
      "Epoch 405/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.7691 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 406/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4575 - accuracy: 0.7691 - val_loss: 0.5199 - val_accuracy: 0.7396\n",
      "Epoch 407/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.7708 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 408/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7691 - val_loss: 0.5198 - val_accuracy: 0.7396\n",
      "Epoch 409/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7708 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 410/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7708 - val_loss: 0.5197 - val_accuracy: 0.7396\n",
      "Epoch 411/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4573 - accuracy: 0.7708 - val_loss: 0.5196 - val_accuracy: 0.7396\n",
      "Epoch 412/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4572 - accuracy: 0.7708 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 413/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.7708 - val_loss: 0.5195 - val_accuracy: 0.7396\n",
      "Epoch 414/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.7708 - val_loss: 0.5194 - val_accuracy: 0.7344\n",
      "Epoch 415/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4570 - accuracy: 0.7708 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 416/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.7708 - val_loss: 0.5193 - val_accuracy: 0.7344\n",
      "Epoch 417/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.7708 - val_loss: 0.5192 - val_accuracy: 0.7344\n",
      "Epoch 418/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4569 - accuracy: 0.7708 - val_loss: 0.5192 - val_accuracy: 0.7344\n",
      "Epoch 419/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7708 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 420/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7708 - val_loss: 0.5191 - val_accuracy: 0.7344\n",
      "Epoch 421/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7708 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 422/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.7708 - val_loss: 0.5190 - val_accuracy: 0.7344\n",
      "Epoch 423/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7726 - val_loss: 0.5189 - val_accuracy: 0.7292\n",
      "Epoch 424/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7726 - val_loss: 0.5188 - val_accuracy: 0.7292\n",
      "Epoch 425/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.7708 - val_loss: 0.5188 - val_accuracy: 0.7292\n",
      "Epoch 426/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.7708 - val_loss: 0.5187 - val_accuracy: 0.7292\n",
      "Epoch 427/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.7726 - val_loss: 0.5187 - val_accuracy: 0.7344\n",
      "Epoch 428/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7708 - val_loss: 0.5186 - val_accuracy: 0.7344\n",
      "Epoch 429/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7726 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
      "Epoch 430/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7691 - val_loss: 0.5185 - val_accuracy: 0.7344\n",
      "Epoch 431/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4563 - accuracy: 0.7708 - val_loss: 0.5184 - val_accuracy: 0.7344\n",
      "Epoch 432/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4562 - accuracy: 0.7708 - val_loss: 0.5184 - val_accuracy: 0.7344\n",
      "Epoch 433/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.7708 - val_loss: 0.5183 - val_accuracy: 0.7344\n",
      "Epoch 434/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7691 - val_loss: 0.5183 - val_accuracy: 0.7344\n",
      "Epoch 435/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4561 - accuracy: 0.7708 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
      "Epoch 436/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7708 - val_loss: 0.5182 - val_accuracy: 0.7344\n",
      "Epoch 437/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7691 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 438/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7691 - val_loss: 0.5181 - val_accuracy: 0.7344\n",
      "Epoch 439/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7691 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 440/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7691 - val_loss: 0.5180 - val_accuracy: 0.7344\n",
      "Epoch 441/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.7691 - val_loss: 0.5179 - val_accuracy: 0.7344\n",
      "Epoch 442/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4558 - accuracy: 0.7691 - val_loss: 0.5179 - val_accuracy: 0.7344\n",
      "Epoch 443/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7691 - val_loss: 0.5178 - val_accuracy: 0.7344\n",
      "Epoch 444/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4557 - accuracy: 0.7708 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 445/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7691 - val_loss: 0.5177 - val_accuracy: 0.7344\n",
      "Epoch 446/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7691 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 447/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7691 - val_loss: 0.5176 - val_accuracy: 0.7344\n",
      "Epoch 448/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.7691 - val_loss: 0.5175 - val_accuracy: 0.7344\n",
      "Epoch 449/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.7691 - val_loss: 0.5175 - val_accuracy: 0.7344\n",
      "Epoch 450/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7691 - val_loss: 0.5174 - val_accuracy: 0.7344\n",
      "Epoch 451/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7691 - val_loss: 0.5174 - val_accuracy: 0.7344\n",
      "Epoch 452/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7691 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 453/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7726 - val_loss: 0.5173 - val_accuracy: 0.7344\n",
      "Epoch 454/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4553 - accuracy: 0.7691 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 455/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7708 - val_loss: 0.5172 - val_accuracy: 0.7344\n",
      "Epoch 456/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7691 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 457/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.7691 - val_loss: 0.5171 - val_accuracy: 0.7344\n",
      "Epoch 458/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7708 - val_loss: 0.5170 - val_accuracy: 0.7344\n",
      "Epoch 459/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7743 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 460/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7726 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 461/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7726 - val_loss: 0.5169 - val_accuracy: 0.7344\n",
      "Epoch 462/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.7726 - val_loss: 0.5168 - val_accuracy: 0.7344\n",
      "Epoch 463/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7726 - val_loss: 0.5168 - val_accuracy: 0.7344\n",
      "Epoch 464/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7743 - val_loss: 0.5167 - val_accuracy: 0.7344\n",
      "Epoch 465/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7726 - val_loss: 0.5167 - val_accuracy: 0.7344\n",
      "Epoch 466/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4548 - accuracy: 0.7743 - val_loss: 0.5166 - val_accuracy: 0.7344\n",
      "Epoch 467/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7743 - val_loss: 0.5166 - val_accuracy: 0.7344\n",
      "Epoch 468/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7743 - val_loss: 0.5165 - val_accuracy: 0.7344\n",
      "Epoch 469/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7708 - val_loss: 0.5165 - val_accuracy: 0.7344\n",
      "Epoch 470/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4546 - accuracy: 0.7743 - val_loss: 0.5164 - val_accuracy: 0.7344\n",
      "Epoch 471/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7726 - val_loss: 0.5164 - val_accuracy: 0.7344\n",
      "Epoch 472/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4545 - accuracy: 0.7726 - val_loss: 0.5163 - val_accuracy: 0.7344\n",
      "Epoch 473/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7708 - val_loss: 0.5162 - val_accuracy: 0.7344\n",
      "Epoch 474/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7726 - val_loss: 0.5162 - val_accuracy: 0.7344\n",
      "Epoch 475/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.7726 - val_loss: 0.5161 - val_accuracy: 0.7344\n",
      "Epoch 476/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7726 - val_loss: 0.5161 - val_accuracy: 0.7344\n",
      "Epoch 477/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.7708 - val_loss: 0.5160 - val_accuracy: 0.7344\n",
      "Epoch 478/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.7726 - val_loss: 0.5160 - val_accuracy: 0.7344\n",
      "Epoch 479/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.7726 - val_loss: 0.5159 - val_accuracy: 0.7344\n",
      "Epoch 480/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7743 - val_loss: 0.5159 - val_accuracy: 0.7344\n",
      "Epoch 481/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7726 - val_loss: 0.5158 - val_accuracy: 0.7344\n",
      "Epoch 482/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7743 - val_loss: 0.5158 - val_accuracy: 0.7344\n",
      "Epoch 483/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.7726 - val_loss: 0.5157 - val_accuracy: 0.7344\n",
      "Epoch 484/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7726 - val_loss: 0.5157 - val_accuracy: 0.7344\n",
      "Epoch 485/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7743 - val_loss: 0.5156 - val_accuracy: 0.7344\n",
      "Epoch 486/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7743 - val_loss: 0.5156 - val_accuracy: 0.7344\n",
      "Epoch 487/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7743 - val_loss: 0.5155 - val_accuracy: 0.7344\n",
      "Epoch 488/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.7743 - val_loss: 0.5155 - val_accuracy: 0.7344\n",
      "Epoch 489/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.7726 - val_loss: 0.5154 - val_accuracy: 0.7344\n",
      "Epoch 490/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7743 - val_loss: 0.5153 - val_accuracy: 0.7344\n",
      "Epoch 491/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4537 - accuracy: 0.7743 - val_loss: 0.5153 - val_accuracy: 0.7344\n",
      "Epoch 492/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7743 - val_loss: 0.5152 - val_accuracy: 0.7344\n",
      "Epoch 493/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7743 - val_loss: 0.5152 - val_accuracy: 0.7344\n",
      "Epoch 494/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.7743 - val_loss: 0.5151 - val_accuracy: 0.7344\n",
      "Epoch 495/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.7743 - val_loss: 0.5151 - val_accuracy: 0.7344\n",
      "Epoch 496/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7743 - val_loss: 0.5150 - val_accuracy: 0.7344\n",
      "Epoch 497/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.7743 - val_loss: 0.5150 - val_accuracy: 0.7344\n",
      "Epoch 498/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4534 - accuracy: 0.7743 - val_loss: 0.5149 - val_accuracy: 0.7344\n",
      "Epoch 499/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.7743 - val_loss: 0.5149 - val_accuracy: 0.7344\n",
      "Epoch 500/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7743 - val_loss: 0.5148 - val_accuracy: 0.7344\n",
      "Epoch 501/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7708 - val_loss: 0.5147 - val_accuracy: 0.7344\n",
      "Epoch 502/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4533 - accuracy: 0.7726 - val_loss: 0.5147 - val_accuracy: 0.7344\n",
      "Epoch 503/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7743 - val_loss: 0.5146 - val_accuracy: 0.7344\n",
      "Epoch 504/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4532 - accuracy: 0.7743 - val_loss: 0.5146 - val_accuracy: 0.7344\n",
      "Epoch 505/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7743 - val_loss: 0.5145 - val_accuracy: 0.7344\n",
      "Epoch 506/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7726 - val_loss: 0.5145 - val_accuracy: 0.7344\n",
      "Epoch 507/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7743 - val_loss: 0.5144 - val_accuracy: 0.7344\n",
      "Epoch 508/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4531 - accuracy: 0.7760 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 509/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7778 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 510/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.7760 - val_loss: 0.5143 - val_accuracy: 0.7344\n",
      "Epoch 511/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7778 - val_loss: 0.5142 - val_accuracy: 0.7344\n",
      "Epoch 512/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4529 - accuracy: 0.7760 - val_loss: 0.5142 - val_accuracy: 0.7344\n",
      "Epoch 513/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7743 - val_loss: 0.5141 - val_accuracy: 0.7344\n",
      "Epoch 514/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.7743 - val_loss: 0.5141 - val_accuracy: 0.7344\n",
      "Epoch 515/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.7778 - val_loss: 0.5140 - val_accuracy: 0.7344\n",
      "Epoch 516/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4527 - accuracy: 0.7778 - val_loss: 0.5140 - val_accuracy: 0.7344\n",
      "Epoch 517/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7778 - val_loss: 0.5139 - val_accuracy: 0.7344\n",
      "Epoch 518/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4526 - accuracy: 0.7778 - val_loss: 0.5139 - val_accuracy: 0.7344\n",
      "Epoch 519/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.7760 - val_loss: 0.5138 - val_accuracy: 0.7344\n",
      "Epoch 520/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7778 - val_loss: 0.5138 - val_accuracy: 0.7344\n",
      "Epoch 521/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7778 - val_loss: 0.5137 - val_accuracy: 0.7344\n",
      "Epoch 522/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4525 - accuracy: 0.7778 - val_loss: 0.5137 - val_accuracy: 0.7344\n",
      "Epoch 523/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4524 - accuracy: 0.7778 - val_loss: 0.5136 - val_accuracy: 0.7344\n",
      "Epoch 524/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7760 - val_loss: 0.5136 - val_accuracy: 0.7344\n",
      "Epoch 525/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.7778 - val_loss: 0.5135 - val_accuracy: 0.7344\n",
      "Epoch 526/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7778 - val_loss: 0.5135 - val_accuracy: 0.7344\n",
      "Epoch 527/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4523 - accuracy: 0.7760 - val_loss: 0.5135 - val_accuracy: 0.7344\n",
      "Epoch 528/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.7778 - val_loss: 0.5134 - val_accuracy: 0.7344\n",
      "Epoch 529/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7795 - val_loss: 0.5134 - val_accuracy: 0.7344\n",
      "Epoch 530/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7778 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 531/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4522 - accuracy: 0.7795 - val_loss: 0.5133 - val_accuracy: 0.7344\n",
      "Epoch 532/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7778 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 533/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7778 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 534/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.7795 - val_loss: 0.5132 - val_accuracy: 0.7344\n",
      "Epoch 535/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7778 - val_loss: 0.5131 - val_accuracy: 0.7344\n",
      "Epoch 536/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4521 - accuracy: 0.7778 - val_loss: 0.5131 - val_accuracy: 0.7344\n",
      "Epoch 537/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7778 - val_loss: 0.5130 - val_accuracy: 0.7344\n",
      "Epoch 538/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7778 - val_loss: 0.5130 - val_accuracy: 0.7344\n",
      "Epoch 539/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7778 - val_loss: 0.5130 - val_accuracy: 0.7344\n",
      "Epoch 540/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
      "Epoch 541/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
      "Epoch 542/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4519 - accuracy: 0.7778 - val_loss: 0.5129 - val_accuracy: 0.7344\n",
      "Epoch 543/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.7795 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
      "Epoch 544/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.7344\n",
      "Epoch 545/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7778 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
      "Epoch 546/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7778 - val_loss: 0.5127 - val_accuracy: 0.7344\n",
      "Epoch 547/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7795 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
      "Epoch 548/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.7778 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
      "Epoch 549/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4517 - accuracy: 0.7778 - val_loss: 0.5126 - val_accuracy: 0.7344\n",
      "Epoch 550/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7778 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
      "Epoch 551/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7778 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
      "Epoch 552/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4516 - accuracy: 0.7778 - val_loss: 0.5125 - val_accuracy: 0.7344\n",
      "Epoch 553/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7795 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
      "Epoch 554/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7778 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
      "Epoch 555/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.7778 - val_loss: 0.5124 - val_accuracy: 0.7344\n",
      "Epoch 556/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.7778 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
      "Epoch 557/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7778 - val_loss: 0.5123 - val_accuracy: 0.7344\n",
      "Epoch 558/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7778 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
      "Epoch 559/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7778 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
      "Epoch 560/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7778 - val_loss: 0.5122 - val_accuracy: 0.7344\n",
      "Epoch 561/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7778 - val_loss: 0.5121 - val_accuracy: 0.7344\n",
      "Epoch 562/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7778 - val_loss: 0.5121 - val_accuracy: 0.7344\n",
      "Epoch 563/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7778 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
      "Epoch 564/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.7778 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
      "Epoch 565/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7778 - val_loss: 0.5120 - val_accuracy: 0.7344\n",
      "Epoch 566/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7778 - val_loss: 0.5119 - val_accuracy: 0.7344\n",
      "Epoch 567/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7778 - val_loss: 0.5119 - val_accuracy: 0.7344\n",
      "Epoch 568/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7778 - val_loss: 0.5118 - val_accuracy: 0.7344\n",
      "Epoch 569/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7760 - val_loss: 0.5118 - val_accuracy: 0.7344\n",
      "Epoch 570/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4511 - accuracy: 0.7760 - val_loss: 0.5118 - val_accuracy: 0.7344\n",
      "Epoch 571/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7760 - val_loss: 0.5117 - val_accuracy: 0.7344\n",
      "Epoch 572/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7760 - val_loss: 0.5117 - val_accuracy: 0.7344\n",
      "Epoch 573/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7760 - val_loss: 0.5117 - val_accuracy: 0.7344\n",
      "Epoch 574/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7760 - val_loss: 0.5116 - val_accuracy: 0.7344\n",
      "Epoch 575/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4509 - accuracy: 0.7778 - val_loss: 0.5116 - val_accuracy: 0.7344\n",
      "Epoch 576/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7760 - val_loss: 0.5116 - val_accuracy: 0.7344\n",
      "Epoch 577/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7760 - val_loss: 0.5115 - val_accuracy: 0.7344\n",
      "Epoch 578/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7760 - val_loss: 0.5115 - val_accuracy: 0.7344\n",
      "Epoch 579/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4508 - accuracy: 0.7778 - val_loss: 0.5115 - val_accuracy: 0.7344\n",
      "Epoch 580/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.7743 - val_loss: 0.5114 - val_accuracy: 0.7344\n",
      "Epoch 581/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.7760 - val_loss: 0.5114 - val_accuracy: 0.7344\n",
      "Epoch 582/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7778 - val_loss: 0.5114 - val_accuracy: 0.7344\n",
      "Epoch 583/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7760 - val_loss: 0.5113 - val_accuracy: 0.7344\n",
      "Epoch 584/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7760 - val_loss: 0.5113 - val_accuracy: 0.7344\n",
      "Epoch 585/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7778 - val_loss: 0.5113 - val_accuracy: 0.7344\n",
      "Epoch 586/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7795 - val_loss: 0.5112 - val_accuracy: 0.7344\n",
      "Epoch 587/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4506 - accuracy: 0.7778 - val_loss: 0.5112 - val_accuracy: 0.7344\n",
      "Epoch 588/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.7743 - val_loss: 0.5112 - val_accuracy: 0.7344\n",
      "Epoch 589/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7778 - val_loss: 0.5111 - val_accuracy: 0.7396\n",
      "Epoch 590/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7760 - val_loss: 0.5111 - val_accuracy: 0.7396\n",
      "Epoch 591/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.7760 - val_loss: 0.5111 - val_accuracy: 0.7396\n",
      "Epoch 592/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7760 - val_loss: 0.5111 - val_accuracy: 0.7448\n",
      "Epoch 593/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.7778 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
      "Epoch 594/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7778 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
      "Epoch 595/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7760 - val_loss: 0.5110 - val_accuracy: 0.7448\n",
      "Epoch 596/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4503 - accuracy: 0.7778 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
      "Epoch 597/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7778 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
      "Epoch 598/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.7778 - val_loss: 0.5109 - val_accuracy: 0.7448\n",
      "Epoch 599/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7778 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
      "Epoch 600/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4502 - accuracy: 0.7778 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
      "Epoch 601/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7778 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
      "Epoch 602/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.7778 - val_loss: 0.5108 - val_accuracy: 0.7448\n",
      "Epoch 603/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7778 - val_loss: 0.5107 - val_accuracy: 0.7448\n",
      "Epoch 604/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7778 - val_loss: 0.5107 - val_accuracy: 0.7448\n",
      "Epoch 605/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4500 - accuracy: 0.7778 - val_loss: 0.5107 - val_accuracy: 0.7448\n",
      "Epoch 606/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7778 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
      "Epoch 607/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7778 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
      "Epoch 608/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.7778 - val_loss: 0.5106 - val_accuracy: 0.7448\n",
      "Epoch 609/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7778 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
      "Epoch 610/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4499 - accuracy: 0.7760 - val_loss: 0.5105 - val_accuracy: 0.7448\n",
      "Epoch 611/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7778 - val_loss: 0.5105 - val_accuracy: 0.7500\n",
      "Epoch 612/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7778 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 613/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7778 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 614/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7778 - val_loss: 0.5104 - val_accuracy: 0.7500\n",
      "Epoch 615/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7795 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 616/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4497 - accuracy: 0.7778 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 617/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7778 - val_loss: 0.5103 - val_accuracy: 0.7500\n",
      "Epoch 618/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7778 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 619/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4496 - accuracy: 0.7795 - val_loss: 0.5102 - val_accuracy: 0.7500\n",
      "Epoch 620/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.7778 - val_loss: 0.5102 - val_accuracy: 0.7448\n",
      "Epoch 621/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4495 - accuracy: 0.7778 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
      "Epoch 622/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7778 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
      "Epoch 623/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7778 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
      "Epoch 624/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7778 - val_loss: 0.5101 - val_accuracy: 0.7448\n",
      "Epoch 625/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7778 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
      "Epoch 626/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4493 - accuracy: 0.7778 - val_loss: 0.5100 - val_accuracy: 0.7448\n",
      "Epoch 627/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4494 - accuracy: 0.7760 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
      "Epoch 628/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7795 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
      "Epoch 629/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.7778 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
      "Epoch 630/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7778 - val_loss: 0.5099 - val_accuracy: 0.7448\n",
      "Epoch 631/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7778 - val_loss: 0.5098 - val_accuracy: 0.7448\n",
      "Epoch 632/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7760 - val_loss: 0.5098 - val_accuracy: 0.7448\n",
      "Epoch 633/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7795 - val_loss: 0.5098 - val_accuracy: 0.7448\n",
      "Epoch 634/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.7760 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
      "Epoch 635/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7760 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
      "Epoch 636/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.7778 - val_loss: 0.5097 - val_accuracy: 0.7448\n",
      "Epoch 637/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7778 - val_loss: 0.5096 - val_accuracy: 0.7448\n",
      "Epoch 638/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7760 - val_loss: 0.5096 - val_accuracy: 0.7448\n",
      "Epoch 639/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7760 - val_loss: 0.5096 - val_accuracy: 0.7448\n",
      "Epoch 640/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7778 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
      "Epoch 641/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4489 - accuracy: 0.7760 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
      "Epoch 642/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.7795 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 643/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7760 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 644/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7778 - val_loss: 0.5094 - val_accuracy: 0.7448\n",
      "Epoch 645/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.7778 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
      "Epoch 646/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7778 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
      "Epoch 647/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7760 - val_loss: 0.5093 - val_accuracy: 0.7448\n",
      "Epoch 648/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4487 - accuracy: 0.7760 - val_loss: 0.5092 - val_accuracy: 0.7448\n",
      "Epoch 649/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7795 - val_loss: 0.5092 - val_accuracy: 0.7448\n",
      "Epoch 650/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.7760 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
      "Epoch 651/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7760 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
      "Epoch 652/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7778 - val_loss: 0.5091 - val_accuracy: 0.7448\n",
      "Epoch 653/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7760 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
      "Epoch 654/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7760 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
      "Epoch 655/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7760 - val_loss: 0.5089 - val_accuracy: 0.7448\n",
      "Epoch 656/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.7760 - val_loss: 0.5089 - val_accuracy: 0.7448\n",
      "Epoch 657/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4484 - accuracy: 0.7760 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
      "Epoch 658/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.3805 - accuracy: 0.75 - 0s 4ms/step - loss: 0.4484 - accuracy: 0.7743 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
      "Epoch 659/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7778 - val_loss: 0.5088 - val_accuracy: 0.7448\n",
      "Epoch 660/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7760 - val_loss: 0.5087 - val_accuracy: 0.7448\n",
      "Epoch 661/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7778 - val_loss: 0.5087 - val_accuracy: 0.7448\n",
      "Epoch 662/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7778 - val_loss: 0.5087 - val_accuracy: 0.7448\n",
      "Epoch 663/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7760 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 664/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7760 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 665/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7760 - val_loss: 0.5086 - val_accuracy: 0.7448\n",
      "Epoch 666/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7760 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 667/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.7760 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 668/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4482 - accuracy: 0.7760 - val_loss: 0.5085 - val_accuracy: 0.7448\n",
      "Epoch 669/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7760 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 670/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.7760 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 671/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.7760 - val_loss: 0.5084 - val_accuracy: 0.7448\n",
      "Epoch 672/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4480 - accuracy: 0.7760 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 673/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.5457 - accuracy: 0.71 - 0s 5ms/step - loss: 0.4480 - accuracy: 0.7743 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 674/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.7760 - val_loss: 0.5083 - val_accuracy: 0.7448\n",
      "Epoch 675/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7743 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 676/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7743 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 677/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7743 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 678/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7760 - val_loss: 0.5082 - val_accuracy: 0.7448\n",
      "Epoch 679/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7743 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 680/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7743 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 681/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7743 - val_loss: 0.5081 - val_accuracy: 0.7448\n",
      "Epoch 682/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4479 - accuracy: 0.7743 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 683/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7743 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 684/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7760 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 685/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.7743 - val_loss: 0.5080 - val_accuracy: 0.7448\n",
      "Epoch 686/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4477 - accuracy: 0.7743 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 687/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7743 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 688/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7760 - val_loss: 0.5079 - val_accuracy: 0.7448\n",
      "Epoch 689/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7743 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
      "Epoch 690/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4476 - accuracy: 0.7743 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
      "Epoch 691/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7743 - val_loss: 0.5078 - val_accuracy: 0.7448\n",
      "Epoch 692/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7743 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
      "Epoch 693/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4476 - accuracy: 0.7743 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
      "Epoch 694/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7743 - val_loss: 0.5077 - val_accuracy: 0.7448\n",
      "Epoch 695/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.7760 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
      "Epoch 696/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7743 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
      "Epoch 697/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4475 - accuracy: 0.7743 - val_loss: 0.5076 - val_accuracy: 0.7448\n",
      "Epoch 698/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7743 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 699/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7743 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 700/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7743 - val_loss: 0.5075 - val_accuracy: 0.7500\n",
      "Epoch 701/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7743 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 702/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7760 - val_loss: 0.5074 - val_accuracy: 0.7500\n",
      "Epoch 703/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.7743 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 704/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4473 - accuracy: 0.7760 - val_loss: 0.5073 - val_accuracy: 0.7500\n",
      "Epoch 705/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4472 - accuracy: 0.7760 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 706/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7743 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 707/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.7760 - val_loss: 0.5072 - val_accuracy: 0.7500\n",
      "Epoch 708/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7726 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 709/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.7743 - val_loss: 0.5071 - val_accuracy: 0.7500\n",
      "Epoch 710/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7743 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 711/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4470 - accuracy: 0.7743 - val_loss: 0.5070 - val_accuracy: 0.7500\n",
      "Epoch 712/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4471 - accuracy: 0.7726 - val_loss: 0.5069 - val_accuracy: 0.7500\n",
      "Epoch 713/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4470 - accuracy: 0.7726 - val_loss: 0.5069 - val_accuracy: 0.7552\n",
      "Epoch 714/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7760 - val_loss: 0.5068 - val_accuracy: 0.7552\n",
      "Epoch 715/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.7743 - val_loss: 0.5068 - val_accuracy: 0.7552\n",
      "Epoch 716/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7726 - val_loss: 0.5067 - val_accuracy: 0.7552\n",
      "Epoch 717/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.7760 - val_loss: 0.5067 - val_accuracy: 0.7552\n",
      "Epoch 718/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4469 - accuracy: 0.7760 - val_loss: 0.5066 - val_accuracy: 0.7552\n",
      "Epoch 719/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7726 - val_loss: 0.5066 - val_accuracy: 0.7552\n",
      "Epoch 720/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7760 - val_loss: 0.5065 - val_accuracy: 0.7552\n",
      "Epoch 721/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7743 - val_loss: 0.5065 - val_accuracy: 0.7552\n",
      "Epoch 722/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.7760 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 723/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7743 - val_loss: 0.5064 - val_accuracy: 0.7552\n",
      "Epoch 724/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7726 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 725/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4467 - accuracy: 0.7760 - val_loss: 0.5063 - val_accuracy: 0.7552\n",
      "Epoch 726/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7743 - val_loss: 0.5062 - val_accuracy: 0.7552\n",
      "Epoch 727/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7743 - val_loss: 0.5062 - val_accuracy: 0.7552\n",
      "Epoch 728/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.7760 - val_loss: 0.5062 - val_accuracy: 0.7552\n",
      "Epoch 729/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7743 - val_loss: 0.5061 - val_accuracy: 0.7552\n",
      "Epoch 730/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7743 - val_loss: 0.5061 - val_accuracy: 0.7552\n",
      "Epoch 731/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.7743 - val_loss: 0.5060 - val_accuracy: 0.7552\n",
      "Epoch 732/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7743 - val_loss: 0.5060 - val_accuracy: 0.7552\n",
      "Epoch 733/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7743 - val_loss: 0.5059 - val_accuracy: 0.7552\n",
      "Epoch 734/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7743 - val_loss: 0.5059 - val_accuracy: 0.7552\n",
      "Epoch 735/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7743 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
      "Epoch 736/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.7726 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
      "Epoch 737/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.7743 - val_loss: 0.5058 - val_accuracy: 0.7552\n",
      "Epoch 738/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.7743 - val_loss: 0.5057 - val_accuracy: 0.7552\n",
      "Epoch 739/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7743 - val_loss: 0.5057 - val_accuracy: 0.7552\n",
      "Epoch 740/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7552\n",
      "Epoch 741/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7726 - val_loss: 0.5056 - val_accuracy: 0.7552\n",
      "Epoch 742/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7743 - val_loss: 0.5056 - val_accuracy: 0.7552\n",
      "Epoch 743/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7743 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
      "Epoch 744/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.7743 - val_loss: 0.5055 - val_accuracy: 0.7552\n",
      "Epoch 745/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
      "Epoch 746/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4461 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
      "Epoch 747/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7743 - val_loss: 0.5054 - val_accuracy: 0.7552\n",
      "Epoch 748/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7743 - val_loss: 0.5053 - val_accuracy: 0.7552\n",
      "Epoch 749/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7726 - val_loss: 0.5053 - val_accuracy: 0.7552\n",
      "Epoch 750/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7743 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 751/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7743 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 752/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.7743 - val_loss: 0.5052 - val_accuracy: 0.7552\n",
      "Epoch 753/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.7743 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 754/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.7726 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 755/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7726 - val_loss: 0.5051 - val_accuracy: 0.7552\n",
      "Epoch 756/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.7743 - val_loss: 0.5050 - val_accuracy: 0.7552\n",
      "Epoch 757/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7743 - val_loss: 0.5050 - val_accuracy: 0.7552\n",
      "Epoch 758/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7743 - val_loss: 0.5049 - val_accuracy: 0.7552\n",
      "Epoch 759/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.7743 - val_loss: 0.5049 - val_accuracy: 0.7552\n",
      "Epoch 760/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7743 - val_loss: 0.5049 - val_accuracy: 0.7552\n",
      "Epoch 761/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7743 - val_loss: 0.5048 - val_accuracy: 0.7552\n",
      "Epoch 762/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7726 - val_loss: 0.5048 - val_accuracy: 0.7552\n",
      "Epoch 763/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7726 - val_loss: 0.5048 - val_accuracy: 0.7552\n",
      "Epoch 764/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.7743 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 765/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7743 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 766/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7743 - val_loss: 0.5047 - val_accuracy: 0.7552\n",
      "Epoch 767/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7726 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 768/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4456 - accuracy: 0.7760 - val_loss: 0.5046 - val_accuracy: 0.7552\n",
      "Epoch 769/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7726 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 770/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7726 - val_loss: 0.5046 - val_accuracy: 0.7604\n",
      "Epoch 771/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7726 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 772/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7743 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 773/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.7760 - val_loss: 0.5045 - val_accuracy: 0.7604\n",
      "Epoch 774/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.7726 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 775/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7743 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 776/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7743 - val_loss: 0.5044 - val_accuracy: 0.7604\n",
      "Epoch 777/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7743 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 778/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.7743 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 779/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.7743 - val_loss: 0.5043 - val_accuracy: 0.7604\n",
      "Epoch 780/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7743 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 781/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7743 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 782/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7743 - val_loss: 0.5042 - val_accuracy: 0.7604\n",
      "Epoch 783/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7743 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 784/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4451 - accuracy: 0.7743 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 785/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4452 - accuracy: 0.7743 - val_loss: 0.5041 - val_accuracy: 0.7604\n",
      "Epoch 786/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7743 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 787/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7743 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 788/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7743 - val_loss: 0.5040 - val_accuracy: 0.7604\n",
      "Epoch 789/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.7743 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 790/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.7743 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 791/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.7743 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 792/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7743 - val_loss: 0.5039 - val_accuracy: 0.7604\n",
      "Epoch 793/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7743 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 794/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7743 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 795/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4449 - accuracy: 0.7743 - val_loss: 0.5038 - val_accuracy: 0.7604\n",
      "Epoch 796/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7743 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 797/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.7743 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 798/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7743 - val_loss: 0.5037 - val_accuracy: 0.7604\n",
      "Epoch 799/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7743 - val_loss: 0.5036 - val_accuracy: 0.7604\n",
      "Epoch 800/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7743 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 801/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4448 - accuracy: 0.7743 - val_loss: 0.5036 - val_accuracy: 0.7656\n",
      "Epoch 802/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.7743 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 803/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4447 - accuracy: 0.7743 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 804/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4447 - accuracy: 0.7743 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 805/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.7743 - val_loss: 0.5035 - val_accuracy: 0.7656\n",
      "Epoch 806/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7743 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 807/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7743 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 808/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7743 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 809/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7743 - val_loss: 0.5034 - val_accuracy: 0.7656\n",
      "Epoch 810/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.7743 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 811/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.7743 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 812/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7743 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 813/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.7743 - val_loss: 0.5033 - val_accuracy: 0.7656\n",
      "Epoch 814/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.7743 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 815/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7743 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 816/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7743 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 817/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.7726 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 818/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.7743 - val_loss: 0.5032 - val_accuracy: 0.7656\n",
      "Epoch 819/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4443 - accuracy: 0.7743 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 820/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4443 - accuracy: 0.7726 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 821/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4442 - accuracy: 0.7743 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 822/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7743 - val_loss: 0.5031 - val_accuracy: 0.7656\n",
      "Epoch 823/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.7743 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 824/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.7743 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 825/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7743 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 826/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7743 - val_loss: 0.5030 - val_accuracy: 0.7656\n",
      "Epoch 827/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7743 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 828/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7743 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 829/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4441 - accuracy: 0.7743 - val_loss: 0.5029 - val_accuracy: 0.7656\n",
      "Epoch 830/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7743 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 831/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7743 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 832/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.7726 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 833/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.7726 - val_loss: 0.5028 - val_accuracy: 0.7656\n",
      "Epoch 834/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7743 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 835/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7743 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 836/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7743 - val_loss: 0.5027 - val_accuracy: 0.7656\n",
      "Epoch 837/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7743 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 838/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7743 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 839/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4438 - accuracy: 0.7743 - val_loss: 0.5026 - val_accuracy: 0.7656\n",
      "Epoch 840/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.7760 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 841/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7743 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 842/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7743 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 843/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7743 - val_loss: 0.5025 - val_accuracy: 0.7656\n",
      "Epoch 844/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7743 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 845/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4436 - accuracy: 0.7743 - val_loss: 0.5024 - val_accuracy: 0.7656\n",
      "Epoch 846/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4436 - accuracy: 0.7743 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 847/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7760 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 848/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.7743 - val_loss: 0.5023 - val_accuracy: 0.7656\n",
      "Epoch 849/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7726 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 850/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7743 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 851/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.7743 - val_loss: 0.5022 - val_accuracy: 0.7656\n",
      "Epoch 852/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7743 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 853/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4435 - accuracy: 0.7743 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 854/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7726 - val_loss: 0.5021 - val_accuracy: 0.7656\n",
      "Epoch 855/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.7726 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 856/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7743 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 857/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7726 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 858/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7726 - val_loss: 0.5020 - val_accuracy: 0.7656\n",
      "Epoch 859/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7743 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 860/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4434 - accuracy: 0.7743 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 861/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7743 - val_loss: 0.5019 - val_accuracy: 0.7656\n",
      "Epoch 862/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7743 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 863/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7708 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 864/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7726 - val_loss: 0.5018 - val_accuracy: 0.7656\n",
      "Epoch 865/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4432 - accuracy: 0.7726 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
      "Epoch 866/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4432 - accuracy: 0.7743 - val_loss: 0.5017 - val_accuracy: 0.7656\n",
      "Epoch 867/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7726 - val_loss: 0.5016 - val_accuracy: 0.7656\n",
      "Epoch 868/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7726 - val_loss: 0.5016 - val_accuracy: 0.7656\n",
      "Epoch 869/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7726 - val_loss: 0.5016 - val_accuracy: 0.7656\n",
      "Epoch 870/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7708 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
      "Epoch 871/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.7726 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
      "Epoch 872/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7691 - val_loss: 0.5015 - val_accuracy: 0.7656\n",
      "Epoch 873/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7726 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 874/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.7708 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 875/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7708 - val_loss: 0.5014 - val_accuracy: 0.7656\n",
      "Epoch 876/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.7743 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 877/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.7708 - val_loss: 0.5013 - val_accuracy: 0.7656\n",
      "Epoch 878/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7708 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 879/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7726 - val_loss: 0.5012 - val_accuracy: 0.7656\n",
      "Epoch 880/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7708 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 881/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7708 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 882/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.7726 - val_loss: 0.5011 - val_accuracy: 0.7656\n",
      "Epoch 883/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7726 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 884/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.7726 - val_loss: 0.5010 - val_accuracy: 0.7656\n",
      "Epoch 885/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.7708 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 886/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4426 - accuracy: 0.7726 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 887/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4426 - accuracy: 0.7708 - val_loss: 0.5009 - val_accuracy: 0.7656\n",
      "Epoch 888/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7708 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
      "Epoch 889/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.7743 - val_loss: 0.5008 - val_accuracy: 0.7656\n",
      "Epoch 890/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7691 - val_loss: 0.5007 - val_accuracy: 0.7656\n",
      "Epoch 891/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4425 - accuracy: 0.7726 - val_loss: 0.5007 - val_accuracy: 0.7656\n",
      "Epoch 892/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.7674 - val_loss: 0.5007 - val_accuracy: 0.7656\n",
      "Epoch 893/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7708 - val_loss: 0.5006 - val_accuracy: 0.7656\n",
      "Epoch 894/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7708 - val_loss: 0.5006 - val_accuracy: 0.7656\n",
      "Epoch 895/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4424 - accuracy: 0.7743 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 896/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7726 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 897/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7708 - val_loss: 0.5005 - val_accuracy: 0.7656\n",
      "Epoch 898/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7708 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
      "Epoch 899/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7691 - val_loss: 0.5004 - val_accuracy: 0.7656\n",
      "Epoch 900/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
      "Epoch 901/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.7708 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
      "Epoch 902/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7691 - val_loss: 0.5003 - val_accuracy: 0.7656\n",
      "Epoch 903/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7691 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 904/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.7726 - val_loss: 0.5002 - val_accuracy: 0.7656\n",
      "Epoch 905/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7726 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 906/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7691 - val_loss: 0.5001 - val_accuracy: 0.7656\n",
      "Epoch 907/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7674 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
      "Epoch 908/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.7691 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
      "Epoch 909/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7691 - val_loss: 0.5000 - val_accuracy: 0.7656\n",
      "Epoch 910/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7674 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
      "Epoch 911/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.7708 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
      "Epoch 912/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.7691 - val_loss: 0.4999 - val_accuracy: 0.7656\n",
      "Epoch 913/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7708 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
      "Epoch 914/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7656 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
      "Epoch 915/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4419 - accuracy: 0.7656 - val_loss: 0.4998 - val_accuracy: 0.7656\n",
      "Epoch 916/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7691 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
      "Epoch 917/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.7708 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
      "Epoch 918/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7691 - val_loss: 0.4997 - val_accuracy: 0.7656\n",
      "Epoch 919/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7708 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
      "Epoch 920/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7674 - val_loss: 0.4996 - val_accuracy: 0.7656\n",
      "Epoch 921/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7691 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 922/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7691 - val_loss: 0.4995 - val_accuracy: 0.7656\n",
      "Epoch 923/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7708 - val_loss: 0.4995 - val_accuracy: 0.7708\n",
      "Epoch 924/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7656 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
      "Epoch 925/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.7674 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
      "Epoch 926/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7708 - val_loss: 0.4994 - val_accuracy: 0.7708\n",
      "Epoch 927/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4416 - accuracy: 0.7691 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
      "Epoch 928/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.7674 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
      "Epoch 929/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7691 - val_loss: 0.4993 - val_accuracy: 0.7708\n",
      "Epoch 930/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.7674 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
      "Epoch 931/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7708 - val_loss: 0.4992 - val_accuracy: 0.7708\n",
      "Epoch 932/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7691 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 933/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4415 - accuracy: 0.7674 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 934/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7691 - val_loss: 0.4991 - val_accuracy: 0.7708\n",
      "Epoch 935/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7708 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
      "Epoch 936/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7708 - val_loss: 0.4990 - val_accuracy: 0.7708\n",
      "Epoch 937/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.7726 - val_loss: 0.4989 - val_accuracy: 0.7708\n",
      "Epoch 938/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7691 - val_loss: 0.4989 - val_accuracy: 0.7708\n",
      "Epoch 939/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7708 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
      "Epoch 940/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.7691 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
      "Epoch 941/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4413 - accuracy: 0.7691 - val_loss: 0.4988 - val_accuracy: 0.7708\n",
      "Epoch 942/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.7726 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 943/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4412 - accuracy: 0.7708 - val_loss: 0.4987 - val_accuracy: 0.7708\n",
      "Epoch 944/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7708 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
      "Epoch 945/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.7708 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
      "Epoch 946/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7691 - val_loss: 0.4986 - val_accuracy: 0.7708\n",
      "Epoch 947/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.7708 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
      "Epoch 948/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4411 - accuracy: 0.7691 - val_loss: 0.4985 - val_accuracy: 0.7708\n",
      "Epoch 949/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7726 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
      "Epoch 950/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7726 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
      "Epoch 951/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.7691 - val_loss: 0.4984 - val_accuracy: 0.7708\n",
      "Epoch 952/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7726 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
      "Epoch 953/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7708 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
      "Epoch 954/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4409 - accuracy: 0.7708 - val_loss: 0.4983 - val_accuracy: 0.7708\n",
      "Epoch 955/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.7743 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
      "Epoch 956/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7726 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
      "Epoch 957/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7708 - val_loss: 0.4982 - val_accuracy: 0.7708\n",
      "Epoch 958/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.7726 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
      "Epoch 959/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4408 - accuracy: 0.7743 - val_loss: 0.4981 - val_accuracy: 0.7708\n",
      "Epoch 960/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7726 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 961/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7708 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 962/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7726 - val_loss: 0.4980 - val_accuracy: 0.7708\n",
      "Epoch 963/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.7760 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 964/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7743 - val_loss: 0.4979 - val_accuracy: 0.7708\n",
      "Epoch 965/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7708 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
      "Epoch 966/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.7743 - val_loss: 0.4978 - val_accuracy: 0.7708\n",
      "Epoch 967/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7743 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 968/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.7708 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 969/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7743 - val_loss: 0.4977 - val_accuracy: 0.7708\n",
      "Epoch 970/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4404 - accuracy: 0.7726 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 971/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7743 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 972/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7743 - val_loss: 0.4976 - val_accuracy: 0.7708\n",
      "Epoch 973/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7760 - val_loss: 0.4975 - val_accuracy: 0.7708\n",
      "Epoch 974/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7743 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 975/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7743 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 976/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7726 - val_loss: 0.4974 - val_accuracy: 0.7708\n",
      "Epoch 977/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7726 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
      "Epoch 978/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.7743 - val_loss: 0.4973 - val_accuracy: 0.7708\n",
      "Epoch 979/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.7743 - val_loss: 0.4972 - val_accuracy: 0.7708\n",
      "Epoch 980/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7760 - val_loss: 0.4972 - val_accuracy: 0.7708\n",
      "Epoch 981/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7743 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
      "Epoch 982/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4402 - accuracy: 0.7743 - val_loss: 0.4971 - val_accuracy: 0.7708\n",
      "Epoch 983/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4401 - accuracy: 0.7743 - val_loss: 0.4971 - val_accuracy: 0.7656\n",
      "Epoch 984/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
      "Epoch 985/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7743 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
      "Epoch 986/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7726 - val_loss: 0.4970 - val_accuracy: 0.7656\n",
      "Epoch 987/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
      "Epoch 988/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
      "Epoch 989/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7743 - val_loss: 0.4969 - val_accuracy: 0.7656\n",
      "Epoch 990/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
      "Epoch 991/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
      "Epoch 992/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4399 - accuracy: 0.7743 - val_loss: 0.4968 - val_accuracy: 0.7656\n",
      "Epoch 993/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
      "Epoch 994/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7743 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
      "Epoch 995/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4398 - accuracy: 0.7726 - val_loss: 0.4967 - val_accuracy: 0.7656\n",
      "Epoch 996/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4398 - accuracy: 0.7743 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 997/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7726 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 998/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7743 - val_loss: 0.4966 - val_accuracy: 0.7656\n",
      "Epoch 999/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.7726 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
      "Epoch 1000/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7743 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
      "Epoch 1001/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7726 - val_loss: 0.4965 - val_accuracy: 0.7656\n",
      "Epoch 1002/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7726 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 1003/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4396 - accuracy: 0.7743 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 1004/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7726 - val_loss: 0.4964 - val_accuracy: 0.7656\n",
      "Epoch 1005/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7726 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 1006/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7743 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 1007/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4395 - accuracy: 0.7708 - val_loss: 0.4963 - val_accuracy: 0.7656\n",
      "Epoch 1008/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7708 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 1009/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7708 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 1010/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7708 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 1011/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.7743 - val_loss: 0.4962 - val_accuracy: 0.7656\n",
      "Epoch 1012/1500\n",
      "18/18 [==============================] - ETA: 0s - loss: 0.4585 - accuracy: 0.75 - 0s 3ms/step - loss: 0.4394 - accuracy: 0.7743 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 1013/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7726 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 1014/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7726 - val_loss: 0.4961 - val_accuracy: 0.7656\n",
      "Epoch 1015/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4393 - accuracy: 0.7743 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 1016/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7726 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 1017/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4392 - accuracy: 0.7726 - val_loss: 0.4960 - val_accuracy: 0.7656\n",
      "Epoch 1018/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7691 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
      "Epoch 1019/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.7691 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
      "Epoch 1020/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7743 - val_loss: 0.4959 - val_accuracy: 0.7656\n",
      "Epoch 1021/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.7708 - val_loss: 0.4958 - val_accuracy: 0.7656\n",
      "Epoch 1022/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4391 - accuracy: 0.7708 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
      "Epoch 1023/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7743 - val_loss: 0.4958 - val_accuracy: 0.7708\n",
      "Epoch 1024/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.7708 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
      "Epoch 1025/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4390 - accuracy: 0.7726 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
      "Epoch 1026/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7708 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
      "Epoch 1027/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.7708 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
      "Epoch 1028/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7708 - val_loss: 0.4957 - val_accuracy: 0.7708\n",
      "Epoch 1029/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7708 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
      "Epoch 1030/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4389 - accuracy: 0.7691 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
      "Epoch 1031/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7708 - val_loss: 0.4956 - val_accuracy: 0.7708\n",
      "Epoch 1032/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.7708 - val_loss: 0.4955 - val_accuracy: 0.7708\n",
      "Epoch 1033/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7691 - val_loss: 0.4955 - val_accuracy: 0.7708\n",
      "Epoch 1034/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.7691 - val_loss: 0.4955 - val_accuracy: 0.7708\n",
      "Epoch 1035/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7726 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
      "Epoch 1036/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7708 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
      "Epoch 1037/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7708 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
      "Epoch 1038/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4387 - accuracy: 0.7691 - val_loss: 0.4954 - val_accuracy: 0.7708\n",
      "Epoch 1039/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4386 - accuracy: 0.7708 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
      "Epoch 1040/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7708 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
      "Epoch 1041/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7708 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
      "Epoch 1042/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.7708 - val_loss: 0.4953 - val_accuracy: 0.7708\n",
      "Epoch 1043/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7691 - val_loss: 0.4952 - val_accuracy: 0.7708\n",
      "Epoch 1044/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7708 - val_loss: 0.4952 - val_accuracy: 0.7708\n",
      "Epoch 1045/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.7708 - val_loss: 0.4952 - val_accuracy: 0.7708\n",
      "Epoch 1046/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7726 - val_loss: 0.4951 - val_accuracy: 0.7708\n",
      "Epoch 1047/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7708 - val_loss: 0.4951 - val_accuracy: 0.7708\n",
      "Epoch 1048/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7708 - val_loss: 0.4951 - val_accuracy: 0.7708\n",
      "Epoch 1049/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7708 - val_loss: 0.4951 - val_accuracy: 0.7708\n",
      "Epoch 1050/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7674 - val_loss: 0.4950 - val_accuracy: 0.7708\n",
      "Epoch 1051/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7708 - val_loss: 0.4950 - val_accuracy: 0.7708\n",
      "Epoch 1052/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7708 - val_loss: 0.4950 - val_accuracy: 0.7708\n",
      "Epoch 1053/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.7691 - val_loss: 0.4950 - val_accuracy: 0.7708\n",
      "Epoch 1054/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7726 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
      "Epoch 1055/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7691 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
      "Epoch 1056/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7708 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
      "Epoch 1057/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.7674 - val_loss: 0.4949 - val_accuracy: 0.7708\n",
      "Epoch 1058/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4381 - accuracy: 0.7691 - val_loss: 0.4948 - val_accuracy: 0.7708\n",
      "Epoch 1059/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7691 - val_loss: 0.4948 - val_accuracy: 0.7708\n",
      "Epoch 1060/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.7708 - val_loss: 0.4948 - val_accuracy: 0.7708\n",
      "Epoch 1061/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7708 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
      "Epoch 1062/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.7691 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
      "Epoch 1063/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.7691 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
      "Epoch 1064/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.7708 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
      "Epoch 1065/1500\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 0.4379 - accuracy: 0.7726 - val_loss: 0.4947 - val_accuracy: 0.7708\n",
      "Epoch 1066/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.7674 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
      "Epoch 1067/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7726 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
      "Epoch 1068/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7708 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
      "Epoch 1069/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7708 - val_loss: 0.4946 - val_accuracy: 0.7708\n",
      "Epoch 1070/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7726 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
      "Epoch 1071/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7726 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
      "Epoch 1072/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4378 - accuracy: 0.7708 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
      "Epoch 1073/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7726 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
      "Epoch 1074/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7726 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
      "Epoch 1075/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7691 - val_loss: 0.4945 - val_accuracy: 0.7708\n",
      "Epoch 1076/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7726 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
      "Epoch 1077/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.7726 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
      "Epoch 1078/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7691 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
      "Epoch 1079/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7691 - val_loss: 0.4944 - val_accuracy: 0.7708\n",
      "Epoch 1080/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
      "Epoch 1081/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.7691 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
      "Epoch 1082/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7708 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
      "Epoch 1083/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7691 - val_loss: 0.4943 - val_accuracy: 0.7708\n",
      "Epoch 1084/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4375 - accuracy: 0.7726 - val_loss: 0.4943 - val_accuracy: 0.7760\n",
      "Epoch 1085/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.7691 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
      "Epoch 1086/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7708 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
      "Epoch 1087/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4374 - accuracy: 0.7726 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
      "Epoch 1088/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7691 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
      "Epoch 1089/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7708 - val_loss: 0.4942 - val_accuracy: 0.7760\n",
      "Epoch 1090/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7708 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
      "Epoch 1091/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
      "Epoch 1092/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.7691 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
      "Epoch 1093/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7691 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
      "Epoch 1094/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7708 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
      "Epoch 1095/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7726 - val_loss: 0.4941 - val_accuracy: 0.7760\n",
      "Epoch 1096/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.7691 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
      "Epoch 1097/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7691 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
      "Epoch 1098/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7726 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
      "Epoch 1099/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4372 - accuracy: 0.7726 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
      "Epoch 1100/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4372 - accuracy: 0.7691 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
      "Epoch 1101/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7691 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
      "Epoch 1102/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7691 - val_loss: 0.4940 - val_accuracy: 0.7760\n",
      "Epoch 1103/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7691 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
      "Epoch 1104/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.7708 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
      "Epoch 1105/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4370 - accuracy: 0.7726 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
      "Epoch 1106/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7726 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
      "Epoch 1107/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7726 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
      "Epoch 1108/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7726 - val_loss: 0.4939 - val_accuracy: 0.7760\n",
      "Epoch 1109/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7708 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
      "Epoch 1110/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7726 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
      "Epoch 1111/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7726 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
      "Epoch 1112/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
      "Epoch 1113/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4369 - accuracy: 0.7743 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
      "Epoch 1114/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4368 - accuracy: 0.7726 - val_loss: 0.4938 - val_accuracy: 0.7760\n",
      "Epoch 1115/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4368 - accuracy: 0.7726 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
      "Epoch 1116/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.7743 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
      "Epoch 1117/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7760 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
      "Epoch 1118/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7726 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
      "Epoch 1119/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7760 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
      "Epoch 1120/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7726 - val_loss: 0.4937 - val_accuracy: 0.7760\n",
      "Epoch 1121/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.7743 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
      "Epoch 1122/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7726 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
      "Epoch 1123/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.7760 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
      "Epoch 1124/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7743 - val_loss: 0.4936 - val_accuracy: 0.7760\n",
      "Epoch 1125/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7760 - val_loss: 0.4935 - val_accuracy: 0.7760\n",
      "Epoch 1126/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.7743 - val_loss: 0.4935 - val_accuracy: 0.7760\n",
      "Epoch 1127/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7743 - val_loss: 0.4935 - val_accuracy: 0.7760\n",
      "Epoch 1128/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7743 - val_loss: 0.4935 - val_accuracy: 0.7760\n",
      "Epoch 1129/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4364 - accuracy: 0.7743 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
      "Epoch 1130/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7743 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
      "Epoch 1131/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7726 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
      "Epoch 1132/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7743 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
      "Epoch 1133/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7743 - val_loss: 0.4934 - val_accuracy: 0.7760\n",
      "Epoch 1134/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.7743 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
      "Epoch 1135/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4363 - accuracy: 0.7760 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
      "Epoch 1136/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7743 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
      "Epoch 1137/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4362 - accuracy: 0.7726 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
      "Epoch 1138/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.7726 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
      "Epoch 1139/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7743 - val_loss: 0.4933 - val_accuracy: 0.7760\n",
      "Epoch 1140/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7743 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
      "Epoch 1141/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7743 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
      "Epoch 1142/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.7743 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
      "Epoch 1143/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4361 - accuracy: 0.7726 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
      "Epoch 1144/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.7743 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
      "Epoch 1145/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7743 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
      "Epoch 1146/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7726 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
      "Epoch 1147/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7726 - val_loss: 0.4932 - val_accuracy: 0.7760\n",
      "Epoch 1148/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.7726 - val_loss: 0.4931 - val_accuracy: 0.7760\n",
      "Epoch 1149/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4358 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7760\n",
      "Epoch 1150/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7726 - val_loss: 0.4931 - val_accuracy: 0.7760\n",
      "Epoch 1151/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7743 - val_loss: 0.4931 - val_accuracy: 0.7760\n",
      "Epoch 1152/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4358 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7760\n",
      "Epoch 1153/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7760 - val_loss: 0.4931 - val_accuracy: 0.7760\n",
      "Epoch 1154/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7743 - val_loss: 0.4931 - val_accuracy: 0.7760\n",
      "Epoch 1155/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7743 - val_loss: 0.4930 - val_accuracy: 0.7760\n",
      "Epoch 1156/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7726 - val_loss: 0.4930 - val_accuracy: 0.7760\n",
      "Epoch 1157/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4357 - accuracy: 0.7708 - val_loss: 0.4930 - val_accuracy: 0.7760\n",
      "Epoch 1158/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7726 - val_loss: 0.4930 - val_accuracy: 0.7760\n",
      "Epoch 1159/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.7778 - val_loss: 0.4930 - val_accuracy: 0.7760\n",
      "Epoch 1160/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4355 - accuracy: 0.7760 - val_loss: 0.4930 - val_accuracy: 0.7760\n",
      "Epoch 1161/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4355 - accuracy: 0.7743 - val_loss: 0.4929 - val_accuracy: 0.7760\n",
      "Epoch 1162/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7743 - val_loss: 0.4929 - val_accuracy: 0.7760\n",
      "Epoch 1163/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7778 - val_loss: 0.4929 - val_accuracy: 0.7760\n",
      "Epoch 1164/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7743 - val_loss: 0.4929 - val_accuracy: 0.7760\n",
      "Epoch 1165/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.7760 - val_loss: 0.4929 - val_accuracy: 0.7760\n",
      "Epoch 1166/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7760 - val_loss: 0.4929 - val_accuracy: 0.7760\n",
      "Epoch 1167/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.7760 - val_loss: 0.4929 - val_accuracy: 0.7760\n",
      "Epoch 1168/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7760 - val_loss: 0.4928 - val_accuracy: 0.7760\n",
      "Epoch 1169/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7778 - val_loss: 0.4928 - val_accuracy: 0.7760\n",
      "Epoch 1170/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4353 - accuracy: 0.7743 - val_loss: 0.4928 - val_accuracy: 0.7760\n",
      "Epoch 1171/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4352 - accuracy: 0.7743 - val_loss: 0.4928 - val_accuracy: 0.7760\n",
      "Epoch 1172/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7760 - val_loss: 0.4928 - val_accuracy: 0.7760\n",
      "Epoch 1173/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7760 - val_loss: 0.4928 - val_accuracy: 0.7760\n",
      "Epoch 1174/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7760 - val_loss: 0.4928 - val_accuracy: 0.7760\n",
      "Epoch 1175/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7760 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
      "Epoch 1176/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7760 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
      "Epoch 1177/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4351 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
      "Epoch 1178/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4350 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
      "Epoch 1179/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
      "Epoch 1180/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
      "Epoch 1181/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
      "Epoch 1182/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.7760 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
      "Epoch 1183/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
      "Epoch 1184/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
      "Epoch 1185/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
      "Epoch 1186/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
      "Epoch 1187/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7743 - val_loss: 0.4927 - val_accuracy: 0.7760\n",
      "Epoch 1188/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
      "Epoch 1189/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
      "Epoch 1190/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
      "Epoch 1191/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
      "Epoch 1192/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.7760 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
      "Epoch 1193/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4347 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
      "Epoch 1194/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4347 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
      "Epoch 1195/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4346 - accuracy: 0.7760 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
      "Epoch 1196/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
      "Epoch 1197/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7778 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
      "Epoch 1198/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.7760 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
      "Epoch 1199/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
      "Epoch 1200/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
      "Epoch 1201/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
      "Epoch 1202/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7743 - val_loss: 0.4926 - val_accuracy: 0.7760\n",
      "Epoch 1203/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7743 - val_loss: 0.4925 - val_accuracy: 0.7760\n",
      "Epoch 1204/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4345 - accuracy: 0.7760 - val_loss: 0.4925 - val_accuracy: 0.7760\n",
      "Epoch 1205/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7760\n",
      "Epoch 1206/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4344 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7760\n",
      "Epoch 1207/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.7760 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 1208/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7795 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 1209/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.7778 - val_loss: 0.4925 - val_accuracy: 0.7708\n",
      "Epoch 1210/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7778 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 1211/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7778 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 1212/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 1213/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.7778 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 1214/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7778 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 1215/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.7778 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 1216/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 1217/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 1218/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.7795 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 1219/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7778 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 1220/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7778 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 1221/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7778 - val_loss: 0.4924 - val_accuracy: 0.7708\n",
      "Epoch 1222/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4340 - accuracy: 0.7778 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1223/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7778 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1224/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1225/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7778 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1226/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.7778 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1227/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4339 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1228/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1229/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1230/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7778 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1231/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1232/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1233/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1234/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1235/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1236/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1237/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4336 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1238/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1239/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4336 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1240/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1241/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1242/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1243/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4334 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1244/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4334 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1245/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1246/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1247/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7795 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1248/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1249/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1250/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4333 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1251/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4333 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1252/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1253/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7708\n",
      "Epoch 1254/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1255/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4331 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1256/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1257/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4331 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1258/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1259/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1260/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1261/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1262/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7812 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1263/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1264/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1265/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1266/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1267/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1268/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4328 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1269/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1270/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1271/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4328 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1272/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7830 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1273/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1274/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1275/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1276/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1277/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4326 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1278/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1279/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1280/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1281/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.7882 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1282/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1283/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7882 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1284/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1285/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1286/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4324 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1287/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7882 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1288/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1289/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1290/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1291/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1292/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1293/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4322 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1294/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1295/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1296/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1297/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1298/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1299/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1300/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1301/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1302/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1303/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1304/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1305/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1306/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1307/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7656\n",
      "Epoch 1308/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1309/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1310/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.7847 - val_loss: 0.4922 - val_accuracy: 0.7604\n",
      "Epoch 1311/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1312/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1313/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1314/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1315/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1316/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1317/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1318/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1319/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1320/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1321/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1322/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1323/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1324/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1325/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1326/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1327/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1328/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1329/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1330/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7604\n",
      "Epoch 1331/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 1332/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 1333/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 1334/1500\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 1335/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 1336/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 1337/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 1338/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 1339/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4312 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 1340/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4312 - accuracy: 0.7865 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 1341/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 1342/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 1343/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 1344/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.4923 - val_accuracy: 0.7552\n",
      "Epoch 1345/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 1346/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 1347/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7604\n",
      "Epoch 1348/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1349/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4310 - accuracy: 0.7865 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1350/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1351/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1352/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7865 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1353/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1354/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1355/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1356/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1357/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1358/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1359/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4307 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1360/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1361/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1362/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1363/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4307 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1364/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1365/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1366/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1367/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1368/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1369/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1370/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.4924 - val_accuracy: 0.7656\n",
      "Epoch 1371/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7656\n",
      "Epoch 1372/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4305 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 1373/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 1374/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 1375/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 1376/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 1377/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 1378/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 1379/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4304 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 1380/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.4925 - val_accuracy: 0.7604\n",
      "Epoch 1381/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.7847 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 1382/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 1383/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 1384/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 1385/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.7847 - val_loss: 0.4926 - val_accuracy: 0.7604\n",
      "Epoch 1386/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 1387/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 1388/1500\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 1389/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 1390/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 1391/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 1392/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 1393/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 1394/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.4927 - val_accuracy: 0.7604\n",
      "Epoch 1395/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 1396/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 1397/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 1398/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 1399/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 1400/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4299 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 1401/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 1402/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 1403/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 1404/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.7847 - val_loss: 0.4928 - val_accuracy: 0.7604\n",
      "Epoch 1405/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
      "Epoch 1406/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
      "Epoch 1407/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
      "Epoch 1408/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
      "Epoch 1409/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
      "Epoch 1410/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
      "Epoch 1411/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
      "Epoch 1412/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
      "Epoch 1413/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.4929 - val_accuracy: 0.7604\n",
      "Epoch 1414/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.7847 - val_loss: 0.4930 - val_accuracy: 0.7604\n",
      "Epoch 1415/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7847 - val_loss: 0.4930 - val_accuracy: 0.7604\n",
      "Epoch 1416/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.7847 - val_loss: 0.4930 - val_accuracy: 0.7604\n",
      "Epoch 1417/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7847 - val_loss: 0.4930 - val_accuracy: 0.7604\n",
      "Epoch 1418/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7847 - val_loss: 0.4930 - val_accuracy: 0.7604\n",
      "Epoch 1419/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.7865 - val_loss: 0.4930 - val_accuracy: 0.7604\n",
      "Epoch 1420/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4294 - accuracy: 0.7847 - val_loss: 0.4931 - val_accuracy: 0.7604\n",
      "Epoch 1421/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7847 - val_loss: 0.4931 - val_accuracy: 0.7604\n",
      "Epoch 1422/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7847 - val_loss: 0.4931 - val_accuracy: 0.7604\n",
      "Epoch 1423/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7847 - val_loss: 0.4931 - val_accuracy: 0.7604\n",
      "Epoch 1424/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.4932 - val_accuracy: 0.7604\n",
      "Epoch 1425/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.7847 - val_loss: 0.4932 - val_accuracy: 0.7604\n",
      "Epoch 1426/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.7847 - val_loss: 0.4932 - val_accuracy: 0.7604\n",
      "Epoch 1427/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4292 - accuracy: 0.7865 - val_loss: 0.4932 - val_accuracy: 0.7604\n",
      "Epoch 1428/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.4932 - val_accuracy: 0.7604\n",
      "Epoch 1429/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.4932 - val_accuracy: 0.7604\n",
      "Epoch 1430/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.7865 - val_loss: 0.4932 - val_accuracy: 0.7604\n",
      "Epoch 1431/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
      "Epoch 1432/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
      "Epoch 1433/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
      "Epoch 1434/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7865 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
      "Epoch 1435/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.4933 - val_accuracy: 0.7604\n",
      "Epoch 1436/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.4934 - val_accuracy: 0.7604\n",
      "Epoch 1437/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4289 - accuracy: 0.7865 - val_loss: 0.4934 - val_accuracy: 0.7604\n",
      "Epoch 1438/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.4934 - val_accuracy: 0.7604\n",
      "Epoch 1439/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.4934 - val_accuracy: 0.7604\n",
      "Epoch 1440/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.4935 - val_accuracy: 0.7604\n",
      "Epoch 1441/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.7865 - val_loss: 0.4935 - val_accuracy: 0.7604\n",
      "Epoch 1442/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.4935 - val_accuracy: 0.7604\n",
      "Epoch 1443/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.7865 - val_loss: 0.4935 - val_accuracy: 0.7604\n",
      "Epoch 1444/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.4935 - val_accuracy: 0.7604\n",
      "Epoch 1445/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.4935 - val_accuracy: 0.7552\n",
      "Epoch 1446/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.4936 - val_accuracy: 0.7552\n",
      "Epoch 1447/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7865 - val_loss: 0.4936 - val_accuracy: 0.7552\n",
      "Epoch 1448/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.4936 - val_accuracy: 0.7552\n",
      "Epoch 1449/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.7865 - val_loss: 0.4936 - val_accuracy: 0.7552\n",
      "Epoch 1450/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.7865 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 1451/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 1452/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.4937 - val_accuracy: 0.7552\n",
      "Epoch 1453/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.4937 - val_accuracy: 0.7604\n",
      "Epoch 1454/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4284 - accuracy: 0.7865 - val_loss: 0.4938 - val_accuracy: 0.7604\n",
      "Epoch 1455/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.4938 - val_accuracy: 0.7604\n",
      "Epoch 1456/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.4938 - val_accuracy: 0.7604\n",
      "Epoch 1457/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.7865 - val_loss: 0.4938 - val_accuracy: 0.7604\n",
      "Epoch 1458/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7865 - val_loss: 0.4938 - val_accuracy: 0.7604\n",
      "Epoch 1459/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.7865 - val_loss: 0.4939 - val_accuracy: 0.7604\n",
      "Epoch 1460/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.7865 - val_loss: 0.4939 - val_accuracy: 0.7604\n",
      "Epoch 1461/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.7865 - val_loss: 0.4939 - val_accuracy: 0.7604\n",
      "Epoch 1462/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7847 - val_loss: 0.4939 - val_accuracy: 0.7604\n",
      "Epoch 1463/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.7882 - val_loss: 0.4940 - val_accuracy: 0.7604\n",
      "Epoch 1464/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.7865 - val_loss: 0.4940 - val_accuracy: 0.7604\n",
      "Epoch 1465/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7865 - val_loss: 0.4940 - val_accuracy: 0.7604\n",
      "Epoch 1466/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7865 - val_loss: 0.4940 - val_accuracy: 0.7604\n",
      "Epoch 1467/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.7865 - val_loss: 0.4941 - val_accuracy: 0.7604\n",
      "Epoch 1468/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.7847 - val_loss: 0.4941 - val_accuracy: 0.7604\n",
      "Epoch 1469/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7865 - val_loss: 0.4941 - val_accuracy: 0.7604\n",
      "Epoch 1470/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.7847 - val_loss: 0.4941 - val_accuracy: 0.7604\n",
      "Epoch 1471/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7847 - val_loss: 0.4941 - val_accuracy: 0.7604\n",
      "Epoch 1472/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7847 - val_loss: 0.4942 - val_accuracy: 0.7604\n",
      "Epoch 1473/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7847 - val_loss: 0.4942 - val_accuracy: 0.7604\n",
      "Epoch 1474/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.7882 - val_loss: 0.4942 - val_accuracy: 0.7604\n",
      "Epoch 1475/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7847 - val_loss: 0.4942 - val_accuracy: 0.7604\n",
      "Epoch 1476/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4278 - accuracy: 0.7847 - val_loss: 0.4942 - val_accuracy: 0.7604\n",
      "Epoch 1477/1500\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.7812 - val_loss: 0.4943 - val_accuracy: 0.7604\n",
      "Epoch 1478/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.7847 - val_loss: 0.4943 - val_accuracy: 0.7604\n",
      "Epoch 1479/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7847 - val_loss: 0.4943 - val_accuracy: 0.7604\n",
      "Epoch 1480/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7847 - val_loss: 0.4943 - val_accuracy: 0.7604\n",
      "Epoch 1481/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.7847 - val_loss: 0.4943 - val_accuracy: 0.7604\n",
      "Epoch 1482/1500\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 0.4276 - accuracy: 0.7865 - val_loss: 0.4943 - val_accuracy: 0.7604\n",
      "Epoch 1483/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.7812 - val_loss: 0.4943 - val_accuracy: 0.7604\n",
      "Epoch 1484/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7830 - val_loss: 0.4944 - val_accuracy: 0.7604\n",
      "Epoch 1485/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.7847 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 1486/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4275 - accuracy: 0.7847 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 1487/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4274 - accuracy: 0.7865 - val_loss: 0.4944 - val_accuracy: 0.7656\n",
      "Epoch 1488/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7847 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 1489/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.7847 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 1490/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7830 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 1491/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7847 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 1492/1500\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 0.4272 - accuracy: 0.7865 - val_loss: 0.4945 - val_accuracy: 0.7656\n",
      "Epoch 1493/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.7865 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 1494/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.7847 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 1495/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7865 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 1496/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7830 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 1497/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.7865 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 1498/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7865 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 1499/1500\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7830 - val_loss: 0.4946 - val_accuracy: 0.7656\n",
      "Epoch 1500/1500\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.4270 - accuracy: 0.7847 - val_loss: 0.4946 - val_accuracy: 0.7656\n"
     ]
    }
   ],
   "source": [
    "### BEGIN SOLUTION\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(6, input_shape=(8,), activation=\"relu\"))\n",
    "model_2.add(Dense(6,  activation=\"relu\"))\n",
    "model_2.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model_2.compile(SGD(lr = .003), \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "run_hist_2 = model_2.fit(X_train_norm, y_train, validation_data=(X_test_norm, y_test), epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist_2.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy over iterations')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = len(run_hist_2.history[\"loss\"])\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(range(n), (run_hist_2.history[\"loss\"]),'r.', label=\"Train Loss\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_loss\"]),'b.', label=\"Validation Loss\")\n",
    "ax.legend()\n",
    "ax.set_title('Loss over iterations')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(range(n), (run_hist_2.history[\"accuracy\"]),'r.', label=\"Train Acc\")\n",
    "ax.plot(range(n), (run_hist_2.history[\"val_accuracy\"]),'b.', label=\"Validation Acc\")\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_title('Accuracy over iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy is 0.641\n",
      "roc-auc is 0.824\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_class_nn_2 = np.argmax(model_2.predict(X_test_norm), axis=-1)#model_2.predict_classes(X_test_norm)\n",
    "y_pred_prob_nn_2 = model_2.predict(X_test_norm)\n",
    "print('')\n",
    "print('accuracy is {:.3f}'.format(accuracy_score(y_test,y_pred_class_nn_2)))\n",
    "print('roc-auc is {:.3f}'.format(roc_auc_score(y_test,y_pred_prob_nn_2)))\n",
    "\n",
    "plot_roc(y_test, y_pred_prob_nn_2, 'NN-2')\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Machine Learning Foundation (C) 2020 IBM Corporation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
